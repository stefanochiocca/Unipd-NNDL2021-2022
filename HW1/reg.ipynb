{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf448e33-9d7f-4413-8491-d5f2831afbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "873acaf7-f514-46c3-a946-2ce8910b8db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2021-12-12 16:24:45--  https://gitlab.dei.unipd.it/michieli/nnld-2021-22-lab-resources/-/raw/main/homework1/train_data.csv\n",
      "Resolving gitlab.dei.unipd.it (gitlab.dei.unipd.it)... 147.162.2.85\n",
      "Connecting to gitlab.dei.unipd.it (gitlab.dei.unipd.it)|147.162.2.85|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3776 (3,7K) [text/plain]\n",
      "Saving to: 'regression_dataset/train_data.csv.10'\n",
      "\n",
      "     0K ...                                                   100%  154K=0,02s\n",
      "\n",
      "2021-12-12 16:24:46 (154 KB/s) - 'regression_dataset/train_data.csv.10' saved [3776/3776]\n",
      "\n",
      "--2021-12-12 16:24:46--  https://gitlab.dei.unipd.it/michieli/nnld-2021-22-lab-resources/-/raw/main/homework1/test_data.csv\n",
      "Resolving gitlab.dei.unipd.it (gitlab.dei.unipd.it)... 147.162.2.85\n",
      "Connecting to gitlab.dei.unipd.it (gitlab.dei.unipd.it)|147.162.2.85|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3788 (3,7K) [text/plain]\n",
      "Saving to: 'regression_dataset/test_data.csv.10'\n",
      "\n",
      "     0K ...                                                   100%  164K=0,02s\n",
      "\n",
      "2021-12-12 16:24:46 (164 KB/s) - 'regression_dataset/test_data.csv.10' saved [3788/3788]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -P regression_dataset https://gitlab.dei.unipd.it/michieli/nnld-2021-22-lab-resources/-/raw/main/homework1/train_data.csv\n",
    "!wget -P regression_dataset https://gitlab.dei.unipd.it/michieli/nnld-2021-22-lab-resources/-/raw/main/homework1/test_data.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c953efe6-87ba-4b5e-9436-334e84e6aca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f677b91b-765d-4071-9693-d5e4ba4f2a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('regression_dataset/train_data.csv')\n",
    "test_data = pd.read_csv('regression_dataset/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3065f8c4-187d-4eb7-a184-6275eb2c60f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CsvDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        \n",
    "        self.transform = transform\n",
    "        # Read the file and split the lines in a list\n",
    "        with open(csv_file, 'r') as f:\n",
    "            lines = f.read().split('\\n')\n",
    "        lines.pop(0)\n",
    "        lines.pop(-1)\n",
    "        # Get x and y values from each line and append to self.data\n",
    "        self.data = []\n",
    "        for line in lines:\n",
    "            sample = line.split(',')\n",
    "            self.data.append((float(sample[0]), float(sample[1])))\n",
    "            # Now self.data contains all our dataset.\n",
    "        # Each element of the list self.data is a tuple: (input, output)\n",
    "    def __len__(self):\n",
    "        # The length of the dataset is simply the length of the self.data list\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Our sample is the element idx of the list self.data\n",
    "        sample = self.data[idx]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39e997c9-5a81-4ba0-865d-9c9fd90045dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor():\n",
    "        \"\"\"Convert sample to Tensors.\"\"\"\n",
    "        def __call__(self, sample):\n",
    "            x, y = sample\n",
    "            return (torch.tensor([x]).float(), torch.tensor([y]).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "655294ad-2ada-4bd7-ab15-acc0a9a9c273",
   "metadata": {},
   "outputs": [],
   "source": [
    "composed_transform = transforms.Compose([ToTensor()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9142651-f395-4452-8bf8-802d4dc4add7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "#Validation test\n",
    "indices = list(range(len(train_data)))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# 20% of the train set will be validation set\n",
    "split = int(np.floor(0.2 * len(train_data)))\n",
    "\n",
    "train_set = SubsetRandomSampler(indices[:split])\n",
    "valid_set = SubsetRandomSampler(indices[split:]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cb905eb-0d92-4318-bcb7-fb14960e81bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CsvDataset('regression_dataset/train_data.csv', transform=composed_transform)\n",
    "#valid_dataset = CsvDataset('regression_dataset/valid_temp.csv', transform=composed_transform)\n",
    "test_dataset = CsvDataset('regression_dataset/test_data.csv', transform=composed_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "560c62b7-df6d-471a-a811-023399516807",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=4)\n",
    "### Define validation dataloader\n",
    "#val_dataloader = DataLoader(train_dataset, sampler=valid_set, batch_size=4)\n",
    "test_dataloader = DataLoader(test_dataset,  batch_size=len(test_dataset), shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d08e427-a1b6-4138-bf82-d6119d3d594a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, Ni, Nh1, Nh2, No):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        print('Network initialized')\n",
    "        \n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(Ni, Nh1),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(Nh1, Nh2),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(Nh2, No)       \n",
    "        )\n",
    "    \n",
    "    def forward(self, x, additional_out=False):\n",
    "        self.linear(x)\n",
    "        return x\n",
    "'''\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, Ni, Nh1, Nh2, No):\n",
    "        \"\"\"\n",
    "        Ni - Input size\n",
    "        Nh1 - Neurons in the 1st hidden layer\n",
    "        Nh2 - Neurons in the 2nd hidden layer\n",
    "        No - Output size\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        print('Network initialized')\n",
    "        self.fc1 = nn.Linear(in_features=Ni, out_features=Nh1)\n",
    "        self.fc2 = nn.Linear(in_features=Nh1, out_features=Nh2)\n",
    "        self.out = nn.Linear(in_features=Nh2, out_features=No)\n",
    "        self.act = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x, additional_out=False):\n",
    "        x = self.act(self.fc1(x))\n",
    "        x = self.act(self.fc2(x))\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf6507a3-5c8d-4c8f-9c50-87eb3843c34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Check if the GPU is available\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Training device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c79f4477-be0b-4c95-ba34-629c42a78c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network initialized\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=1, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=256, bias=True)\n",
       "  (out): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (act): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "Ni = 1\n",
    "Nh1 = 128\n",
    "Nh2 = 256\n",
    "No = 1\n",
    "net = Net(Ni, Nh1, Nh2, No)\n",
    "net.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02c6e8a0-7d52-4a5d-9dcd-8d56e9fd20e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()  \n",
    "optimizer = optim.Adam(net.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90740683-ee84-4945-86c7-168c63ef501a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1df169c-6b61-46b1-b327-a274c7da0ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE TRAIN LOSS: 4.4477996826171875\n",
      "AVERAGE TEST LOSS: 3.0139875411987305\n",
      "AVERAGE TRAIN LOSS: 2.819979190826416\n",
      "AVERAGE TEST LOSS: 2.843344211578369\n",
      "AVERAGE TRAIN LOSS: 2.6361396312713623\n",
      "AVERAGE TEST LOSS: 2.94181489944458\n",
      "AVERAGE TRAIN LOSS: 2.7298548221588135\n",
      "AVERAGE TEST LOSS: 3.043100357055664\n",
      "AVERAGE TRAIN LOSS: 2.663914203643799\n",
      "AVERAGE TEST LOSS: 2.9221081733703613\n",
      "AVERAGE TRAIN LOSS: 2.669382095336914\n",
      "AVERAGE TEST LOSS: 2.862778902053833\n",
      "AVERAGE TRAIN LOSS: 2.6570284366607666\n",
      "AVERAGE TEST LOSS: 2.933281660079956\n",
      "AVERAGE TRAIN LOSS: 2.650756597518921\n",
      "AVERAGE TEST LOSS: 2.8703453540802\n",
      "AVERAGE TRAIN LOSS: 2.661008834838867\n",
      "AVERAGE TEST LOSS: 2.960939884185791\n",
      "AVERAGE TRAIN LOSS: 2.619123935699463\n",
      "AVERAGE TEST LOSS: 2.8579788208007812\n",
      "AVERAGE TRAIN LOSS: 2.6482303142547607\n",
      "AVERAGE TEST LOSS: 2.885441780090332\n",
      "AVERAGE TRAIN LOSS: 2.676926612854004\n",
      "AVERAGE TEST LOSS: 2.850956916809082\n",
      "AVERAGE TRAIN LOSS: 2.5980658531188965\n",
      "AVERAGE TEST LOSS: 2.8091113567352295\n",
      "AVERAGE TRAIN LOSS: 2.6539905071258545\n",
      "AVERAGE TEST LOSS: 2.970938205718994\n",
      "AVERAGE TRAIN LOSS: 2.57096529006958\n",
      "AVERAGE TEST LOSS: 2.8230533599853516\n",
      "AVERAGE TRAIN LOSS: 2.598909854888916\n",
      "AVERAGE TEST LOSS: 2.8043901920318604\n",
      "AVERAGE TRAIN LOSS: 2.6723098754882812\n",
      "AVERAGE TEST LOSS: 2.8377654552459717\n",
      "AVERAGE TRAIN LOSS: 2.6237049102783203\n",
      "AVERAGE TEST LOSS: 2.836914300918579\n",
      "AVERAGE TRAIN LOSS: 2.5529139041900635\n",
      "AVERAGE TEST LOSS: 2.9286913871765137\n",
      "AVERAGE TRAIN LOSS: 2.698885202407837\n",
      "AVERAGE TEST LOSS: 2.77956485748291\n",
      "AVERAGE TRAIN LOSS: 2.668210744857788\n",
      "AVERAGE TEST LOSS: 2.807651996612549\n",
      "AVERAGE TRAIN LOSS: 2.5169548988342285\n",
      "AVERAGE TEST LOSS: 2.7776098251342773\n",
      "AVERAGE TRAIN LOSS: 2.5865318775177\n",
      "AVERAGE TEST LOSS: 2.7295403480529785\n",
      "AVERAGE TRAIN LOSS: 2.459717035293579\n",
      "AVERAGE TEST LOSS: 2.6990342140197754\n",
      "AVERAGE TRAIN LOSS: 2.5141632556915283\n",
      "AVERAGE TEST LOSS: 2.7627294063568115\n",
      "AVERAGE TRAIN LOSS: 2.4889023303985596\n",
      "AVERAGE TEST LOSS: 2.649749755859375\n",
      "AVERAGE TRAIN LOSS: 2.464651584625244\n",
      "AVERAGE TEST LOSS: 2.652189254760742\n",
      "AVERAGE TRAIN LOSS: 2.4539055824279785\n",
      "AVERAGE TEST LOSS: 2.6580095291137695\n",
      "AVERAGE TRAIN LOSS: 2.4505913257598877\n",
      "AVERAGE TEST LOSS: 2.607631206512451\n",
      "AVERAGE TRAIN LOSS: 2.5844995975494385\n",
      "AVERAGE TEST LOSS: 2.6763761043548584\n",
      "AVERAGE TRAIN LOSS: 2.583787202835083\n",
      "AVERAGE TEST LOSS: 2.555396556854248\n",
      "AVERAGE TRAIN LOSS: 2.3786163330078125\n",
      "AVERAGE TEST LOSS: 2.6371288299560547\n",
      "AVERAGE TRAIN LOSS: 2.3989129066467285\n",
      "AVERAGE TEST LOSS: 2.570676565170288\n",
      "AVERAGE TRAIN LOSS: 2.3904476165771484\n",
      "AVERAGE TEST LOSS: 2.618581771850586\n",
      "AVERAGE TRAIN LOSS: 2.399775505065918\n",
      "AVERAGE TEST LOSS: 2.547041416168213\n",
      "AVERAGE TRAIN LOSS: 2.357851028442383\n",
      "AVERAGE TEST LOSS: 2.5048892498016357\n",
      "AVERAGE TRAIN LOSS: 2.380276679992676\n",
      "AVERAGE TEST LOSS: 2.501859664916992\n",
      "AVERAGE TRAIN LOSS: 2.2821507453918457\n",
      "AVERAGE TEST LOSS: 2.550013542175293\n",
      "AVERAGE TRAIN LOSS: 2.335005760192871\n",
      "AVERAGE TEST LOSS: 2.3770830631256104\n",
      "AVERAGE TRAIN LOSS: 2.228426456451416\n",
      "AVERAGE TEST LOSS: 2.4528114795684814\n",
      "AVERAGE TRAIN LOSS: 2.2802300453186035\n",
      "AVERAGE TEST LOSS: 2.349294424057007\n",
      "AVERAGE TRAIN LOSS: 2.2244858741760254\n",
      "AVERAGE TEST LOSS: 2.4158802032470703\n",
      "AVERAGE TRAIN LOSS: 2.129826545715332\n",
      "AVERAGE TEST LOSS: 2.28228497505188\n",
      "AVERAGE TRAIN LOSS: 2.1429333686828613\n",
      "AVERAGE TEST LOSS: 2.2955126762390137\n",
      "AVERAGE TRAIN LOSS: 2.1764519214630127\n",
      "AVERAGE TEST LOSS: 2.409304618835449\n",
      "AVERAGE TRAIN LOSS: 2.208996057510376\n",
      "AVERAGE TEST LOSS: 2.1704814434051514\n",
      "AVERAGE TRAIN LOSS: 2.0664050579071045\n",
      "AVERAGE TEST LOSS: 2.4450020790100098\n",
      "AVERAGE TRAIN LOSS: 2.1712467670440674\n",
      "AVERAGE TEST LOSS: 2.126248359680176\n",
      "AVERAGE TRAIN LOSS: 2.065291166305542\n",
      "AVERAGE TEST LOSS: 2.1149508953094482\n",
      "AVERAGE TRAIN LOSS: 1.966782569885254\n",
      "AVERAGE TEST LOSS: 2.138075351715088\n",
      "AVERAGE TRAIN LOSS: 1.9432929754257202\n",
      "AVERAGE TEST LOSS: 2.136256694793701\n",
      "AVERAGE TRAIN LOSS: 1.9194008111953735\n",
      "AVERAGE TEST LOSS: 2.091369390487671\n",
      "AVERAGE TRAIN LOSS: 2.0198683738708496\n",
      "AVERAGE TEST LOSS: 1.9731476306915283\n",
      "AVERAGE TRAIN LOSS: 1.7953709363937378\n",
      "AVERAGE TEST LOSS: 1.9360798597335815\n",
      "AVERAGE TRAIN LOSS: 1.7938793897628784\n",
      "AVERAGE TEST LOSS: 1.9158440828323364\n",
      "AVERAGE TRAIN LOSS: 1.8606070280075073\n",
      "AVERAGE TEST LOSS: 1.955552101135254\n",
      "AVERAGE TRAIN LOSS: 1.7201324701309204\n",
      "AVERAGE TEST LOSS: 1.9061580896377563\n",
      "AVERAGE TRAIN LOSS: 1.832348346710205\n",
      "AVERAGE TEST LOSS: 1.7568938732147217\n",
      "AVERAGE TRAIN LOSS: 1.6577835083007812\n",
      "AVERAGE TEST LOSS: 1.783182978630066\n",
      "AVERAGE TRAIN LOSS: 1.6933059692382812\n",
      "AVERAGE TEST LOSS: 1.7942270040512085\n",
      "AVERAGE TRAIN LOSS: 1.6556293964385986\n",
      "AVERAGE TEST LOSS: 1.7309247255325317\n",
      "AVERAGE TRAIN LOSS: 1.573768138885498\n",
      "AVERAGE TEST LOSS: 1.6865872144699097\n",
      "AVERAGE TRAIN LOSS: 1.5871338844299316\n",
      "AVERAGE TEST LOSS: 1.7487374544143677\n",
      "AVERAGE TRAIN LOSS: 1.6628737449645996\n",
      "AVERAGE TEST LOSS: 1.9117764234542847\n",
      "AVERAGE TRAIN LOSS: 1.5700095891952515\n",
      "AVERAGE TEST LOSS: 1.9415338039398193\n",
      "AVERAGE TRAIN LOSS: 1.6067390441894531\n",
      "AVERAGE TEST LOSS: 2.159407138824463\n",
      "AVERAGE TRAIN LOSS: 1.6024175882339478\n",
      "AVERAGE TEST LOSS: 1.6263943910598755\n",
      "AVERAGE TRAIN LOSS: 1.640303134918213\n",
      "AVERAGE TEST LOSS: 1.5651299953460693\n",
      "AVERAGE TRAIN LOSS: 1.3828390836715698\n",
      "AVERAGE TEST LOSS: 1.598901391029358\n",
      "AVERAGE TRAIN LOSS: 1.4880588054656982\n",
      "AVERAGE TEST LOSS: 1.5231502056121826\n",
      "AVERAGE TRAIN LOSS: 1.3887141942977905\n",
      "AVERAGE TEST LOSS: 1.5730520486831665\n",
      "AVERAGE TRAIN LOSS: 1.3410027027130127\n",
      "AVERAGE TEST LOSS: 1.5506973266601562\n",
      "AVERAGE TRAIN LOSS: 1.3910845518112183\n",
      "AVERAGE TEST LOSS: 1.5199710130691528\n",
      "AVERAGE TRAIN LOSS: 1.5381219387054443\n",
      "AVERAGE TEST LOSS: 1.5035229921340942\n",
      "AVERAGE TRAIN LOSS: 1.2727019786834717\n",
      "AVERAGE TEST LOSS: 1.4875845909118652\n",
      "AVERAGE TRAIN LOSS: 1.296860694885254\n",
      "AVERAGE TEST LOSS: 1.6776500940322876\n",
      "AVERAGE TRAIN LOSS: 1.2916795015335083\n",
      "AVERAGE TEST LOSS: 1.549098014831543\n",
      "AVERAGE TRAIN LOSS: 1.3109257221221924\n",
      "AVERAGE TEST LOSS: 2.514634132385254\n",
      "AVERAGE TRAIN LOSS: 1.3998005390167236\n",
      "AVERAGE TEST LOSS: 1.7049245834350586\n",
      "AVERAGE TRAIN LOSS: 1.3543533086776733\n",
      "AVERAGE TEST LOSS: 1.6425708532333374\n",
      "AVERAGE TRAIN LOSS: 1.3091479539871216\n",
      "AVERAGE TEST LOSS: 1.4480175971984863\n",
      "AVERAGE TRAIN LOSS: 1.23148512840271\n",
      "AVERAGE TEST LOSS: 1.4962027072906494\n",
      "AVERAGE TRAIN LOSS: 1.197295904159546\n",
      "AVERAGE TEST LOSS: 1.7401858568191528\n",
      "AVERAGE TRAIN LOSS: 1.2217689752578735\n",
      "AVERAGE TEST LOSS: 2.050771951675415\n",
      "AVERAGE TRAIN LOSS: 1.3029462099075317\n",
      "AVERAGE TEST LOSS: 2.166255235671997\n",
      "AVERAGE TRAIN LOSS: 1.3755638599395752\n",
      "AVERAGE TEST LOSS: 1.8906840085983276\n",
      "AVERAGE TRAIN LOSS: 1.363608956336975\n",
      "AVERAGE TEST LOSS: 1.7316644191741943\n",
      "AVERAGE TRAIN LOSS: 1.1341763734817505\n",
      "AVERAGE TEST LOSS: 1.5532516241073608\n",
      "AVERAGE TRAIN LOSS: 1.123321771621704\n",
      "AVERAGE TEST LOSS: 1.6032097339630127\n",
      "AVERAGE TRAIN LOSS: 1.1095473766326904\n",
      "AVERAGE TEST LOSS: 1.473073124885559\n",
      "AVERAGE TRAIN LOSS: 1.2537965774536133\n",
      "AVERAGE TEST LOSS: 1.4049888849258423\n",
      "AVERAGE TRAIN LOSS: 1.2223678827285767\n",
      "AVERAGE TEST LOSS: 1.4078906774520874\n",
      "AVERAGE TRAIN LOSS: 1.249801516532898\n",
      "AVERAGE TEST LOSS: 1.3637253046035767\n",
      "AVERAGE TRAIN LOSS: 1.1437592506408691\n",
      "AVERAGE TEST LOSS: 1.5431116819381714\n",
      "AVERAGE TRAIN LOSS: 1.1089388132095337\n",
      "AVERAGE TEST LOSS: 1.4538851976394653\n",
      "AVERAGE TRAIN LOSS: 1.0485007762908936\n",
      "AVERAGE TEST LOSS: 1.5052828788757324\n",
      "AVERAGE TRAIN LOSS: 1.059465765953064\n",
      "AVERAGE TEST LOSS: 1.3386332988739014\n",
      "AVERAGE TRAIN LOSS: 0.9109365940093994\n",
      "AVERAGE TEST LOSS: 1.8907321691513062\n",
      "AVERAGE TRAIN LOSS: 1.117630124092102\n",
      "AVERAGE TEST LOSS: 1.2874711751937866\n",
      "AVERAGE TRAIN LOSS: 0.9995546936988831\n",
      "AVERAGE TEST LOSS: 1.7200422286987305\n",
      "AVERAGE TRAIN LOSS: 1.0433878898620605\n",
      "AVERAGE TEST LOSS: 1.306858777999878\n",
      "AVERAGE TRAIN LOSS: 0.9895671606063843\n",
      "AVERAGE TEST LOSS: 1.3080252408981323\n",
      "AVERAGE TRAIN LOSS: 1.0716227293014526\n",
      "AVERAGE TEST LOSS: 1.303392767906189\n",
      "AVERAGE TRAIN LOSS: 0.9762156009674072\n",
      "AVERAGE TEST LOSS: 1.2404922246932983\n",
      "AVERAGE TRAIN LOSS: 0.984569251537323\n",
      "AVERAGE TEST LOSS: 1.2450791597366333\n",
      "AVERAGE TRAIN LOSS: 0.934386134147644\n",
      "AVERAGE TEST LOSS: 1.3171993494033813\n",
      "AVERAGE TRAIN LOSS: 0.918812096118927\n",
      "AVERAGE TEST LOSS: 1.414800763130188\n",
      "AVERAGE TRAIN LOSS: 0.9894890785217285\n",
      "AVERAGE TEST LOSS: 1.3080732822418213\n",
      "AVERAGE TRAIN LOSS: 0.9598197937011719\n",
      "AVERAGE TEST LOSS: 1.2198741436004639\n",
      "AVERAGE TRAIN LOSS: 1.0024765729904175\n",
      "AVERAGE TEST LOSS: 1.265838623046875\n",
      "AVERAGE TRAIN LOSS: 1.089521050453186\n",
      "AVERAGE TEST LOSS: 1.2395297288894653\n",
      "AVERAGE TRAIN LOSS: 0.8437184691429138\n",
      "AVERAGE TEST LOSS: 1.1564712524414062\n",
      "AVERAGE TRAIN LOSS: 0.9153834581375122\n",
      "AVERAGE TEST LOSS: 1.1340855360031128\n",
      "AVERAGE TRAIN LOSS: 0.8559118509292603\n",
      "AVERAGE TEST LOSS: 1.2914881706237793\n",
      "AVERAGE TRAIN LOSS: 0.884205162525177\n",
      "AVERAGE TEST LOSS: 1.2886178493499756\n",
      "AVERAGE TRAIN LOSS: 0.9091255068778992\n",
      "AVERAGE TEST LOSS: 1.3715115785598755\n",
      "AVERAGE TRAIN LOSS: 0.8972021341323853\n",
      "AVERAGE TEST LOSS: 1.1563894748687744\n",
      "AVERAGE TRAIN LOSS: 0.8248460292816162\n",
      "AVERAGE TEST LOSS: 1.1062618494033813\n",
      "AVERAGE TRAIN LOSS: 0.8729267716407776\n",
      "AVERAGE TEST LOSS: 1.313269019126892\n",
      "AVERAGE TRAIN LOSS: 0.8136013150215149\n",
      "AVERAGE TEST LOSS: 1.095035433769226\n",
      "AVERAGE TRAIN LOSS: 0.7845824956893921\n",
      "AVERAGE TEST LOSS: 1.1031253337860107\n",
      "AVERAGE TRAIN LOSS: 0.7782713174819946\n",
      "AVERAGE TEST LOSS: 1.059342384338379\n",
      "AVERAGE TRAIN LOSS: 0.7676377892494202\n",
      "AVERAGE TEST LOSS: 1.14826500415802\n",
      "AVERAGE TRAIN LOSS: 0.8118002414703369\n",
      "AVERAGE TEST LOSS: 1.1801598072052002\n",
      "AVERAGE TRAIN LOSS: 0.764803409576416\n",
      "AVERAGE TEST LOSS: 1.0168209075927734\n",
      "AVERAGE TRAIN LOSS: 0.8077687621116638\n",
      "AVERAGE TEST LOSS: 1.016382098197937\n",
      "AVERAGE TRAIN LOSS: 0.720375120639801\n",
      "AVERAGE TEST LOSS: 1.0523985624313354\n",
      "AVERAGE TRAIN LOSS: 0.7827389240264893\n",
      "AVERAGE TEST LOSS: 1.040675401687622\n",
      "AVERAGE TRAIN LOSS: 0.7399287223815918\n",
      "AVERAGE TEST LOSS: 1.0027775764465332\n",
      "AVERAGE TRAIN LOSS: 0.6726170182228088\n",
      "AVERAGE TEST LOSS: 0.9716513156890869\n",
      "AVERAGE TRAIN LOSS: 0.6732842922210693\n",
      "AVERAGE TEST LOSS: 1.009800672531128\n",
      "AVERAGE TRAIN LOSS: 0.7395249009132385\n",
      "AVERAGE TEST LOSS: 1.0381709337234497\n",
      "AVERAGE TRAIN LOSS: 0.7471785545349121\n",
      "AVERAGE TEST LOSS: 0.9296806454658508\n",
      "AVERAGE TRAIN LOSS: 0.6874946355819702\n",
      "AVERAGE TEST LOSS: 0.9905218482017517\n",
      "AVERAGE TRAIN LOSS: 0.6046363711357117\n",
      "AVERAGE TEST LOSS: 1.2230579853057861\n",
      "AVERAGE TRAIN LOSS: 0.7081220149993896\n",
      "AVERAGE TEST LOSS: 1.0372824668884277\n",
      "AVERAGE TRAIN LOSS: 0.6705712080001831\n",
      "AVERAGE TEST LOSS: 1.0956159830093384\n",
      "AVERAGE TRAIN LOSS: 0.6997490525245667\n",
      "AVERAGE TEST LOSS: 0.9967077374458313\n",
      "AVERAGE TRAIN LOSS: 0.6941245198249817\n",
      "AVERAGE TEST LOSS: 0.9753473401069641\n",
      "AVERAGE TRAIN LOSS: 0.7030971050262451\n",
      "AVERAGE TEST LOSS: 0.8681507706642151\n",
      "AVERAGE TRAIN LOSS: 0.7862266302108765\n",
      "AVERAGE TEST LOSS: 0.9223085045814514\n",
      "AVERAGE TRAIN LOSS: 0.7325882911682129\n",
      "AVERAGE TEST LOSS: 1.094731330871582\n",
      "AVERAGE TRAIN LOSS: 0.6879334449768066\n",
      "AVERAGE TEST LOSS: 1.0313605070114136\n",
      "AVERAGE TRAIN LOSS: 0.6838575601577759\n",
      "AVERAGE TEST LOSS: 0.9075364470481873\n",
      "AVERAGE TRAIN LOSS: 0.6010342836380005\n",
      "AVERAGE TEST LOSS: 0.7909495830535889\n",
      "AVERAGE TRAIN LOSS: 0.5984837412834167\n",
      "AVERAGE TEST LOSS: 0.8092858791351318\n",
      "AVERAGE TRAIN LOSS: 0.5478837490081787\n",
      "AVERAGE TEST LOSS: 0.826140284538269\n",
      "AVERAGE TRAIN LOSS: 0.5584097504615784\n",
      "AVERAGE TEST LOSS: 0.7715246677398682\n",
      "AVERAGE TRAIN LOSS: 0.5448728203773499\n",
      "AVERAGE TEST LOSS: 0.8099147081375122\n",
      "AVERAGE TRAIN LOSS: 0.5779100060462952\n",
      "AVERAGE TEST LOSS: 0.8201135396957397\n",
      "AVERAGE TRAIN LOSS: 0.5754575133323669\n",
      "AVERAGE TEST LOSS: 0.7635509967803955\n",
      "AVERAGE TRAIN LOSS: 0.6578361392021179\n",
      "AVERAGE TEST LOSS: 0.7887595891952515\n",
      "AVERAGE TRAIN LOSS: 0.5368754863739014\n",
      "AVERAGE TEST LOSS: 0.7411589026451111\n",
      "AVERAGE TRAIN LOSS: 0.5605266690254211\n",
      "AVERAGE TEST LOSS: 0.8009251952171326\n",
      "AVERAGE TRAIN LOSS: 0.5565136671066284\n",
      "AVERAGE TEST LOSS: 0.7379170060157776\n",
      "AVERAGE TRAIN LOSS: 0.49538418650627136\n",
      "AVERAGE TEST LOSS: 0.8052131533622742\n",
      "AVERAGE TRAIN LOSS: 0.484127402305603\n",
      "AVERAGE TEST LOSS: 0.7531381249427795\n",
      "AVERAGE TRAIN LOSS: 0.5152784585952759\n",
      "AVERAGE TEST LOSS: 0.6286841630935669\n",
      "AVERAGE TRAIN LOSS: 0.5555419325828552\n",
      "AVERAGE TEST LOSS: 0.6788708567619324\n",
      "AVERAGE TRAIN LOSS: 0.5306629538536072\n",
      "AVERAGE TEST LOSS: 0.7169658541679382\n",
      "AVERAGE TRAIN LOSS: 0.5307765603065491\n",
      "AVERAGE TEST LOSS: 0.7536280751228333\n",
      "AVERAGE TRAIN LOSS: 0.46199190616607666\n",
      "AVERAGE TEST LOSS: 0.657976508140564\n",
      "AVERAGE TRAIN LOSS: 0.4719524383544922\n",
      "AVERAGE TEST LOSS: 0.6329647898674011\n",
      "AVERAGE TRAIN LOSS: 0.43172991275787354\n",
      "AVERAGE TEST LOSS: 0.6361526250839233\n",
      "AVERAGE TRAIN LOSS: 0.47992390394210815\n",
      "AVERAGE TEST LOSS: 0.6303004622459412\n",
      "AVERAGE TRAIN LOSS: 0.45820221304893494\n",
      "AVERAGE TEST LOSS: 0.5972264409065247\n",
      "AVERAGE TRAIN LOSS: 0.4434182643890381\n",
      "AVERAGE TEST LOSS: 0.6149676442146301\n",
      "AVERAGE TRAIN LOSS: 0.45513203740119934\n",
      "AVERAGE TEST LOSS: 0.5871253609657288\n",
      "AVERAGE TRAIN LOSS: 0.4828103184700012\n",
      "AVERAGE TEST LOSS: 0.5587295889854431\n",
      "AVERAGE TRAIN LOSS: 0.42919114232063293\n",
      "AVERAGE TEST LOSS: 0.5848529934883118\n",
      "AVERAGE TRAIN LOSS: 0.4844997525215149\n",
      "AVERAGE TEST LOSS: 0.5513298511505127\n",
      "AVERAGE TRAIN LOSS: 0.4528709352016449\n",
      "AVERAGE TEST LOSS: 0.5569372773170471\n",
      "AVERAGE TRAIN LOSS: 0.43932515382766724\n",
      "AVERAGE TEST LOSS: 0.5327284336090088\n",
      "AVERAGE TRAIN LOSS: 0.41101008653640747\n",
      "AVERAGE TEST LOSS: 0.5376082062721252\n",
      "AVERAGE TRAIN LOSS: 0.39970701932907104\n",
      "AVERAGE TEST LOSS: 0.6511968970298767\n",
      "AVERAGE TRAIN LOSS: 0.43873322010040283\n",
      "AVERAGE TEST LOSS: 0.5531672835350037\n",
      "AVERAGE TRAIN LOSS: 0.4205138087272644\n",
      "AVERAGE TEST LOSS: 0.5191806554794312\n",
      "AVERAGE TRAIN LOSS: 0.4306102991104126\n",
      "AVERAGE TEST LOSS: 0.5021187663078308\n",
      "AVERAGE TRAIN LOSS: 0.4000205993652344\n",
      "AVERAGE TEST LOSS: 0.5188697576522827\n",
      "AVERAGE TRAIN LOSS: 0.4096914529800415\n",
      "AVERAGE TEST LOSS: 0.5336650013923645\n",
      "AVERAGE TRAIN LOSS: 0.38443514704704285\n",
      "AVERAGE TEST LOSS: 0.5637613534927368\n",
      "AVERAGE TRAIN LOSS: 0.36752158403396606\n",
      "AVERAGE TEST LOSS: 0.49293068051338196\n",
      "AVERAGE TRAIN LOSS: 0.355223149061203\n",
      "AVERAGE TEST LOSS: 0.5834305882453918\n",
      "AVERAGE TRAIN LOSS: 0.3740294575691223\n",
      "AVERAGE TEST LOSS: 0.4754665493965149\n",
      "AVERAGE TRAIN LOSS: 0.41829949617385864\n",
      "AVERAGE TEST LOSS: 0.47592154145240784\n",
      "AVERAGE TRAIN LOSS: 0.3518081605434418\n",
      "AVERAGE TEST LOSS: 0.6050787568092346\n",
      "AVERAGE TRAIN LOSS: 0.42680805921554565\n",
      "AVERAGE TEST LOSS: 0.4976567029953003\n",
      "AVERAGE TRAIN LOSS: 0.3646746575832367\n",
      "AVERAGE TEST LOSS: 0.5083553194999695\n",
      "AVERAGE TRAIN LOSS: 0.4235679507255554\n",
      "AVERAGE TEST LOSS: 0.5150246620178223\n",
      "AVERAGE TRAIN LOSS: 0.3843626081943512\n",
      "AVERAGE TEST LOSS: 0.4802732467651367\n",
      "AVERAGE TRAIN LOSS: 0.33988574147224426\n",
      "AVERAGE TEST LOSS: 0.5079259276390076\n",
      "AVERAGE TRAIN LOSS: 0.35613811016082764\n",
      "AVERAGE TEST LOSS: 0.4783950746059418\n",
      "AVERAGE TRAIN LOSS: 0.3506781756877899\n",
      "AVERAGE TEST LOSS: 0.5897532105445862\n",
      "AVERAGE TRAIN LOSS: 0.4111822843551636\n",
      "AVERAGE TEST LOSS: 0.5316898822784424\n",
      "AVERAGE TRAIN LOSS: 0.3443337678909302\n",
      "AVERAGE TEST LOSS: 0.4002780020236969\n",
      "AVERAGE TRAIN LOSS: 0.396284282207489\n",
      "AVERAGE TEST LOSS: 0.4035676121711731\n",
      "AVERAGE TRAIN LOSS: 0.3724623918533325\n",
      "AVERAGE TEST LOSS: 0.42081764340400696\n",
      "AVERAGE TRAIN LOSS: 0.34372207522392273\n",
      "AVERAGE TEST LOSS: 0.5377658009529114\n",
      "AVERAGE TRAIN LOSS: 0.4038752615451813\n",
      "AVERAGE TEST LOSS: 0.40134739875793457\n",
      "AVERAGE TRAIN LOSS: 0.3150741755962372\n",
      "AVERAGE TEST LOSS: 0.4865380525588989\n",
      "AVERAGE TRAIN LOSS: 0.3589324653148651\n",
      "AVERAGE TEST LOSS: 0.5533552765846252\n",
      "AVERAGE TRAIN LOSS: 0.33779376745224\n",
      "AVERAGE TEST LOSS: 0.5146647691726685\n",
      "AVERAGE TRAIN LOSS: 0.3570548892021179\n",
      "AVERAGE TEST LOSS: 0.3811914920806885\n",
      "AVERAGE TRAIN LOSS: 0.34330472350120544\n",
      "AVERAGE TEST LOSS: 0.41639459133148193\n",
      "AVERAGE TRAIN LOSS: 0.3567751348018646\n",
      "AVERAGE TEST LOSS: 0.40959128737449646\n",
      "AVERAGE TRAIN LOSS: 0.39858201146125793\n",
      "AVERAGE TEST LOSS: 0.39291489124298096\n",
      "AVERAGE TRAIN LOSS: 0.3808780610561371\n",
      "AVERAGE TEST LOSS: 0.3888848125934601\n",
      "AVERAGE TRAIN LOSS: 0.34352219104766846\n",
      "AVERAGE TEST LOSS: 0.37935301661491394\n",
      "AVERAGE TRAIN LOSS: 0.30330273509025574\n",
      "AVERAGE TEST LOSS: 0.38844192028045654\n",
      "AVERAGE TRAIN LOSS: 0.3265652358531952\n",
      "AVERAGE TEST LOSS: 0.3837977647781372\n",
      "AVERAGE TRAIN LOSS: 0.3156338632106781\n",
      "AVERAGE TEST LOSS: 0.3837187886238098\n",
      "AVERAGE TRAIN LOSS: 0.2990871071815491\n",
      "AVERAGE TEST LOSS: 0.3492177724838257\n",
      "AVERAGE TRAIN LOSS: 0.33374038338661194\n",
      "AVERAGE TEST LOSS: 0.3696820139884949\n",
      "AVERAGE TRAIN LOSS: 0.3258824944496155\n",
      "AVERAGE TEST LOSS: 0.4578453004360199\n",
      "AVERAGE TRAIN LOSS: 0.3538868725299835\n",
      "AVERAGE TEST LOSS: 0.4760901927947998\n",
      "AVERAGE TRAIN LOSS: 0.3183266818523407\n",
      "AVERAGE TEST LOSS: 0.35388466715812683\n",
      "AVERAGE TRAIN LOSS: 0.3109956681728363\n",
      "AVERAGE TEST LOSS: 0.3432348668575287\n",
      "AVERAGE TRAIN LOSS: 0.28749290108680725\n",
      "AVERAGE TEST LOSS: 0.38814613223075867\n",
      "AVERAGE TRAIN LOSS: 0.3469688892364502\n",
      "AVERAGE TEST LOSS: 0.3835141062736511\n",
      "AVERAGE TRAIN LOSS: 0.33311426639556885\n",
      "AVERAGE TEST LOSS: 0.3823263943195343\n",
      "AVERAGE TRAIN LOSS: 0.3029831051826477\n",
      "AVERAGE TEST LOSS: 0.4045490622520447\n",
      "AVERAGE TRAIN LOSS: 0.32551372051239014\n",
      "AVERAGE TEST LOSS: 0.42005911469459534\n",
      "AVERAGE TRAIN LOSS: 0.32152050733566284\n",
      "AVERAGE TEST LOSS: 0.3685028553009033\n",
      "AVERAGE TRAIN LOSS: 0.30632275342941284\n",
      "AVERAGE TEST LOSS: 0.378714382648468\n",
      "AVERAGE TRAIN LOSS: 0.3209976553916931\n",
      "AVERAGE TEST LOSS: 0.4846983253955841\n",
      "AVERAGE TRAIN LOSS: 0.328586608171463\n",
      "AVERAGE TEST LOSS: 0.46088477969169617\n",
      "AVERAGE TRAIN LOSS: 0.3123875856399536\n",
      "AVERAGE TEST LOSS: 0.32018277049064636\n",
      "AVERAGE TRAIN LOSS: 0.2950461506843567\n",
      "AVERAGE TEST LOSS: 0.3891850709915161\n",
      "AVERAGE TRAIN LOSS: 0.3238784074783325\n",
      "AVERAGE TEST LOSS: 0.4498383402824402\n",
      "AVERAGE TRAIN LOSS: 0.37244608998298645\n",
      "AVERAGE TEST LOSS: 0.3448237478733063\n",
      "AVERAGE TRAIN LOSS: 0.2839755415916443\n",
      "AVERAGE TEST LOSS: 0.3161100447177887\n",
      "AVERAGE TRAIN LOSS: 0.3219268321990967\n",
      "AVERAGE TEST LOSS: 0.358734667301178\n",
      "AVERAGE TRAIN LOSS: 0.2943974733352661\n",
      "AVERAGE TEST LOSS: 0.352403461933136\n",
      "AVERAGE TRAIN LOSS: 0.3081570863723755\n",
      "AVERAGE TEST LOSS: 0.34206634759902954\n",
      "AVERAGE TRAIN LOSS: 0.2916398048400879\n",
      "AVERAGE TEST LOSS: 0.3708208501338959\n",
      "AVERAGE TRAIN LOSS: 0.3031361401081085\n",
      "AVERAGE TEST LOSS: 0.3343503475189209\n",
      "AVERAGE TRAIN LOSS: 0.32596468925476074\n",
      "AVERAGE TEST LOSS: 0.35795772075653076\n",
      "AVERAGE TRAIN LOSS: 0.36091557145118713\n",
      "AVERAGE TEST LOSS: 0.3220326602458954\n",
      "AVERAGE TRAIN LOSS: 0.3156653344631195\n",
      "AVERAGE TEST LOSS: 0.35422283411026\n",
      "AVERAGE TRAIN LOSS: 0.33766329288482666\n",
      "AVERAGE TEST LOSS: 0.3040335774421692\n",
      "AVERAGE TRAIN LOSS: 0.3799923360347748\n",
      "AVERAGE TEST LOSS: 0.3236124813556671\n",
      "AVERAGE TRAIN LOSS: 0.32554420828819275\n",
      "AVERAGE TEST LOSS: 0.35775548219680786\n",
      "AVERAGE TRAIN LOSS: 0.3578365743160248\n",
      "AVERAGE TEST LOSS: 0.3551464378833771\n",
      "AVERAGE TRAIN LOSS: 0.2993472218513489\n",
      "AVERAGE TEST LOSS: 0.35586321353912354\n",
      "AVERAGE TRAIN LOSS: 0.3554217517375946\n",
      "AVERAGE TEST LOSS: 0.34599533677101135\n",
      "AVERAGE TRAIN LOSS: 0.3203252851963043\n",
      "AVERAGE TEST LOSS: 0.3491778075695038\n",
      "AVERAGE TRAIN LOSS: 0.3202717900276184\n",
      "AVERAGE TEST LOSS: 0.35208290815353394\n",
      "AVERAGE TRAIN LOSS: 0.2986597716808319\n",
      "AVERAGE TEST LOSS: 0.3252597749233246\n",
      "AVERAGE TRAIN LOSS: 0.3268902599811554\n",
      "AVERAGE TEST LOSS: 0.3152269721031189\n",
      "AVERAGE TRAIN LOSS: 0.28533896803855896\n",
      "AVERAGE TEST LOSS: 0.31258487701416016\n",
      "AVERAGE TRAIN LOSS: 0.3159586191177368\n",
      "AVERAGE TEST LOSS: 0.31030476093292236\n",
      "AVERAGE TRAIN LOSS: 0.2971035838127136\n",
      "AVERAGE TEST LOSS: 0.28825363516807556\n",
      "AVERAGE TRAIN LOSS: 0.338049978017807\n",
      "AVERAGE TEST LOSS: 0.30668196082115173\n",
      "AVERAGE TRAIN LOSS: 0.3258019685745239\n",
      "AVERAGE TEST LOSS: 0.3114210367202759\n",
      "AVERAGE TRAIN LOSS: 0.30021053552627563\n",
      "AVERAGE TEST LOSS: 0.3254653811454773\n",
      "AVERAGE TRAIN LOSS: 0.2972281873226166\n",
      "AVERAGE TEST LOSS: 0.2798882722854614\n",
      "AVERAGE TRAIN LOSS: 0.30163705348968506\n",
      "AVERAGE TEST LOSS: 0.3141513466835022\n",
      "AVERAGE TRAIN LOSS: 0.28698495030403137\n",
      "AVERAGE TEST LOSS: 0.3057512938976288\n",
      "AVERAGE TRAIN LOSS: 0.2857183516025543\n",
      "AVERAGE TEST LOSS: 0.2836470901966095\n",
      "AVERAGE TRAIN LOSS: 0.2982162535190582\n",
      "AVERAGE TEST LOSS: 0.38542675971984863\n",
      "AVERAGE TRAIN LOSS: 0.29106763005256653\n",
      "AVERAGE TEST LOSS: 0.3147420883178711\n",
      "AVERAGE TRAIN LOSS: 0.3208518326282501\n",
      "AVERAGE TEST LOSS: 0.35438382625579834\n",
      "AVERAGE TRAIN LOSS: 0.2759496867656708\n",
      "AVERAGE TEST LOSS: 0.3394370675086975\n",
      "AVERAGE TRAIN LOSS: 0.3084350824356079\n",
      "AVERAGE TEST LOSS: 0.34317654371261597\n",
      "AVERAGE TRAIN LOSS: 0.3388391137123108\n",
      "AVERAGE TEST LOSS: 0.4449789524078369\n",
      "AVERAGE TRAIN LOSS: 0.38980424404144287\n",
      "AVERAGE TEST LOSS: 0.30570438504219055\n",
      "AVERAGE TRAIN LOSS: 0.31977009773254395\n",
      "AVERAGE TEST LOSS: 0.29950451850891113\n",
      "AVERAGE TRAIN LOSS: 0.2851055860519409\n",
      "AVERAGE TEST LOSS: 0.2757247984409332\n",
      "AVERAGE TRAIN LOSS: 0.3040010929107666\n",
      "AVERAGE TEST LOSS: 0.28096264600753784\n",
      "AVERAGE TRAIN LOSS: 0.2805488109588623\n",
      "AVERAGE TEST LOSS: 0.3300229609012604\n",
      "AVERAGE TRAIN LOSS: 0.2837776839733124\n",
      "AVERAGE TEST LOSS: 0.28005358576774597\n",
      "AVERAGE TRAIN LOSS: 0.27910324931144714\n",
      "AVERAGE TEST LOSS: 0.2829935848712921\n",
      "AVERAGE TRAIN LOSS: 0.28800711035728455\n",
      "AVERAGE TEST LOSS: 0.3240489959716797\n",
      "AVERAGE TRAIN LOSS: 0.2895367741584778\n",
      "AVERAGE TEST LOSS: 0.2765524089336395\n",
      "AVERAGE TRAIN LOSS: 0.3294963836669922\n",
      "AVERAGE TEST LOSS: 0.2952535152435303\n",
      "AVERAGE TRAIN LOSS: 0.34721270203590393\n",
      "AVERAGE TEST LOSS: 0.25884294509887695\n",
      "AVERAGE TRAIN LOSS: 0.2885114252567291\n",
      "AVERAGE TEST LOSS: 0.2573432922363281\n",
      "AVERAGE TRAIN LOSS: 0.3097589910030365\n",
      "AVERAGE TEST LOSS: 0.3191392123699188\n",
      "AVERAGE TRAIN LOSS: 0.38188058137893677\n",
      "AVERAGE TEST LOSS: 0.3740184009075165\n",
      "AVERAGE TRAIN LOSS: 0.33338645100593567\n",
      "AVERAGE TEST LOSS: 0.40446603298187256\n",
      "AVERAGE TRAIN LOSS: 0.3388543725013733\n",
      "AVERAGE TEST LOSS: 0.25654369592666626\n",
      "AVERAGE TRAIN LOSS: 0.30278798937797546\n",
      "AVERAGE TEST LOSS: 0.28914737701416016\n",
      "AVERAGE TRAIN LOSS: 0.2990473508834839\n",
      "AVERAGE TEST LOSS: 0.27266770601272583\n",
      "AVERAGE TRAIN LOSS: 0.3869438171386719\n",
      "AVERAGE TEST LOSS: 0.28226912021636963\n",
      "AVERAGE TRAIN LOSS: 0.3005131483078003\n",
      "AVERAGE TEST LOSS: 0.26707905530929565\n",
      "AVERAGE TRAIN LOSS: 0.2857659161090851\n",
      "AVERAGE TEST LOSS: 0.29661864042282104\n",
      "AVERAGE TRAIN LOSS: 0.32251808047294617\n",
      "AVERAGE TEST LOSS: 0.26414886116981506\n",
      "AVERAGE TRAIN LOSS: 0.28896769881248474\n",
      "AVERAGE TEST LOSS: 0.2697632908821106\n",
      "AVERAGE TRAIN LOSS: 0.2815205156803131\n",
      "AVERAGE TEST LOSS: 0.2946503758430481\n",
      "AVERAGE TRAIN LOSS: 0.2953290045261383\n",
      "AVERAGE TEST LOSS: 0.2837602198123932\n",
      "AVERAGE TRAIN LOSS: 0.2772184908390045\n",
      "AVERAGE TEST LOSS: 0.25750982761383057\n",
      "AVERAGE TRAIN LOSS: 0.3093259036540985\n",
      "AVERAGE TEST LOSS: 0.3490525186061859\n",
      "AVERAGE TRAIN LOSS: 0.3377106189727783\n",
      "AVERAGE TEST LOSS: 0.3263358175754547\n",
      "AVERAGE TRAIN LOSS: 0.2943715751171112\n",
      "AVERAGE TEST LOSS: 0.3434225916862488\n",
      "AVERAGE TRAIN LOSS: 0.3240691125392914\n",
      "AVERAGE TEST LOSS: 0.3367641866207123\n",
      "AVERAGE TRAIN LOSS: 0.3257592022418976\n",
      "AVERAGE TEST LOSS: 0.3211420178413391\n",
      "AVERAGE TRAIN LOSS: 0.31215333938598633\n",
      "AVERAGE TEST LOSS: 0.33342647552490234\n",
      "AVERAGE TRAIN LOSS: 0.31512200832366943\n",
      "AVERAGE TEST LOSS: 0.26156264543533325\n",
      "AVERAGE TRAIN LOSS: 0.28608012199401855\n",
      "AVERAGE TEST LOSS: 0.26022976636886597\n",
      "AVERAGE TRAIN LOSS: 0.29142358899116516\n",
      "AVERAGE TEST LOSS: 0.2634608745574951\n"
     ]
    }
   ],
   "source": [
    "### TRAINING LOOP\n",
    "num_epochs = 300\n",
    "train_loss_log = []\n",
    "test_loss_log = []\n",
    "\n",
    "for epoch_num in range(num_epochs):\n",
    "    #print('#################')\n",
    "    #print(f'# EPOCH {epoch_num}')\n",
    "    #print('#################')\n",
    "\n",
    "    ### TRAIN\n",
    "    train_loss= []\n",
    "    net.train() # Training mode (e.g. enable dropout, batchnorm updates,...)\n",
    "    for sample_batched in train_dataloader:\n",
    "        # Move data to device\n",
    "        x_batch = sample_batched[0].to(device)\n",
    "        label_batch = sample_batched[1].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        out = net(x_batch)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(out, label_batch)\n",
    "\n",
    "        # Backpropagation\n",
    "        net.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Save train loss for this batch\n",
    "        loss_batch = loss.detach().cpu().numpy()\n",
    "        train_loss.append(loss_batch)\n",
    "        \n",
    "\n",
    "    # Save average train loss\n",
    "    train_loss = np.mean(train_loss)\n",
    "    print(f\"AVERAGE TRAIN LOSS: {train_loss}\")\n",
    "    train_loss_log.append(train_loss)\n",
    "    \n",
    "    ### VALIDATION\n",
    "    test_loss= []\n",
    "    net.eval() # Evaluation mode (e.g. disable dropout, batchnorm,...)\n",
    "    with torch.no_grad(): # Disable gradient tracking\n",
    "        for sample_batched in test_dataloader:\n",
    "            # Move data to device\n",
    "            x_batch = sample_batched[0].to(device)\n",
    "            label_batch = sample_batched[1].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            out = net(x_batch)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_fn(out, label_batch)\n",
    "\n",
    "            # Save val loss for this batch\n",
    "            loss_batch = loss.detach().cpu().numpy()\n",
    "            test_loss.append(loss_batch)\n",
    "\n",
    "        # Save average validation loss\n",
    "        test_loss = np.mean(test_loss)\n",
    "        print(f\"AVERAGE TEST LOSS: {np.mean(test_loss)}\")\n",
    "        test_loss_log.append(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dda85735-a676-4ec7-85b1-34112eb83eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE TEST LOSS: 0.2634608745574951\n"
     ]
    }
   ],
   "source": [
    "all_inputs = []\n",
    "all_outputs = []\n",
    "all_labels = []\n",
    "net.eval() # Evaluation mode (e.g. disable dropout)\n",
    "with torch.no_grad(): # Disable gradient tracking\n",
    "    for sample_batched in test_dataloader:\n",
    "        # Move data to device\n",
    "        x_batch = sample_batched[0].to(device)\n",
    "        label_batch = sample_batched[1].to(device)\n",
    "        # Forward pass\n",
    "        out = net(x_batch)\n",
    "        # Save outputs and labels\n",
    "        all_inputs.append(x_batch)\n",
    "        all_outputs.append(out)\n",
    "        all_labels.append(label_batch)\n",
    "# Concatenate all the outputs and labels in a single tensor\n",
    "all_inputs  = torch.cat(all_inputs)\n",
    "all_outputs = torch.cat(all_outputs)\n",
    "all_labels  = torch.cat(all_labels)\n",
    "\n",
    "test_loss = loss_fn(all_outputs, all_labels)\n",
    "print(f\"AVERAGE TEST LOSS: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8bf4e8a4-c2de-4e17-a709-83c97fbadcd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1])\n"
     ]
    }
   ],
   "source": [
    "X = np.zeros(len(train_data), dtype=np.float32)\n",
    "\n",
    "y = np.zeros(len(train_data), dtype=np.float32)\n",
    "\n",
    "#store the training /test data into ndarrays\n",
    "\n",
    "for sample_index in range(len(train_data)):\n",
    "    X[sample_index] = train_data.iloc[sample_index]['input']\n",
    "    y[sample_index] = train_data.iloc[sample_index]['label']\n",
    "\n",
    "X = X.reshape((len(train_data),1))\n",
    "y = y.reshape((len(train_data),1))\n",
    "\n",
    "X = torch.from_numpy(X)\n",
    "y = torch.from_numpy(y)\n",
    "\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8037c68c-f66b-4a3a-856c-5c09a7ba9a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1])\n"
     ]
    }
   ],
   "source": [
    "X = X.reshape((len(train_data),1))\n",
    "y = y.reshape((len(train_data),1))\n",
    "\n",
    "X = torch.from_numpy(X)\n",
    "y = torch.from_numpy(y)\n",
    "\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "22e47b97-f07c-4db4-969f-60dc8348c0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network initialized\n"
     ]
    }
   ],
   "source": [
    "from skorch import NeuralNetRegressor\n",
    "\n",
    "net_skorch = NeuralNetRegressor(\n",
    "    Net(Ni, Nh1, Nh2, No),\n",
    "    max_epochs=300,\n",
    "    lr=0.001,\n",
    "    batch_size = 4,\n",
    "    optimizer = optim.Adam\n",
    "#            device='cuda',  # uncomment this to train with CUDA\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ed8952ac-3322-4066-b399-4e540fa29e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-4.7879)\n"
     ]
    }
   ],
   "source": [
    "print(X[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7bb2c6f7-8b86-4b6d-9d5c-9361b3840348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m3.7405\u001b[0m       \u001b[32m10.5492\u001b[0m  0.0811\n",
      "      2        4.0107        \u001b[32m5.9091\u001b[0m  0.0922\n",
      "      3        \u001b[36m2.8802\u001b[0m        \u001b[32m4.3897\u001b[0m  0.0780\n",
      "      4        \u001b[36m2.6328\u001b[0m        \u001b[32m4.0407\u001b[0m  0.0908\n",
      "      5        \u001b[36m2.6260\u001b[0m        \u001b[32m3.7506\u001b[0m  0.0799\n",
      "      6        \u001b[36m2.6040\u001b[0m        \u001b[32m3.6838\u001b[0m  0.1002\n",
      "      7        2.6069        \u001b[32m3.6628\u001b[0m  0.0914\n",
      "      8        \u001b[36m2.6003\u001b[0m        \u001b[32m3.6583\u001b[0m  0.0893\n",
      "      9        \u001b[36m2.5910\u001b[0m        3.6606  0.0788\n",
      "     10        \u001b[36m2.5803\u001b[0m        3.6638  0.1041\n",
      "     11        \u001b[36m2.5688\u001b[0m        3.6677  0.0804\n",
      "     12        \u001b[36m2.5569\u001b[0m        3.6722  0.0902\n",
      "     13        \u001b[36m2.5446\u001b[0m        3.6773  0.0834\n",
      "     14        \u001b[36m2.5318\u001b[0m        3.6832  0.0980\n",
      "     15        \u001b[36m2.5185\u001b[0m        3.6898  0.0800\n",
      "     16        \u001b[36m2.5047\u001b[0m        3.6971  0.0804\n",
      "     17        \u001b[36m2.4903\u001b[0m        3.7052  0.0978\n",
      "     18        \u001b[36m2.4753\u001b[0m        3.7139  0.0778\n",
      "     19        \u001b[36m2.4596\u001b[0m        3.7234  0.0797\n",
      "     20        \u001b[36m2.4433\u001b[0m        3.7337  0.1067\n",
      "     21        \u001b[36m2.4262\u001b[0m        3.7447  0.0814\n",
      "     22        \u001b[36m2.4084\u001b[0m        3.7565  0.1007\n",
      "     23        \u001b[36m2.3898\u001b[0m        3.7691  0.0949\n",
      "     24        \u001b[36m2.3704\u001b[0m        3.7825  0.0892\n",
      "     25        \u001b[36m2.3501\u001b[0m        3.7967  0.0993\n",
      "     26        \u001b[36m2.3290\u001b[0m        3.8118  0.0956\n",
      "     27        \u001b[36m2.3071\u001b[0m        3.8276  0.0877\n",
      "     28        \u001b[36m2.2843\u001b[0m        3.8443  0.0834\n",
      "     29        \u001b[36m2.2607\u001b[0m        3.8617  0.0804\n",
      "     30        \u001b[36m2.2364\u001b[0m        3.8799  0.0887\n",
      "     31        \u001b[36m2.2112\u001b[0m        3.8987  0.0835\n",
      "     32        \u001b[36m2.1854\u001b[0m        3.9182  0.0932\n",
      "     33        \u001b[36m2.1588\u001b[0m        3.9383  0.0607\n",
      "     34        \u001b[36m2.1317\u001b[0m        3.9589  0.0765\n",
      "     35        \u001b[36m2.1038\u001b[0m        3.9800  0.0924\n",
      "     36        \u001b[36m2.0754\u001b[0m        4.0015  0.0887\n",
      "     37        \u001b[36m2.0465\u001b[0m        4.0234  0.0942\n",
      "     38        \u001b[36m2.0171\u001b[0m        4.0455  0.0750\n",
      "     39        \u001b[36m1.9872\u001b[0m        4.0678  0.0804\n",
      "     40        \u001b[36m1.9569\u001b[0m        4.0902  0.0935\n",
      "     41        \u001b[36m1.9263\u001b[0m        4.1127  0.0898\n",
      "     42        \u001b[36m1.8953\u001b[0m        4.1352  0.0808\n",
      "     43        \u001b[36m1.8640\u001b[0m        4.1576  0.0811\n",
      "     44        \u001b[36m1.8325\u001b[0m        4.1798  0.0815\n",
      "     45        \u001b[36m1.8008\u001b[0m        4.2017  0.0816\n",
      "     46        \u001b[36m1.7690\u001b[0m        4.2233  0.0927\n",
      "     47        \u001b[36m1.7371\u001b[0m        4.2442  0.0892\n",
      "     48        \u001b[36m1.7051\u001b[0m        4.2646  0.0845\n",
      "     49        \u001b[36m1.6732\u001b[0m        4.2841  0.0888\n",
      "     50        \u001b[36m1.6414\u001b[0m        4.3027  0.0761\n",
      "     51        \u001b[36m1.6097\u001b[0m        4.3201  0.0850\n",
      "     52        \u001b[36m1.5781\u001b[0m        4.3362  0.0833\n",
      "     53        \u001b[36m1.5469\u001b[0m        4.3508  0.1508\n",
      "     54        \u001b[36m1.5160\u001b[0m        4.3638  0.0998\n",
      "     55        \u001b[36m1.4855\u001b[0m        4.3748  0.0790\n",
      "     56        \u001b[36m1.4554\u001b[0m        4.3838  0.0760\n",
      "     57        \u001b[36m1.4258\u001b[0m        4.3906  0.0746\n",
      "     58        \u001b[36m1.3968\u001b[0m        4.3949  0.0928\n",
      "     59        \u001b[36m1.3685\u001b[0m        4.3967  0.0704\n",
      "     60        \u001b[36m1.3408\u001b[0m        4.3959  0.0909\n",
      "     61        \u001b[36m1.3138\u001b[0m        4.3922  0.0859\n",
      "     62        \u001b[36m1.2876\u001b[0m        4.3857  0.0708\n",
      "     63        \u001b[36m1.2621\u001b[0m        4.3764  0.0699\n",
      "     64        \u001b[36m1.2374\u001b[0m        4.3642  0.0681\n",
      "     65        \u001b[36m1.2135\u001b[0m        4.3493  0.0821\n",
      "     66        \u001b[36m1.1904\u001b[0m        4.3316  0.0910\n",
      "     67        \u001b[36m1.1680\u001b[0m        4.3115  0.0795\n",
      "     68        \u001b[36m1.1465\u001b[0m        4.2890  0.0911\n",
      "     69        \u001b[36m1.1257\u001b[0m        4.2644  0.0911\n",
      "     70        \u001b[36m1.1057\u001b[0m        4.2379  0.0887\n",
      "     71        \u001b[36m1.0863\u001b[0m        4.2097  0.1029\n",
      "     72        \u001b[36m1.0677\u001b[0m        4.1801  0.0859\n",
      "     73        \u001b[36m1.0496\u001b[0m        4.1494  0.0766\n",
      "     74        \u001b[36m1.0323\u001b[0m        4.1179  0.0828\n",
      "     75        \u001b[36m1.0155\u001b[0m        4.0857  0.0943\n",
      "     76        \u001b[36m0.9993\u001b[0m        4.0531  0.1002\n",
      "     77        \u001b[36m0.9836\u001b[0m        4.0203  0.0830\n",
      "     78        \u001b[36m0.9684\u001b[0m        3.9876  0.0729\n",
      "     79        \u001b[36m0.9537\u001b[0m        3.9550  0.1003\n",
      "     80        \u001b[36m0.9395\u001b[0m        3.9226  0.0875\n",
      "     81        \u001b[36m0.9256\u001b[0m        3.8907  0.0846\n",
      "     82        \u001b[36m0.9122\u001b[0m        3.8592  0.0817\n",
      "     83        \u001b[36m0.8991\u001b[0m        3.8281  0.0752\n",
      "     84        \u001b[36m0.8864\u001b[0m        3.7975  0.0817\n",
      "     85        \u001b[36m0.8741\u001b[0m        3.7674  0.0864\n",
      "     86        \u001b[36m0.8620\u001b[0m        3.7379  0.0838\n",
      "     87        \u001b[36m0.8502\u001b[0m        3.7088  0.0814\n",
      "     88        \u001b[36m0.8387\u001b[0m        3.6803  0.0717\n",
      "     89        \u001b[36m0.8274\u001b[0m        \u001b[32m3.6524\u001b[0m  0.0828\n",
      "     90        \u001b[36m0.8164\u001b[0m        \u001b[32m3.6251\u001b[0m  0.0909\n",
      "     91        \u001b[36m0.8056\u001b[0m        \u001b[32m3.5984\u001b[0m  0.0752\n",
      "     92        \u001b[36m0.7950\u001b[0m        \u001b[32m3.5723\u001b[0m  0.0838\n",
      "     93        \u001b[36m0.7847\u001b[0m        \u001b[32m3.5468\u001b[0m  0.0778\n",
      "     94        \u001b[36m0.7746\u001b[0m        \u001b[32m3.5219\u001b[0m  0.0917\n",
      "     95        \u001b[36m0.7647\u001b[0m        \u001b[32m3.4976\u001b[0m  0.0903\n",
      "     96        \u001b[36m0.7550\u001b[0m        \u001b[32m3.4738\u001b[0m  0.1022\n",
      "     97        \u001b[36m0.7455\u001b[0m        \u001b[32m3.4507\u001b[0m  0.0574\n",
      "     98        \u001b[36m0.7362\u001b[0m        \u001b[32m3.4281\u001b[0m  0.0595\n",
      "     99        \u001b[36m0.7271\u001b[0m        \u001b[32m3.4062\u001b[0m  0.0609\n",
      "    100        \u001b[36m0.7181\u001b[0m        \u001b[32m3.3848\u001b[0m  0.0622\n",
      "    101        \u001b[36m0.7094\u001b[0m        \u001b[32m3.3640\u001b[0m  0.0680\n",
      "    102        \u001b[36m0.7009\u001b[0m        \u001b[32m3.3437\u001b[0m  0.0645\n",
      "    103        \u001b[36m0.6925\u001b[0m        \u001b[32m3.3240\u001b[0m  0.0627\n",
      "    104        \u001b[36m0.6843\u001b[0m        \u001b[32m3.3048\u001b[0m  0.0619\n",
      "    105        \u001b[36m0.6763\u001b[0m        \u001b[32m3.2860\u001b[0m  0.0679\n",
      "    106        \u001b[36m0.6685\u001b[0m        \u001b[32m3.2678\u001b[0m  0.0617\n",
      "    107        \u001b[36m0.6608\u001b[0m        \u001b[32m3.2500\u001b[0m  0.0630\n",
      "    108        \u001b[36m0.6533\u001b[0m        \u001b[32m3.2327\u001b[0m  0.0890\n",
      "    109        \u001b[36m0.6460\u001b[0m        \u001b[32m3.2159\u001b[0m  0.0605\n",
      "    110        \u001b[36m0.6388\u001b[0m        \u001b[32m3.1994\u001b[0m  0.0741\n",
      "    111        \u001b[36m0.6318\u001b[0m        \u001b[32m3.1833\u001b[0m  0.0890\n",
      "    112        \u001b[36m0.6250\u001b[0m        \u001b[32m3.1677\u001b[0m  0.0904\n",
      "    113        \u001b[36m0.6183\u001b[0m        \u001b[32m3.1523\u001b[0m  0.1016\n",
      "    114        \u001b[36m0.6118\u001b[0m        \u001b[32m3.1374\u001b[0m  0.0896\n",
      "    115        \u001b[36m0.6054\u001b[0m        \u001b[32m3.1227\u001b[0m  0.0984\n",
      "    116        \u001b[36m0.5992\u001b[0m        \u001b[32m3.1083\u001b[0m  0.0991\n",
      "    117        \u001b[36m0.5931\u001b[0m        \u001b[32m3.0941\u001b[0m  0.0979\n",
      "    118        \u001b[36m0.5871\u001b[0m        \u001b[32m3.0802\u001b[0m  0.0972\n",
      "    119        \u001b[36m0.5813\u001b[0m        \u001b[32m3.0664\u001b[0m  0.0791\n",
      "    120        \u001b[36m0.5757\u001b[0m        \u001b[32m3.0528\u001b[0m  0.0809\n",
      "    121        \u001b[36m0.5701\u001b[0m        \u001b[32m3.0394\u001b[0m  0.0986\n",
      "    122        \u001b[36m0.5647\u001b[0m        \u001b[32m3.0261\u001b[0m  0.1002\n",
      "    123        \u001b[36m0.5594\u001b[0m        \u001b[32m3.0128\u001b[0m  0.0973\n",
      "    124        \u001b[36m0.5542\u001b[0m        \u001b[32m2.9997\u001b[0m  0.0774\n",
      "    125        \u001b[36m0.5492\u001b[0m        \u001b[32m2.9866\u001b[0m  0.0687\n",
      "    126        \u001b[36m0.5442\u001b[0m        \u001b[32m2.9735\u001b[0m  0.0561\n",
      "    127        \u001b[36m0.5394\u001b[0m        \u001b[32m2.9604\u001b[0m  0.0654\n",
      "    128        \u001b[36m0.5346\u001b[0m        \u001b[32m2.9474\u001b[0m  0.0854\n",
      "    129        \u001b[36m0.5300\u001b[0m        \u001b[32m2.9343\u001b[0m  0.0863\n",
      "    130        \u001b[36m0.5255\u001b[0m        \u001b[32m2.9213\u001b[0m  0.0813\n",
      "    131        \u001b[36m0.5210\u001b[0m        \u001b[32m2.9081\u001b[0m  0.1011\n",
      "    132        \u001b[36m0.5167\u001b[0m        \u001b[32m2.8950\u001b[0m  0.0906\n",
      "    133        \u001b[36m0.5125\u001b[0m        \u001b[32m2.8818\u001b[0m  0.0938\n",
      "    134        \u001b[36m0.5083\u001b[0m        \u001b[32m2.8685\u001b[0m  0.0951\n",
      "    135        \u001b[36m0.5042\u001b[0m        \u001b[32m2.8552\u001b[0m  0.0947\n",
      "    136        \u001b[36m0.5002\u001b[0m        \u001b[32m2.8418\u001b[0m  0.0992\n",
      "    137        \u001b[36m0.4963\u001b[0m        \u001b[32m2.8283\u001b[0m  0.0815\n",
      "    138        \u001b[36m0.4925\u001b[0m        \u001b[32m2.8148\u001b[0m  0.0643\n",
      "    139        \u001b[36m0.4888\u001b[0m        \u001b[32m2.8011\u001b[0m  0.0839\n",
      "    140        \u001b[36m0.4851\u001b[0m        \u001b[32m2.7874\u001b[0m  0.0898\n",
      "    141        \u001b[36m0.4815\u001b[0m        \u001b[32m2.7735\u001b[0m  0.0817\n",
      "    142        \u001b[36m0.4779\u001b[0m        \u001b[32m2.7595\u001b[0m  0.0920\n",
      "    143        \u001b[36m0.4745\u001b[0m        \u001b[32m2.7454\u001b[0m  0.0842\n",
      "    144        \u001b[36m0.4711\u001b[0m        \u001b[32m2.7312\u001b[0m  0.0921\n",
      "    145        \u001b[36m0.4677\u001b[0m        \u001b[32m2.7169\u001b[0m  0.0880\n",
      "    146        \u001b[36m0.4644\u001b[0m        \u001b[32m2.7024\u001b[0m  0.0923\n",
      "    147        \u001b[36m0.4612\u001b[0m        \u001b[32m2.6878\u001b[0m  0.0837\n",
      "    148        \u001b[36m0.4580\u001b[0m        \u001b[32m2.6731\u001b[0m  0.0883\n",
      "    149        \u001b[36m0.4549\u001b[0m        \u001b[32m2.6582\u001b[0m  0.0986\n",
      "    150        \u001b[36m0.4518\u001b[0m        \u001b[32m2.6432\u001b[0m  0.0816\n",
      "    151        \u001b[36m0.4488\u001b[0m        \u001b[32m2.6281\u001b[0m  0.0842\n",
      "    152        \u001b[36m0.4459\u001b[0m        \u001b[32m2.6128\u001b[0m  0.1040\n",
      "    153        \u001b[36m0.4429\u001b[0m        \u001b[32m2.5973\u001b[0m  0.0973\n",
      "    154        \u001b[36m0.4400\u001b[0m        \u001b[32m2.5817\u001b[0m  0.0896\n",
      "    155        \u001b[36m0.4372\u001b[0m        \u001b[32m2.5660\u001b[0m  0.0905\n",
      "    156        \u001b[36m0.4344\u001b[0m        \u001b[32m2.5501\u001b[0m  0.0898\n",
      "    157        \u001b[36m0.4317\u001b[0m        \u001b[32m2.5340\u001b[0m  0.0883\n",
      "    158        \u001b[36m0.4290\u001b[0m        \u001b[32m2.5178\u001b[0m  0.0937\n",
      "    159        \u001b[36m0.4263\u001b[0m        \u001b[32m2.5014\u001b[0m  0.0830\n",
      "    160        \u001b[36m0.4237\u001b[0m        \u001b[32m2.4849\u001b[0m  0.0787\n",
      "    161        \u001b[36m0.4211\u001b[0m        \u001b[32m2.4682\u001b[0m  0.0877\n",
      "    162        \u001b[36m0.4185\u001b[0m        \u001b[32m2.4513\u001b[0m  0.0805\n",
      "    163        \u001b[36m0.4160\u001b[0m        \u001b[32m2.4343\u001b[0m  0.0900\n",
      "    164        \u001b[36m0.4135\u001b[0m        \u001b[32m2.4171\u001b[0m  0.0938\n",
      "    165        \u001b[36m0.4110\u001b[0m        \u001b[32m2.3998\u001b[0m  0.0890\n",
      "    166        \u001b[36m0.4086\u001b[0m        \u001b[32m2.3823\u001b[0m  0.0998\n",
      "    167        \u001b[36m0.4062\u001b[0m        \u001b[32m2.3646\u001b[0m  0.0826\n",
      "    168        \u001b[36m0.4038\u001b[0m        \u001b[32m2.3468\u001b[0m  0.0912\n",
      "    169        \u001b[36m0.4015\u001b[0m        \u001b[32m2.3289\u001b[0m  0.0783\n",
      "    170        \u001b[36m0.3992\u001b[0m        \u001b[32m2.3107\u001b[0m  0.0781\n",
      "    171        \u001b[36m0.3969\u001b[0m        \u001b[32m2.2924\u001b[0m  0.0870\n",
      "    172        \u001b[36m0.3947\u001b[0m        \u001b[32m2.2740\u001b[0m  0.0821\n",
      "    173        \u001b[36m0.3924\u001b[0m        \u001b[32m2.2554\u001b[0m  0.0988\n",
      "    174        \u001b[36m0.3902\u001b[0m        \u001b[32m2.2366\u001b[0m  0.0901\n",
      "    175        \u001b[36m0.3880\u001b[0m        \u001b[32m2.2177\u001b[0m  0.0984\n",
      "    176        \u001b[36m0.3859\u001b[0m        \u001b[32m2.1986\u001b[0m  0.0701\n",
      "    177        \u001b[36m0.3837\u001b[0m        \u001b[32m2.1794\u001b[0m  0.0706\n",
      "    178        \u001b[36m0.3816\u001b[0m        \u001b[32m2.1600\u001b[0m  0.0802\n",
      "    179        \u001b[36m0.3794\u001b[0m        \u001b[32m2.1405\u001b[0m  0.0966\n",
      "    180        \u001b[36m0.3773\u001b[0m        \u001b[32m2.1209\u001b[0m  0.1037\n",
      "    181        \u001b[36m0.3752\u001b[0m        \u001b[32m2.1010\u001b[0m  0.0795\n",
      "    182        \u001b[36m0.3730\u001b[0m        \u001b[32m2.0811\u001b[0m  0.0833\n",
      "    183        \u001b[36m0.3709\u001b[0m        \u001b[32m2.0610\u001b[0m  0.0980\n",
      "    184        \u001b[36m0.3688\u001b[0m        \u001b[32m2.0408\u001b[0m  0.0914\n",
      "    185        \u001b[36m0.3666\u001b[0m        \u001b[32m2.0204\u001b[0m  0.0917\n",
      "    186        \u001b[36m0.3645\u001b[0m        \u001b[32m1.9999\u001b[0m  0.0659\n",
      "    187        \u001b[36m0.3624\u001b[0m        \u001b[32m1.9793\u001b[0m  0.0701\n",
      "    188        \u001b[36m0.3602\u001b[0m        \u001b[32m1.9586\u001b[0m  0.0715\n",
      "    189        \u001b[36m0.3581\u001b[0m        \u001b[32m1.9377\u001b[0m  0.0767\n",
      "    190        \u001b[36m0.3559\u001b[0m        \u001b[32m1.9168\u001b[0m  0.0887\n",
      "    191        \u001b[36m0.3537\u001b[0m        \u001b[32m1.8958\u001b[0m  0.0862\n",
      "    192        \u001b[36m0.3516\u001b[0m        \u001b[32m1.8746\u001b[0m  0.0783\n",
      "    193        \u001b[36m0.3494\u001b[0m        \u001b[32m1.8534\u001b[0m  0.0895\n",
      "    194        \u001b[36m0.3472\u001b[0m        \u001b[32m1.8321\u001b[0m  0.0925\n",
      "    195        \u001b[36m0.3450\u001b[0m        \u001b[32m1.8108\u001b[0m  0.0909\n",
      "    196        \u001b[36m0.3429\u001b[0m        \u001b[32m1.7894\u001b[0m  0.1625\n",
      "    197        \u001b[36m0.3407\u001b[0m        \u001b[32m1.7679\u001b[0m  0.0791\n",
      "    198        \u001b[36m0.3385\u001b[0m        \u001b[32m1.7464\u001b[0m  0.0872\n",
      "    199        \u001b[36m0.3363\u001b[0m        \u001b[32m1.7249\u001b[0m  0.0919\n",
      "    200        \u001b[36m0.3342\u001b[0m        \u001b[32m1.7034\u001b[0m  0.0903\n",
      "    201        \u001b[36m0.3320\u001b[0m        \u001b[32m1.6819\u001b[0m  0.0678\n",
      "    202        \u001b[36m0.3298\u001b[0m        \u001b[32m1.6603\u001b[0m  0.0864\n",
      "    203        \u001b[36m0.3277\u001b[0m        \u001b[32m1.6388\u001b[0m  0.0992\n",
      "    204        \u001b[36m0.3255\u001b[0m        \u001b[32m1.6173\u001b[0m  0.0931\n",
      "    205        \u001b[36m0.3234\u001b[0m        \u001b[32m1.5958\u001b[0m  0.0867\n",
      "    206        \u001b[36m0.3212\u001b[0m        \u001b[32m1.5744\u001b[0m  0.0917\n",
      "    207        \u001b[36m0.3191\u001b[0m        \u001b[32m1.5530\u001b[0m  0.0921\n",
      "    208        \u001b[36m0.3170\u001b[0m        \u001b[32m1.5317\u001b[0m  0.0885\n",
      "    209        \u001b[36m0.3149\u001b[0m        \u001b[32m1.5105\u001b[0m  0.0819\n",
      "    210        \u001b[36m0.3128\u001b[0m        \u001b[32m1.4893\u001b[0m  0.0592\n",
      "    211        \u001b[36m0.3108\u001b[0m        \u001b[32m1.4683\u001b[0m  0.0879\n",
      "    212        \u001b[36m0.3087\u001b[0m        \u001b[32m1.4474\u001b[0m  0.0705\n",
      "    213        \u001b[36m0.3067\u001b[0m        \u001b[32m1.4265\u001b[0m  0.0619\n",
      "    214        \u001b[36m0.3047\u001b[0m        \u001b[32m1.4059\u001b[0m  0.0624\n",
      "    215        \u001b[36m0.3027\u001b[0m        \u001b[32m1.3853\u001b[0m  0.0848\n",
      "    216        \u001b[36m0.3007\u001b[0m        \u001b[32m1.3650\u001b[0m  0.0748\n",
      "    217        \u001b[36m0.2987\u001b[0m        \u001b[32m1.3446\u001b[0m  0.0816\n",
      "    218        \u001b[36m0.2968\u001b[0m        \u001b[32m1.3248\u001b[0m  0.0700\n",
      "    219        \u001b[36m0.2949\u001b[0m        \u001b[32m1.3046\u001b[0m  0.0722\n",
      "    220        \u001b[36m0.2930\u001b[0m        \u001b[32m1.2854\u001b[0m  0.0695\n",
      "    221        \u001b[36m0.2912\u001b[0m        \u001b[32m1.2650\u001b[0m  0.0835\n",
      "    222        \u001b[36m0.2893\u001b[0m        \u001b[32m1.2475\u001b[0m  0.0681\n",
      "    223        \u001b[36m0.2876\u001b[0m        \u001b[32m1.2252\u001b[0m  0.0776\n",
      "    224        \u001b[36m0.2856\u001b[0m        \u001b[32m1.2127\u001b[0m  0.0819\n",
      "    225        \u001b[36m0.2842\u001b[0m        \u001b[32m1.1824\u001b[0m  0.0740\n",
      "    226        \u001b[36m0.2820\u001b[0m        1.1893  0.0669\n",
      "    227        \u001b[36m0.2817\u001b[0m        \u001b[32m1.1289\u001b[0m  0.0821\n",
      "    228        \u001b[36m0.2786\u001b[0m        1.2379  0.0731\n",
      "    229        0.2861        \u001b[32m1.1249\u001b[0m  0.1373\n",
      "    230        0.2925        1.8523  0.0897\n",
      "    231        0.3676        1.4208  0.0809\n",
      "    232        0.3819        2.0923  0.0623\n",
      "    233        0.4241        \u001b[32m1.1028\u001b[0m  0.0773\n",
      "    234        0.2941        1.2889  0.0675\n",
      "    235        0.2864        1.1105  0.0709\n",
      "    236        0.2881        1.8394  0.0626\n",
      "    237        0.3421        1.3957  0.0637\n",
      "    238        0.3541        2.3785  0.0695\n",
      "    239        0.4098        1.4541  0.0677\n",
      "    240        0.3551        2.8053  0.0657\n",
      "    241        0.4228        1.8883  0.0990\n",
      "    242        0.4135        3.6469  0.0672\n",
      "    243        0.4866        1.9181  0.0730\n",
      "    244        0.4226        3.6515  0.0658\n",
      "    245        0.4643        1.8989  0.0657\n",
      "    246        0.4339        3.0656  0.0644\n",
      "    247        0.4080        1.5032  0.0673\n",
      "    248        0.3736        2.2067  0.0706\n",
      "    249        0.3339        1.2654  0.0907\n",
      "    250        0.3217        1.6954  0.0838\n",
      "    251        0.2935        1.1476  0.0697\n",
      "    252        0.2906        1.4543  0.0774\n",
      "    253        \u001b[36m0.2769\u001b[0m        \u001b[32m1.0950\u001b[0m  0.0802\n",
      "    254        0.2781        1.3460  0.0878\n",
      "    255        \u001b[36m0.2704\u001b[0m        \u001b[32m1.0604\u001b[0m  0.0735\n",
      "    256        0.2724        1.2929  0.0989\n",
      "    257        \u001b[36m0.2675\u001b[0m        \u001b[32m1.0349\u001b[0m  0.0646\n",
      "    258        0.2701        1.2752  0.1010\n",
      "    259        \u001b[36m0.2668\u001b[0m        \u001b[32m1.0184\u001b[0m  0.0818\n",
      "    260        0.2701        1.2900  0.0656\n",
      "    261        0.2683        \u001b[32m1.0154\u001b[0m  0.0802\n",
      "    262        0.2726        1.3446  0.0718\n",
      "    263        0.2727        1.0343  0.0615\n",
      "    264        0.2784        1.4521  0.0727\n",
      "    265        0.2813        1.0848  0.1000\n",
      "    266        0.2886        1.6217  0.0809\n",
      "    267        0.2951        1.1685  0.0690\n",
      "    268        0.3033        1.8352  0.0828\n",
      "    269        0.3125        1.2635  0.0911\n",
      "    270        0.3196        2.0252  0.0693\n",
      "    271        0.3276        1.3255  0.0680\n",
      "    272        0.3317        2.1007  0.0789\n",
      "    273        0.3326        1.3195  0.0645\n",
      "    274        0.3339        2.0239  0.0666\n",
      "    275        0.3249        1.2524  0.0579\n",
      "    276        0.3253        1.8470  0.0903\n",
      "    277        0.3096        1.1635  0.0867\n",
      "    278        0.3109        1.6566  0.0894\n",
      "    279        0.2939        1.0867  0.0739\n",
      "    280        0.2968        1.5050  0.0762\n",
      "    281        0.2821        1.0323  0.0611\n",
      "    282        0.2861        1.4030  0.0879\n",
      "    283        0.2745        \u001b[32m0.9975\u001b[0m  0.0954\n",
      "    284        0.2794        1.3429  0.0702\n",
      "    285        0.2703        \u001b[32m0.9773\u001b[0m  0.0793\n",
      "    286        0.2757        1.3159  0.0698\n",
      "    287        0.2686        \u001b[32m0.9687\u001b[0m  0.0796\n",
      "    288        0.2746        1.3166  0.0634\n",
      "    289        0.2689        0.9711  0.1006\n",
      "    290        0.2756        1.3423  0.0950\n",
      "    291        0.2712        0.9848  0.0699\n",
      "    292        0.2786        1.3906  0.0627\n",
      "    293        0.2752        1.0090  0.1306\n",
      "    294        0.2833        1.4557  0.0857\n",
      "    295        0.2805        1.0400  0.0595\n",
      "    296        0.2891        1.5251  0.0530\n",
      "    297        0.2862        1.0694  0.0660\n",
      "    298        0.2947        1.5792  0.0977\n",
      "    299        0.2905        1.0865  0.0734\n",
      "    300        0.2985        1.5990  0.0521\n",
      "    301        0.2919        1.0837  0.0716\n",
      "    302        0.2991        1.5764  0.0989\n",
      "    303        0.2899        1.0617  0.0725\n",
      "    304        0.2964        1.5202  0.0912\n",
      "    305        0.2852        1.0285  0.0666\n",
      "    306        0.2913        1.4495  0.0718\n",
      "    307        0.2794        0.9937  0.0876\n",
      "    308        0.2855        1.3821  0.0767\n",
      "    309        0.2740        \u001b[32m0.9641\u001b[0m  0.0681\n",
      "    310        0.2803        1.3285  0.0720\n",
      "    311        0.2699        \u001b[32m0.9425\u001b[0m  0.0989\n",
      "    312        0.2764        1.2926  0.0912\n",
      "    313        0.2672        \u001b[32m0.9292\u001b[0m  0.0874\n",
      "    314        0.2740        1.2744  0.0921\n",
      "    315        \u001b[36m0.2660\u001b[0m        \u001b[32m0.9237\u001b[0m  0.0689\n",
      "    316        0.2731        1.2723  0.0847\n",
      "    317        0.2660        0.9253  0.0594\n",
      "    318        0.2735        1.2838  0.0701\n",
      "    319        0.2670        0.9326  0.0793\n",
      "    320        0.2749        1.3051  0.0789\n",
      "    321        0.2689        0.9437  0.0700\n",
      "    322        0.2770        1.3305  0.0898\n",
      "    323        0.2710        0.9553  0.0789\n",
      "    324        0.2793        1.3530  0.0789\n",
      "    325        0.2729        0.9635  0.0913\n",
      "    326        0.2811        1.3651  0.0703\n",
      "    327        0.2739        0.9650  0.0706\n",
      "    328        0.2819        1.3621  0.1002\n",
      "    329        0.2736        0.9583  0.0735\n",
      "    330        0.2812        1.3438  0.0691\n",
      "    331        0.2721        0.9450  0.0787\n",
      "    332        0.2794        1.3145  0.0782\n",
      "    333        0.2698        0.9281  0.0790\n",
      "    334        0.2768        1.2811  0.0918\n",
      "    335        0.2671        \u001b[32m0.9110\u001b[0m  0.0932\n",
      "    336        0.2740        1.2497  0.0689\n",
      "    337        \u001b[36m0.2646\u001b[0m        \u001b[32m0.8964\u001b[0m  0.0693\n",
      "    338        0.2715        1.2248  0.0991\n",
      "    339        \u001b[36m0.2627\u001b[0m        \u001b[32m0.8858\u001b[0m  0.0679\n",
      "    340        0.2697        1.2082  0.0618\n",
      "    341        \u001b[36m0.2615\u001b[0m        \u001b[32m0.8795\u001b[0m  0.0999\n",
      "    342        0.2686        1.2003  0.0770\n",
      "    343        \u001b[36m0.2609\u001b[0m        \u001b[32m0.8773\u001b[0m  0.0717\n",
      "    344        0.2682        1.2000  0.0827\n",
      "    345        0.2610        0.8784  0.0719\n",
      "    346        0.2684        1.2052  0.1010\n",
      "    347        0.2615        0.8817  0.0683\n",
      "    348        0.2691        1.2130  0.0710\n",
      "    349        0.2622        0.8853  0.0703\n",
      "    350        0.2698        1.2199  0.0908\n",
      "    351        0.2628        0.8876  0.0974\n",
      "    352        0.2704        1.2228  0.0767\n",
      "    353        0.2631        0.8870  0.0931\n",
      "    354        0.2706        1.2194  0.0634\n",
      "    355        0.2629        0.8830  0.0645\n",
      "    356        0.2701        1.2094  0.0610\n",
      "    357        0.2621        \u001b[32m0.8758\u001b[0m  0.0585\n",
      "    358        0.2691        1.1942  0.0666\n",
      "    359        \u001b[36m0.2609\u001b[0m        \u001b[32m0.8666\u001b[0m  0.0665\n",
      "    360        0.2677        1.1764  0.1284\n",
      "    361        \u001b[36m0.2595\u001b[0m        \u001b[32m0.8570\u001b[0m  0.0921\n",
      "    362        0.2662        1.1587  0.0756\n",
      "    363        \u001b[36m0.2581\u001b[0m        \u001b[32m0.8481\u001b[0m  0.0720\n",
      "    364        0.2647        1.1434  0.0735\n",
      "    365        \u001b[36m0.2569\u001b[0m        \u001b[32m0.8411\u001b[0m  0.0704\n",
      "    366        0.2635        1.1320  0.0612\n",
      "    367        \u001b[36m0.2560\u001b[0m        \u001b[32m0.8361\u001b[0m  0.0631\n",
      "    368        0.2627        1.1247  0.0769\n",
      "    369        \u001b[36m0.2555\u001b[0m        \u001b[32m0.8334\u001b[0m  0.0956\n",
      "    370        0.2622        1.1212  0.0681\n",
      "    371        \u001b[36m0.2553\u001b[0m        \u001b[32m0.8323\u001b[0m  0.0720\n",
      "    372        0.2620        1.1205  0.0758\n",
      "    373        \u001b[36m0.2553\u001b[0m        \u001b[32m0.8322\u001b[0m  0.0799\n",
      "    374        0.2620        1.1209  0.0872\n",
      "    375        0.2554        0.8322  0.0928\n",
      "    376        0.2621        1.1208  0.0828\n",
      "    377        0.2554        \u001b[32m0.8316\u001b[0m  0.0606\n",
      "    378        0.2620        1.1188  0.0937\n",
      "    379        0.2553        \u001b[32m0.8296\u001b[0m  0.0945\n",
      "    380        0.2618        1.1141  0.0657\n",
      "    381        \u001b[36m0.2549\u001b[0m        \u001b[32m0.8260\u001b[0m  0.0567\n",
      "    382        0.2613        1.1066  0.0729\n",
      "    383        \u001b[36m0.2543\u001b[0m        \u001b[32m0.8211\u001b[0m  0.0634\n",
      "    384        0.2606        1.0968  0.0980\n",
      "    385        \u001b[36m0.2536\u001b[0m        \u001b[32m0.8154\u001b[0m  0.0646\n",
      "    386        0.2597        1.0859  0.1081\n",
      "    387        \u001b[36m0.2527\u001b[0m        \u001b[32m0.8094\u001b[0m  0.0943\n",
      "    388        0.2587        1.0751  0.0811\n",
      "    389        \u001b[36m0.2519\u001b[0m        \u001b[32m0.8039\u001b[0m  0.0839\n",
      "    390        0.2578        1.0656  0.0694\n",
      "    391        \u001b[36m0.2511\u001b[0m        \u001b[32m0.7993\u001b[0m  0.0626\n",
      "    392        0.2570        1.0579  0.0920\n",
      "    393        \u001b[36m0.2505\u001b[0m        \u001b[32m0.7957\u001b[0m  0.0611\n",
      "    394        0.2564        1.0521  0.0809\n",
      "    395        \u001b[36m0.2501\u001b[0m        \u001b[32m0.7932\u001b[0m  0.0974\n",
      "    396        0.2559        1.0481  0.0692\n",
      "    397        \u001b[36m0.2498\u001b[0m        \u001b[32m0.7914\u001b[0m  0.0903\n",
      "    398        0.2556        1.0453  0.0554\n",
      "    399        \u001b[36m0.2496\u001b[0m        \u001b[32m0.7900\u001b[0m  0.0744\n",
      "    400        0.2553        1.0429  0.0894\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.regressor.NeuralNetRegressor'>[initialized](\n",
       "  module_=Net(\n",
       "    (fc1): Linear(in_features=1, out_features=128, bias=True)\n",
       "    (fc2): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (out): Linear(in_features=256, out_features=1, bias=True)\n",
       "    (act): Sigmoid()\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_skorch.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f592ced2-9b94-47d3-8658-e0c466b5f020",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = net_skorch.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5272641e-4760-47a6-9ec7-da5df0d508dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = net_skorch.get_loss(torch.from_numpy(y_pred), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3ea64bf6-cf97-4926-9c6e-4e16cf932d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4178)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3abc06-df53-4556-8db1-f81f7212b97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m4.0731\u001b[0m        \u001b[32m1.4684\u001b[0m  0.1499\n",
      "      2        5.3133        8.1300  0.1200\n",
      "      3        7.7844        \u001b[32m1.2572\u001b[0m  0.0998\n",
      "      4        4.8227        2.4631  0.1095\n",
      "      5        4.2289        4.5875  0.1071\n",
      "      6        \u001b[36m3.8306\u001b[0m        3.8364  0.1100\n",
      "      7        \u001b[36m3.3822\u001b[0m        2.2078  0.1264\n",
      "      8        \u001b[36m2.6675\u001b[0m        1.6786  0.0963\n",
      "      9        \u001b[36m2.2432\u001b[0m        1.6042  0.1128\n",
      "     10        \u001b[36m1.4651\u001b[0m        1.6818  0.1183\n",
      "     11        \u001b[36m1.1741\u001b[0m        1.7041  0.1170\n",
      "     12        1.4150        1.6016  0.1165\n",
      "     13        1.6745        1.4092  0.1270\n",
      "     14        1.3068        1.3850  0.1201\n",
      "     15        \u001b[36m0.9642\u001b[0m        1.4612  0.1028\n",
      "     16        \u001b[36m0.8576\u001b[0m        1.5195  0.1128\n",
      "     17        0.9557        1.5315  0.1129\n",
      "     18        1.0913        1.4900  0.0989\n",
      "     19        1.2809        1.3971  0.1206\n",
      "     20        1.3717        1.2944  0.1107\n",
      "     21        1.0875        1.3047  0.1106\n",
      "     22        \u001b[36m0.8138\u001b[0m        1.3869  0.1181\n",
      "     23        \u001b[36m0.7292\u001b[0m        1.4525  0.1201\n",
      "     24        0.7631        1.4786  0.0978\n",
      "     25        0.8315        1.4678  0.1091\n",
      "     26        0.9168        1.4325  0.1001\n",
      "     27        1.0185        1.3798  0.0998\n",
      "     28        1.0756        1.3254  0.1331\n",
      "     29        0.9912        1.3087  0.0849\n",
      "     30        0.8244        1.3402  0.1030\n",
      "     31        \u001b[36m0.7118\u001b[0m        1.3840  0.1160\n",
      "     32        \u001b[36m0.6780\u001b[0m        1.4124  0.0971\n",
      "     33        0.6916        1.4200  0.1092\n",
      "     34        0.7258        1.4113  0.1012\n",
      "     35        0.7681        1.3925  0.1009\n",
      "     36        0.8081        1.3686  0.1070\n",
      "     37        0.8276        1.3461  0.1318\n",
      "     38        0.8080        1.3334  0.1042\n",
      "     39        0.7550        1.3351  0.0942\n",
      "     40        0.6969        1.3464  0.1296\n",
      "     41        \u001b[36m0.6564\u001b[0m        1.3583  0.0987\n",
      "     42        \u001b[36m0.6379\u001b[0m        1.3651  0.0986\n",
      "     43        \u001b[36m0.6354\u001b[0m        1.3656  0.1099\n",
      "     44        0.6421        1.3612  0.1095\n",
      "     45        0.6521        1.3537  0.1135\n",
      "     46        0.6608        1.3449  0.1210\n",
      "     47        0.6642        1.3365  0.1020\n",
      "     48        0.6600        1.3299  0.0999\n",
      "     49        0.6486        1.3258  0.1111\n",
      "     50        \u001b[36m0.6331\u001b[0m        1.3239  0.0914\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m4.1827\u001b[0m        \u001b[32m3.6853\u001b[0m  0.0886\n",
      "      2        4.2770        \u001b[32m2.5203\u001b[0m  0.1183\n",
      "      3        \u001b[36m3.5096\u001b[0m        2.5691  0.1189\n",
      "      4        \u001b[36m3.3319\u001b[0m        \u001b[32m2.1204\u001b[0m  0.1139\n",
      "      5        \u001b[36m3.0895\u001b[0m        2.1763  0.0992\n",
      "      6        3.1149        \u001b[32m1.9718\u001b[0m  0.0901\n",
      "      7        \u001b[36m3.0264\u001b[0m        2.1589  0.1121\n",
      "      8        3.0761        \u001b[32m1.8573\u001b[0m  0.1174\n",
      "      9        \u001b[36m2.9537\u001b[0m        2.5362  0.1287\n",
      "     10        3.0651        2.1539  0.1089\n",
      "     11        \u001b[36m2.8539\u001b[0m        3.6739  0.0864\n",
      "     12        3.3286        3.9099  0.0924\n",
      "     13        \u001b[36m2.7603\u001b[0m        4.1634  0.0818\n",
      "     14        3.5466        2.4119  0.0826\n",
      "     15        2.9445        2.0562  0.0786\n",
      "     16        2.8887        1.9524  0.0836\n",
      "     17        2.8956        2.7327  0.0839\n",
      "     18        2.8984        2.7222  0.0860\n",
      "     19        2.8735        4.4493  0.0822\n",
      "     20        3.2481        5.1099  0.0829\n",
      "     21        2.9369        5.3715  0.0826\n",
      "     22        3.8088        2.1832  0.0810\n",
      "     23        \u001b[36m2.5099\u001b[0m        \u001b[32m1.6278\u001b[0m  0.0823\n",
      "     24        2.9641        \u001b[32m1.0832\u001b[0m  0.0927\n",
      "     25        2.6743        2.1256  0.0909\n",
      "     26        2.8177        \u001b[32m1.0252\u001b[0m  0.1199\n",
      "     27        2.6603        \u001b[32m0.8066\u001b[0m  0.1109\n",
      "     28        2.6473        2.5330  0.1127\n",
      "     29        2.6909        4.5316  0.0921\n",
      "     30        2.6512        5.2100  0.1182\n",
      "     31        3.3212        2.6981  0.1090\n",
      "     32        \u001b[36m2.2142\u001b[0m        2.5410  0.1291\n",
      "     33        2.2440        4.1085  0.1219\n",
      "     34        \u001b[36m1.3749\u001b[0m        3.8395  0.1074\n",
      "     35        2.3672        2.0204  0.1119\n",
      "     36        2.5610        0.8684  0.1285\n",
      "     37        \u001b[36m0.9741\u001b[0m        1.5090  0.1271\n",
      "     38        2.1758        \u001b[32m0.6874\u001b[0m  0.1024\n",
      "     39        1.0255        2.3310  0.1028\n",
      "     40        2.4804        1.1881  0.1299\n",
      "     41        1.3598        2.6903  0.1078\n",
      "     42        1.6036        2.6064  0.0917\n",
      "     43        \u001b[36m0.6839\u001b[0m        3.2126  0.1008\n",
      "     44        1.7154        7.3268  0.1074\n",
      "     45        1.3241        4.9166  0.1105\n",
      "     46        2.5799        2.5592  0.1176\n",
      "     47        1.8804        2.6080  0.1113\n",
      "     48        3.0133        3.5172  0.1236\n",
      "     49        2.0544        1.7125  0.1235\n",
      "     50        1.7487        4.0476  0.0956\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m1.9783\u001b[0m        \u001b[32m2.6602\u001b[0m  0.1110\n",
      "      2        2.6375        2.6800  0.1253\n",
      "      3        2.9504        5.2635  0.1117\n",
      "      4        3.0722        3.5350  0.1437\n",
      "      5        2.1357        3.7182  0.0990\n",
      "      6        2.1676        3.9784  0.1012\n",
      "      7        2.1485        3.5528  0.1117\n",
      "      8        2.0628        3.4023  0.1106\n",
      "      9        \u001b[36m1.9067\u001b[0m        2.8778  0.1156\n",
      "     10        \u001b[36m1.7113\u001b[0m        2.7611  0.0980\n",
      "     11        \u001b[36m1.6513\u001b[0m        2.8286  0.1069\n",
      "     12        1.6571        \u001b[32m2.5575\u001b[0m  0.0922\n",
      "     13        \u001b[36m1.5123\u001b[0m        \u001b[32m2.5198\u001b[0m  0.1184\n",
      "     14        \u001b[36m1.4805\u001b[0m        3.4215  0.1221\n",
      "     15        1.6410        \u001b[32m1.9430\u001b[0m  0.1205\n",
      "     16        \u001b[36m1.0495\u001b[0m        4.4343  0.1113\n",
      "     17        2.0616        2.0192  0.1227\n",
      "     18        \u001b[36m0.9119\u001b[0m        3.4348  0.1160\n",
      "     19        1.9668        \u001b[32m1.5879\u001b[0m  0.0927\n",
      "     20        1.0733        2.0346  0.0981\n",
      "     21        1.2060        1.9703  0.1090\n",
      "     22        1.0319        \u001b[32m0.6508\u001b[0m  0.1280\n",
      "     23        \u001b[36m0.6300\u001b[0m        4.6991  0.1149\n",
      "     24        1.5659        4.3248  0.1161\n",
      "     25        0.6599        3.6870  0.1037\n",
      "     26        1.8549        3.4150  0.0858\n",
      "     27        0.9737        2.8659  0.0726\n",
      "     28        1.6035        1.6351  0.0834\n",
      "     29        1.0399        0.8075  0.0977\n",
      "     30        0.7407        1.2675  0.1200\n",
      "     31        0.7436        1.6920  0.1355\n",
      "     32        0.7934        \u001b[32m0.2663\u001b[0m  0.1182\n",
      "     33        \u001b[36m0.4082\u001b[0m        2.1298  0.1126\n",
      "     34        0.8645        1.7699  0.1245\n",
      "     35        \u001b[36m0.3569\u001b[0m        2.7284  0.1092\n",
      "     36        1.0467       13.4243  0.1116\n",
      "     37        1.1603        4.3123  0.1014\n",
      "     38        2.3041        1.7450  0.1269\n",
      "     39        1.1013        1.0603  0.1204\n",
      "     40        0.8917        0.8121  0.1211\n",
      "     41        0.7833        0.7489  0.1265\n",
      "     42        0.5943        1.4021  0.1180\n",
      "     43        0.8204        2.7269  0.1116\n",
      "     44        0.6175        4.6057  0.1219\n",
      "     45        2.2723        2.7418  0.1277\n",
      "     46        0.6909        3.2943  0.1210\n",
      "     47        1.6367        3.8756  0.1070\n",
      "     48        0.9014        3.1013  0.2055\n",
      "     49        1.5468        1.8255  0.1171\n",
      "     50        0.9633        0.6433  0.1217\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m4.0731\u001b[0m        \u001b[32m1.4684\u001b[0m  0.1137\n",
      "      2        5.3133        8.1300  0.1180\n",
      "      3        7.7844        \u001b[32m1.2572\u001b[0m  0.1176\n",
      "      4        4.8227        2.4631  0.1087\n",
      "      5        4.2289        4.5875  0.1095\n",
      "      6        \u001b[36m3.8306\u001b[0m        3.8364  0.1019\n",
      "      7        \u001b[36m3.3822\u001b[0m        2.2078  0.1105\n",
      "      8        \u001b[36m2.6675\u001b[0m        1.6786  0.0980\n",
      "      9        \u001b[36m2.2432\u001b[0m        1.6042  0.1163\n",
      "     10        \u001b[36m1.4651\u001b[0m        1.6818  0.1087\n",
      "     11        \u001b[36m1.1741\u001b[0m        1.7041  0.1027\n",
      "     12        1.4150        1.6016  0.1089\n",
      "     13        1.6745        1.4092  0.1204\n",
      "     14        1.3068        1.3850  0.1049\n",
      "     15        \u001b[36m0.9642\u001b[0m        1.4612  0.1190\n",
      "     16        \u001b[36m0.8576\u001b[0m        1.5195  0.1209\n",
      "     17        0.9557        1.5315  0.1083\n",
      "     18        1.0913        1.4900  0.1072\n",
      "     19        1.2809        1.3971  0.1258\n",
      "     20        1.3717        1.2944  0.1132\n",
      "     21        1.0875        1.3047  0.1218\n",
      "     22        \u001b[36m0.8138\u001b[0m        1.3869  0.1211\n",
      "     23        \u001b[36m0.7292\u001b[0m        1.4525  0.1276\n",
      "     24        0.7631        1.4786  0.1177\n",
      "     25        0.8315        1.4678  0.1281\n",
      "     26        0.9168        1.4325  0.1212\n",
      "     27        1.0185        1.3798  0.1181\n",
      "     28        1.0756        1.3254  0.1105\n",
      "     29        0.9912        1.3087  0.1201\n",
      "     30        0.8244        1.3402  0.1175\n",
      "     31        \u001b[36m0.7118\u001b[0m        1.3840  0.1108\n",
      "     32        \u001b[36m0.6780\u001b[0m        1.4124  0.1103\n",
      "     33        0.6916        1.4200  0.0987\n",
      "     34        0.7258        1.4113  0.1118\n",
      "     35        0.7681        1.3925  0.1002\n",
      "     36        0.8081        1.3686  0.1019\n",
      "     37        0.8276        1.3461  0.1079\n",
      "     38        0.8080        1.3334  0.1202\n",
      "     39        0.7550        1.3351  0.1019\n",
      "     40        0.6969        1.3464  0.1220\n",
      "     41        \u001b[36m0.6564\u001b[0m        1.3583  0.1095\n",
      "     42        \u001b[36m0.6379\u001b[0m        1.3651  0.1044\n",
      "     43        \u001b[36m0.6354\u001b[0m        1.3656  0.0802\n",
      "     44        0.6421        1.3612  0.0828\n",
      "     45        0.6521        1.3537  0.0811\n",
      "     46        0.6608        1.3449  0.0750\n",
      "     47        0.6642        1.3365  0.0800\n",
      "     48        0.6600        1.3299  0.0808\n",
      "     49        0.6486        1.3258  0.0744\n",
      "     50        \u001b[36m0.6331\u001b[0m        1.3239  0.0695\n",
      "     51        \u001b[36m0.6175\u001b[0m        1.3232  0.0803\n",
      "     52        \u001b[36m0.6046\u001b[0m        1.3226  0.0806\n",
      "     53        \u001b[36m0.5957\u001b[0m        1.3213  0.0763\n",
      "     54        \u001b[36m0.5905\u001b[0m        1.3189  0.0800\n",
      "     55        \u001b[36m0.5880\u001b[0m        1.3156  0.0925\n",
      "     56        \u001b[36m0.5870\u001b[0m        1.3116  0.0999\n",
      "     57        \u001b[36m0.5864\u001b[0m        1.3072  0.1110\n",
      "     58        \u001b[36m0.5853\u001b[0m        1.3029  0.1134\n",
      "     59        \u001b[36m0.5833\u001b[0m        1.2987  0.1030\n",
      "     60        \u001b[36m0.5802\u001b[0m        1.2948  0.1017\n",
      "     61        \u001b[36m0.5764\u001b[0m        1.2913  0.0959\n",
      "     62        \u001b[36m0.5722\u001b[0m        1.2880  0.1194\n",
      "     63        \u001b[36m0.5682\u001b[0m        1.2849  0.1160\n",
      "     64        \u001b[36m0.5646\u001b[0m        1.2818  0.0993\n",
      "     65        \u001b[36m0.5616\u001b[0m        1.2786  0.1298\n",
      "     66        \u001b[36m0.5592\u001b[0m        1.2753  0.1154\n",
      "     67        \u001b[36m0.5573\u001b[0m        1.2719  0.1103\n",
      "     68        \u001b[36m0.5558\u001b[0m        1.2684  0.1119\n",
      "     69        \u001b[36m0.5543\u001b[0m        1.2649  0.1073\n",
      "     70        \u001b[36m0.5529\u001b[0m        1.2614  0.1024\n",
      "     71        \u001b[36m0.5515\u001b[0m        1.2580  0.1047\n",
      "     72        \u001b[36m0.5500\u001b[0m        \u001b[32m1.2546\u001b[0m  0.1129\n",
      "     73        \u001b[36m0.5485\u001b[0m        \u001b[32m1.2513\u001b[0m  0.1098\n",
      "     74        \u001b[36m0.5470\u001b[0m        \u001b[32m1.2480\u001b[0m  0.1111\n",
      "     75        \u001b[36m0.5455\u001b[0m        \u001b[32m1.2448\u001b[0m  0.1183\n",
      "     76        \u001b[36m0.5441\u001b[0m        \u001b[32m1.2415\u001b[0m  0.1081\n",
      "     77        \u001b[36m0.5428\u001b[0m        \u001b[32m1.2383\u001b[0m  0.1007\n",
      "     78        \u001b[36m0.5416\u001b[0m        \u001b[32m1.2351\u001b[0m  0.1032\n",
      "     79        \u001b[36m0.5405\u001b[0m        \u001b[32m1.2319\u001b[0m  0.1204\n",
      "     80        \u001b[36m0.5395\u001b[0m        \u001b[32m1.2287\u001b[0m  0.1299\n",
      "     81        \u001b[36m0.5385\u001b[0m        \u001b[32m1.2255\u001b[0m  0.1139\n",
      "     82        \u001b[36m0.5375\u001b[0m        \u001b[32m1.2223\u001b[0m  0.1284\n",
      "     83        \u001b[36m0.5366\u001b[0m        \u001b[32m1.2192\u001b[0m  0.1259\n",
      "     84        \u001b[36m0.5356\u001b[0m        \u001b[32m1.2161\u001b[0m  0.1186\n",
      "     85        \u001b[36m0.5347\u001b[0m        \u001b[32m1.2130\u001b[0m  0.1076\n",
      "     86        \u001b[36m0.5338\u001b[0m        \u001b[32m1.2099\u001b[0m  0.1009\n",
      "     87        \u001b[36m0.5329\u001b[0m        \u001b[32m1.2068\u001b[0m  0.0935\n",
      "     88        \u001b[36m0.5320\u001b[0m        \u001b[32m1.2038\u001b[0m  0.1193\n",
      "     89        \u001b[36m0.5311\u001b[0m        \u001b[32m1.2008\u001b[0m  0.1085\n",
      "     90        \u001b[36m0.5303\u001b[0m        \u001b[32m1.1978\u001b[0m  0.1103\n",
      "     91        \u001b[36m0.5294\u001b[0m        \u001b[32m1.1948\u001b[0m  0.1165\n",
      "     92        \u001b[36m0.5286\u001b[0m        \u001b[32m1.1918\u001b[0m  0.1156\n",
      "     93        \u001b[36m0.5278\u001b[0m        \u001b[32m1.1889\u001b[0m  0.1037\n",
      "     94        \u001b[36m0.5269\u001b[0m        \u001b[32m1.1860\u001b[0m  0.1088\n",
      "     95        \u001b[36m0.5261\u001b[0m        \u001b[32m1.1831\u001b[0m  0.1237\n",
      "     96        \u001b[36m0.5253\u001b[0m        \u001b[32m1.1803\u001b[0m  0.1097\n",
      "     97        \u001b[36m0.5245\u001b[0m        \u001b[32m1.1774\u001b[0m  0.1070\n",
      "     98        \u001b[36m0.5236\u001b[0m        \u001b[32m1.1746\u001b[0m  0.1151\n",
      "     99        \u001b[36m0.5228\u001b[0m        \u001b[32m1.1719\u001b[0m  0.1051\n",
      "    100        \u001b[36m0.5219\u001b[0m        \u001b[32m1.1691\u001b[0m  0.1173\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m4.1827\u001b[0m        \u001b[32m3.6853\u001b[0m  0.0964\n",
      "      2        4.2770        \u001b[32m2.5203\u001b[0m  0.1104\n",
      "      3        \u001b[36m3.5096\u001b[0m        2.5691  0.1132\n",
      "      4        \u001b[36m3.3319\u001b[0m        \u001b[32m2.1204\u001b[0m  0.1081\n",
      "      5        \u001b[36m3.0895\u001b[0m        2.1763  0.1168\n",
      "      6        3.1149        \u001b[32m1.9718\u001b[0m  0.1113\n",
      "      7        \u001b[36m3.0264\u001b[0m        2.1589  0.1087\n",
      "      8        3.0761        \u001b[32m1.8573\u001b[0m  0.1399\n",
      "      9        \u001b[36m2.9537\u001b[0m        2.5362  0.1099\n",
      "     10        3.0651        2.1539  0.1079\n",
      "     11        \u001b[36m2.8539\u001b[0m        3.6739  0.1088\n",
      "     12        3.3286        3.9099  0.1001\n",
      "     13        \u001b[36m2.7603\u001b[0m        4.1634  0.0926\n",
      "     14        3.5466        2.4119  0.1345\n",
      "     15        2.9445        2.0562  0.1262\n",
      "     16        2.8887        1.9524  0.1156\n",
      "     17        2.8956        2.7327  0.1202\n",
      "     18        2.8984        2.7222  0.1103\n",
      "     19        2.8735        4.4493  0.1187\n",
      "     20        3.2481        5.1099  0.0780\n",
      "     21        2.9369        5.3715  0.0949\n",
      "     22        3.8088        2.1832  0.0887\n",
      "     23        \u001b[36m2.5099\u001b[0m        \u001b[32m1.6278\u001b[0m  0.1977\n",
      "     24        2.9641        \u001b[32m1.0832\u001b[0m  0.0949\n",
      "     25        2.6743        2.1256  0.1007\n",
      "     26        2.8177        \u001b[32m1.0252\u001b[0m  0.1208\n",
      "     27        2.6603        \u001b[32m0.8066\u001b[0m  0.1155\n",
      "     28        2.6473        2.5330  0.1054\n",
      "     29        2.6909        4.5316  0.1096\n",
      "     30        2.6512        5.2100  0.0927\n",
      "     31        3.3212        2.6981  0.1076\n",
      "     32        \u001b[36m2.2142\u001b[0m        2.5410  0.1117\n",
      "     33        2.2440        4.1085  0.1132\n",
      "     34        \u001b[36m1.3749\u001b[0m        3.8395  0.1277\n",
      "     35        2.3672        2.0204  0.1327\n",
      "     36        2.5610        0.8684  0.1117\n",
      "     37        \u001b[36m0.9741\u001b[0m        1.5090  0.1159\n",
      "     38        2.1758        \u001b[32m0.6874\u001b[0m  0.1826\n",
      "     39        1.0255        2.3310  0.1102\n",
      "     40        2.4804        1.1881  0.1097\n",
      "     41        1.3598        2.6903  0.1137\n",
      "     42        1.6036        2.6064  0.1052\n",
      "     43        \u001b[36m0.6839\u001b[0m        3.2126  0.1548\n",
      "     44        1.7154        7.3268  0.1193\n",
      "     45        1.3241        4.9166  0.1093\n",
      "     46        2.5799        2.5592  0.1107\n",
      "     47        1.8804        2.6080  0.1010\n",
      "     48        3.0133        3.5172  0.1086\n",
      "     49        2.0544        1.7125  0.1276\n",
      "     50        1.7487        4.0476  0.1569\n",
      "     51        1.2320        4.0398  0.1220\n",
      "     52        2.0614        1.4698  0.1442\n",
      "     53        1.3840        0.7345  0.0972\n",
      "     54        0.7409        0.7955  0.0982\n",
      "     55        1.3585        \u001b[32m0.5493\u001b[0m  0.1467\n",
      "     56        \u001b[36m0.6504\u001b[0m        0.9171  0.1161\n",
      "     57        1.1987        \u001b[32m0.4228\u001b[0m  0.0996\n",
      "     58        \u001b[36m0.5831\u001b[0m        0.5404  0.0975\n",
      "     59        0.9367        0.4440  0.0878\n",
      "     60        \u001b[36m0.5273\u001b[0m        0.9157  0.1016\n",
      "     61        1.1199        0.5557  0.0992\n",
      "     62        0.5490        1.2584  0.0854\n",
      "     63        1.2554        1.0875  0.0814\n",
      "     64        0.5332        2.4293  0.1485\n",
      "     65        1.2663        6.1494  0.1131\n",
      "     66        0.7678        4.8322  0.1191\n",
      "     67        2.4731        2.5761  0.1455\n",
      "     68        1.6144        1.7365  0.1258\n",
      "     69        1.2329        1.7345  0.1500\n",
      "     70        0.9228        1.8943  0.1341\n",
      "     71        1.8349        1.6044  0.1491\n",
      "     72        0.8449        3.8179  0.2084\n",
      "     73        1.5678        6.6582  0.1269\n",
      "     74        1.5443        2.6865  0.1449\n",
      "     75        1.2761        2.5757  0.0996\n",
      "     76        1.1924        \u001b[32m0.3851\u001b[0m  0.1538\n",
      "     77        0.6335        \u001b[32m0.2567\u001b[0m  0.1077\n",
      "     78        1.2318        0.6033  0.0988\n",
      "     79        0.7032        0.9864  0.1042\n",
      "     80        1.0781        3.4770  0.1099\n",
      "     81        0.6184        3.4937  0.1087\n",
      "     82        1.4570        2.8547  0.0989\n",
      "     83        1.1972        0.6384  0.0816\n",
      "     84        0.6208        2.5430  0.1127\n",
      "     85        0.9909        1.1335  0.1091\n",
      "     86        1.0243        1.7035  0.1171\n",
      "     87        1.5277        0.5594  0.0961\n",
      "     88        0.9753        0.3550  0.1182\n",
      "     89        0.9323        0.8161  0.1087\n",
      "     90        0.5644        1.5879  0.1124\n",
      "     91        0.8386        6.2604  0.1067\n",
      "     92        0.6124        4.5281  0.1208\n",
      "     93        2.1650        2.0764  0.1261\n",
      "     94        0.7464        1.8929  0.1325\n",
      "     95        1.1503        7.2877  0.1271\n",
      "     96        1.0536        4.2592  0.0958\n",
      "     97        2.4017        3.7806  0.1310\n",
      "     98        2.1713        3.3839  0.1019\n",
      "     99        1.9857        3.8661  0.1680\n",
      "    100        2.1823        2.1981  0.1071\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m1.9783\u001b[0m        \u001b[32m2.6602\u001b[0m  0.0801\n",
      "      2        2.6375        2.6800  0.1040\n",
      "      3        2.9504        5.2635  0.1078\n",
      "      4        3.0722        3.5350  0.0953\n",
      "      5        2.1357        3.7182  0.0920\n",
      "      6        2.1676        3.9784  0.1574\n",
      "      7        2.1485        3.5528  0.1568\n",
      "      8        2.0628        3.4023  0.1062\n",
      "      9        \u001b[36m1.9067\u001b[0m        2.8778  0.1055\n",
      "     10        \u001b[36m1.7113\u001b[0m        2.7611  0.2082\n",
      "     11        \u001b[36m1.6513\u001b[0m        2.8286  0.0891\n",
      "     12        1.6571        \u001b[32m2.5575\u001b[0m  0.0906\n",
      "     13        \u001b[36m1.5123\u001b[0m        \u001b[32m2.5198\u001b[0m  0.0917\n",
      "     14        \u001b[36m1.4805\u001b[0m        3.4215  0.0866\n",
      "     15        1.6410        \u001b[32m1.9430\u001b[0m  0.1038\n",
      "     16        \u001b[36m1.0495\u001b[0m        4.4343  0.0878\n",
      "     17        2.0616        2.0192  0.0959\n",
      "     18        \u001b[36m0.9119\u001b[0m        3.4348  0.0799\n",
      "     19        1.9668        \u001b[32m1.5879\u001b[0m  0.0879\n",
      "     20        1.0733        2.0346  0.0802\n",
      "     21        1.2060        1.9703  0.0893\n",
      "     22        1.0319        \u001b[32m0.6508\u001b[0m  0.0954\n",
      "     23        \u001b[36m0.6300\u001b[0m        4.6991  0.0957\n",
      "     24        1.5659        4.3248  0.0999\n",
      "     25        0.6599        3.6870  0.0811\n",
      "     26        1.8549        3.4150  0.0970\n",
      "     27        0.9737        2.8659  0.0811\n",
      "     28        1.6035        1.6351  0.0921\n",
      "     29        1.0399        0.8075  0.0947\n",
      "     30        0.7407        1.2675  0.0934\n",
      "     31        0.7436        1.6920  0.1002\n",
      "     32        0.7934        \u001b[32m0.2663\u001b[0m  0.0829\n",
      "     33        \u001b[36m0.4082\u001b[0m        2.1298  0.0958\n",
      "     34        0.8645        1.7699  0.1444\n",
      "     35        \u001b[36m0.3569\u001b[0m        2.7284  0.0975\n",
      "     36        1.0467       13.4243  0.1021\n",
      "     37        1.1603        4.3123  0.1089\n",
      "     38        2.3041        1.7450  0.1055\n",
      "     39        1.1013        1.0603  0.1105\n",
      "     40        0.8917        0.8121  0.1101\n",
      "     41        0.7833        0.7489  0.1090\n",
      "     42        0.5943        1.4021  0.1060\n",
      "     43        0.8204        2.7269  0.0744\n",
      "     44        0.6175        4.6057  0.1060\n",
      "     45        2.2723        2.7418  0.1063\n",
      "     46        0.6909        3.2943  0.0924\n",
      "     47        1.6367        3.8756  0.0932\n",
      "     48        0.9014        3.1013  0.1104\n",
      "     49        1.5468        1.8255  0.1137\n",
      "     50        0.9633        0.6433  0.1079\n",
      "     51        0.5877        0.4006  0.1025\n",
      "     52        0.5165        0.9828  0.1237\n",
      "     53        0.3866        1.7368  0.0790\n",
      "     54        0.7591        6.1190  0.1138\n",
      "     55        0.6761        5.7338  0.1180\n",
      "     56        2.7059        2.5421  0.0923\n",
      "     57        1.1670        7.5805  0.1117\n",
      "     58        1.2373        3.5614  0.1047\n",
      "     59        1.7203        1.7807  0.1221\n",
      "     60        1.0425        1.2598  0.1226\n",
      "     61        0.8643        0.7556  0.1098\n",
      "     62        0.6782        1.6003  0.1186\n",
      "     63        0.4293        2.8265  0.1028\n",
      "     64        1.1146       11.0428  0.1201\n",
      "     65        1.1237        3.4609  0.1214\n",
      "     66        1.7776        1.9336  0.1280\n",
      "     67        1.0212        1.2689  0.1149\n",
      "     68        0.8455        0.8170  0.1193\n",
      "     69        0.7323        1.3987  0.1201\n",
      "     70        0.5640        2.0798  0.1124\n",
      "     71        0.8969        9.4368  0.1192\n",
      "     72        0.8793        4.6860  0.1140\n",
      "     73        2.3784        1.2604  0.1142\n",
      "     74        0.8798        2.5761  0.1212\n",
      "     75        0.8497        1.4998  0.1117\n",
      "     76        0.9289        3.2306  0.1218\n",
      "     77        0.7275        2.6023  0.1104\n",
      "     78        1.3098        1.8596  0.1107\n",
      "     79        0.7240        0.6315  0.1261\n",
      "     80        0.6637        1.7713  0.1190\n",
      "     81        0.5091        1.3900  0.1344\n",
      "     82        0.8428        4.6634  0.1044\n",
      "     83        0.7813        3.4684  0.1102\n",
      "     84        1.7022        1.0078  0.0980\n",
      "     85        0.6495        0.6764  0.1210\n",
      "     86        0.5252        0.2931  0.0976\n",
      "     87        0.4939        1.3559  0.1279\n",
      "     88        0.4593        1.0991  0.1328\n",
      "     89        0.7432        4.7937  0.1306\n",
      "     90        0.7373        2.9304  0.0961\n",
      "     91        1.5150        0.9185  0.0949\n",
      "     92        0.5905        0.5094  0.0876\n",
      "     93        0.5142        \u001b[32m0.2617\u001b[0m  0.1129\n",
      "     94        0.4560        0.5739  0.1154\n",
      "     95        0.4405        0.3566  0.1193\n",
      "     96        0.5130        1.7641  0.0981\n",
      "     97        0.4825        1.2557  0.0983\n",
      "     98        0.7983        4.9237  0.1276\n",
      "     99        0.7679        2.7207  0.1277\n",
      "    100        1.4843        0.6651  0.0882\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m4.0731\u001b[0m        \u001b[32m1.4684\u001b[0m  0.0814\n",
      "      2        5.3133        8.1300  0.0613\n",
      "      3        7.7844        \u001b[32m1.2572\u001b[0m  0.0698\n",
      "      4        4.8227        2.4631  0.0769\n",
      "      5        4.2289        4.5875  0.0850\n",
      "      6        \u001b[36m3.8306\u001b[0m        3.8364  0.0784\n",
      "      7        \u001b[36m3.3822\u001b[0m        2.2078  0.0775\n",
      "      8        \u001b[36m2.6675\u001b[0m        1.6786  0.0740\n",
      "      9        \u001b[36m2.2432\u001b[0m        1.6042  0.0767\n",
      "     10        \u001b[36m1.4651\u001b[0m        1.6818  0.0910\n",
      "     11        \u001b[36m1.1741\u001b[0m        1.7041  0.0880\n",
      "     12        1.4150        1.6016  0.0970\n",
      "     13        1.6745        1.4092  0.1305\n",
      "     14        1.3068        1.3850  0.0849\n",
      "     15        \u001b[36m0.9642\u001b[0m        1.4612  0.1059\n",
      "     16        \u001b[36m0.8576\u001b[0m        1.5195  0.0964\n",
      "     17        0.9557        1.5315  0.0841\n",
      "     18        1.0913        1.4900  0.1099\n",
      "     19        1.2809        1.3971  0.1102\n",
      "     20        1.3717        1.2944  0.1204\n",
      "     21        1.0875        1.3047  0.1229\n",
      "     22        \u001b[36m0.8138\u001b[0m        1.3869  0.0966\n",
      "     23        \u001b[36m0.7292\u001b[0m        1.4525  0.0845\n",
      "     24        0.7631        1.4786  0.0973\n",
      "     25        0.8315        1.4678  0.1017\n",
      "     26        0.9168        1.4325  0.1204\n",
      "     27        1.0185        1.3798  0.1195\n",
      "     28        1.0756        1.3254  0.1100\n",
      "     29        0.9912        1.3087  0.1164\n",
      "     30        0.8244        1.3402  0.1113\n",
      "     31        \u001b[36m0.7118\u001b[0m        1.3840  0.1103\n",
      "     32        \u001b[36m0.6780\u001b[0m        1.4124  0.1678\n",
      "     33        0.6916        1.4200  0.0940\n",
      "     34        0.7258        1.4113  0.1097\n",
      "     35        0.7681        1.3925  0.1045\n",
      "     36        0.8081        1.3686  0.1193\n",
      "     37        0.8276        1.3461  0.1005\n",
      "     38        0.8080        1.3334  0.1224\n",
      "     39        0.7550        1.3351  0.0967\n",
      "     40        0.6969        1.3464  0.1273\n",
      "     41        \u001b[36m0.6564\u001b[0m        1.3583  0.0905\n",
      "     42        \u001b[36m0.6379\u001b[0m        1.3651  0.1158\n",
      "     43        \u001b[36m0.6354\u001b[0m        1.3656  0.1088\n",
      "     44        0.6421        1.3612  0.1036\n",
      "     45        0.6521        1.3537  0.1109\n",
      "     46        0.6608        1.3449  0.1278\n",
      "     47        0.6642        1.3365  0.1070\n",
      "     48        0.6600        1.3299  0.1065\n",
      "     49        0.6486        1.3258  0.1310\n",
      "     50        \u001b[36m0.6331\u001b[0m        1.3239  0.1134\n",
      "     51        \u001b[36m0.6175\u001b[0m        1.3232  0.1014\n",
      "     52        \u001b[36m0.6046\u001b[0m        1.3226  0.1099\n",
      "     53        \u001b[36m0.5957\u001b[0m        1.3213  0.1032\n",
      "     54        \u001b[36m0.5905\u001b[0m        1.3189  0.1120\n",
      "     55        \u001b[36m0.5880\u001b[0m        1.3156  0.1230\n",
      "     56        \u001b[36m0.5870\u001b[0m        1.3116  0.1080\n",
      "     57        \u001b[36m0.5864\u001b[0m        1.3072  0.1238\n",
      "     58        \u001b[36m0.5853\u001b[0m        1.3029  0.1197\n",
      "     59        \u001b[36m0.5833\u001b[0m        1.2987  0.1188\n",
      "     60        \u001b[36m0.5802\u001b[0m        1.2948  0.0978\n",
      "     61        \u001b[36m0.5764\u001b[0m        1.2913  0.1141\n",
      "     62        \u001b[36m0.5722\u001b[0m        1.2880  0.1103\n",
      "     63        \u001b[36m0.5682\u001b[0m        1.2849  0.1210\n",
      "     64        \u001b[36m0.5646\u001b[0m        1.2818  0.1050\n",
      "     65        \u001b[36m0.5616\u001b[0m        1.2786  0.1054\n",
      "     66        \u001b[36m0.5592\u001b[0m        1.2753  0.1066\n",
      "     67        \u001b[36m0.5573\u001b[0m        1.2719  0.0944\n",
      "     68        \u001b[36m0.5558\u001b[0m        1.2684  0.1044\n",
      "     69        \u001b[36m0.5543\u001b[0m        1.2649  0.1259\n",
      "     70        \u001b[36m0.5529\u001b[0m        1.2614  0.0910\n",
      "     71        \u001b[36m0.5515\u001b[0m        1.2580  0.1192\n",
      "     72        \u001b[36m0.5500\u001b[0m        \u001b[32m1.2546\u001b[0m  0.1016\n",
      "     73        \u001b[36m0.5485\u001b[0m        \u001b[32m1.2513\u001b[0m  0.1073\n",
      "     74        \u001b[36m0.5470\u001b[0m        \u001b[32m1.2480\u001b[0m  0.1013\n",
      "     75        \u001b[36m0.5455\u001b[0m        \u001b[32m1.2448\u001b[0m  0.0904\n",
      "     76        \u001b[36m0.5441\u001b[0m        \u001b[32m1.2415\u001b[0m  0.0961\n",
      "     77        \u001b[36m0.5428\u001b[0m        \u001b[32m1.2383\u001b[0m  0.1130\n",
      "     78        \u001b[36m0.5416\u001b[0m        \u001b[32m1.2351\u001b[0m  0.1173\n",
      "     79        \u001b[36m0.5405\u001b[0m        \u001b[32m1.2319\u001b[0m  0.1007\n",
      "     80        \u001b[36m0.5395\u001b[0m        \u001b[32m1.2287\u001b[0m  0.1039\n",
      "     81        \u001b[36m0.5385\u001b[0m        \u001b[32m1.2255\u001b[0m  0.1176\n",
      "     82        \u001b[36m0.5375\u001b[0m        \u001b[32m1.2223\u001b[0m  0.1186\n",
      "     83        \u001b[36m0.5366\u001b[0m        \u001b[32m1.2192\u001b[0m  0.1176\n",
      "     84        \u001b[36m0.5356\u001b[0m        \u001b[32m1.2161\u001b[0m  0.1275\n",
      "     85        \u001b[36m0.5347\u001b[0m        \u001b[32m1.2130\u001b[0m  0.1014\n",
      "     86        \u001b[36m0.5338\u001b[0m        \u001b[32m1.2099\u001b[0m  0.1267\n",
      "     87        \u001b[36m0.5329\u001b[0m        \u001b[32m1.2068\u001b[0m  0.1215\n",
      "     88        \u001b[36m0.5320\u001b[0m        \u001b[32m1.2038\u001b[0m  0.1237\n",
      "     89        \u001b[36m0.5311\u001b[0m        \u001b[32m1.2008\u001b[0m  0.0898\n",
      "     90        \u001b[36m0.5303\u001b[0m        \u001b[32m1.1978\u001b[0m  0.0981\n",
      "     91        \u001b[36m0.5294\u001b[0m        \u001b[32m1.1948\u001b[0m  0.0993\n",
      "     92        \u001b[36m0.5286\u001b[0m        \u001b[32m1.1918\u001b[0m  0.1184\n",
      "     93        \u001b[36m0.5278\u001b[0m        \u001b[32m1.1889\u001b[0m  0.1190\n",
      "     94        \u001b[36m0.5269\u001b[0m        \u001b[32m1.1860\u001b[0m  0.1200\n",
      "     95        \u001b[36m0.5261\u001b[0m        \u001b[32m1.1831\u001b[0m  0.1080\n",
      "     96        \u001b[36m0.5253\u001b[0m        \u001b[32m1.1803\u001b[0m  0.1172\n",
      "     97        \u001b[36m0.5245\u001b[0m        \u001b[32m1.1774\u001b[0m  0.1107\n",
      "     98        \u001b[36m0.5236\u001b[0m        \u001b[32m1.1746\u001b[0m  0.1340\n",
      "     99        \u001b[36m0.5228\u001b[0m        \u001b[32m1.1719\u001b[0m  0.1090\n",
      "    100        \u001b[36m0.5219\u001b[0m        \u001b[32m1.1691\u001b[0m  0.0988\n",
      "    101        \u001b[36m0.5211\u001b[0m        \u001b[32m1.1664\u001b[0m  0.1117\n",
      "    102        \u001b[36m0.5202\u001b[0m        \u001b[32m1.1637\u001b[0m  0.1025\n",
      "    103        \u001b[36m0.5194\u001b[0m        \u001b[32m1.1611\u001b[0m  0.1116\n",
      "    104        \u001b[36m0.5185\u001b[0m        \u001b[32m1.1585\u001b[0m  0.1263\n",
      "    105        \u001b[36m0.5176\u001b[0m        \u001b[32m1.1559\u001b[0m  0.1084\n",
      "    106        \u001b[36m0.5167\u001b[0m        \u001b[32m1.1534\u001b[0m  0.1180\n",
      "    107        \u001b[36m0.5158\u001b[0m        \u001b[32m1.1509\u001b[0m  0.1203\n",
      "    108        \u001b[36m0.5149\u001b[0m        \u001b[32m1.1485\u001b[0m  0.1000\n",
      "    109        \u001b[36m0.5140\u001b[0m        \u001b[32m1.1460\u001b[0m  0.0896\n",
      "    110        \u001b[36m0.5131\u001b[0m        \u001b[32m1.1437\u001b[0m  0.0920\n",
      "    111        \u001b[36m0.5121\u001b[0m        \u001b[32m1.1414\u001b[0m  0.0964\n",
      "    112        \u001b[36m0.5112\u001b[0m        \u001b[32m1.1391\u001b[0m  0.1229\n",
      "    113        \u001b[36m0.5103\u001b[0m        \u001b[32m1.1368\u001b[0m  0.1200\n",
      "    114        \u001b[36m0.5093\u001b[0m        \u001b[32m1.1347\u001b[0m  0.1110\n",
      "    115        \u001b[36m0.5083\u001b[0m        \u001b[32m1.1325\u001b[0m  0.1169\n",
      "    116        \u001b[36m0.5074\u001b[0m        \u001b[32m1.1304\u001b[0m  0.1143\n",
      "    117        \u001b[36m0.5064\u001b[0m        \u001b[32m1.1284\u001b[0m  0.1186\n",
      "    118        \u001b[36m0.5054\u001b[0m        \u001b[32m1.1264\u001b[0m  0.1123\n",
      "    119        \u001b[36m0.5045\u001b[0m        \u001b[32m1.1244\u001b[0m  0.1231\n",
      "    120        \u001b[36m0.5035\u001b[0m        \u001b[32m1.1225\u001b[0m  0.1119\n",
      "    121        \u001b[36m0.5025\u001b[0m        \u001b[32m1.1206\u001b[0m  0.1068\n",
      "    122        \u001b[36m0.5015\u001b[0m        \u001b[32m1.1188\u001b[0m  0.1141\n",
      "    123        \u001b[36m0.5006\u001b[0m        \u001b[32m1.1171\u001b[0m  0.1116\n",
      "    124        \u001b[36m0.4996\u001b[0m        \u001b[32m1.1154\u001b[0m  0.1215\n",
      "    125        \u001b[36m0.4986\u001b[0m        \u001b[32m1.1137\u001b[0m  0.1271\n",
      "    126        \u001b[36m0.4977\u001b[0m        \u001b[32m1.1121\u001b[0m  0.1053\n",
      "    127        \u001b[36m0.4967\u001b[0m        \u001b[32m1.1105\u001b[0m  0.0890\n",
      "    128        \u001b[36m0.4958\u001b[0m        \u001b[32m1.1090\u001b[0m  0.0757\n",
      "    129        \u001b[36m0.4948\u001b[0m        \u001b[32m1.1076\u001b[0m  0.0779\n",
      "    130        \u001b[36m0.4939\u001b[0m        \u001b[32m1.1061\u001b[0m  0.0695\n",
      "    131        \u001b[36m0.4930\u001b[0m        \u001b[32m1.1048\u001b[0m  0.0747\n",
      "    132        \u001b[36m0.4920\u001b[0m        \u001b[32m1.1035\u001b[0m  0.0852\n",
      "    133        \u001b[36m0.4911\u001b[0m        \u001b[32m1.1022\u001b[0m  0.0748\n",
      "    134        \u001b[36m0.4902\u001b[0m        \u001b[32m1.1010\u001b[0m  0.0792\n",
      "    135        \u001b[36m0.4894\u001b[0m        \u001b[32m1.0998\u001b[0m  0.0822\n",
      "    136        \u001b[36m0.4885\u001b[0m        \u001b[32m1.0987\u001b[0m  0.0766\n",
      "    137        \u001b[36m0.4876\u001b[0m        \u001b[32m1.0976\u001b[0m  0.0758\n",
      "    138        \u001b[36m0.4868\u001b[0m        \u001b[32m1.0966\u001b[0m  0.0910\n",
      "    139        \u001b[36m0.4859\u001b[0m        \u001b[32m1.0957\u001b[0m  0.1047\n",
      "    140        \u001b[36m0.4851\u001b[0m        \u001b[32m1.0948\u001b[0m  0.1008\n",
      "    141        \u001b[36m0.4843\u001b[0m        \u001b[32m1.0939\u001b[0m  0.1081\n",
      "    142        \u001b[36m0.4835\u001b[0m        \u001b[32m1.0931\u001b[0m  0.1486\n",
      "    143        \u001b[36m0.4827\u001b[0m        \u001b[32m1.0923\u001b[0m  0.1059\n",
      "    144        \u001b[36m0.4820\u001b[0m        \u001b[32m1.0916\u001b[0m  0.0817\n",
      "    145        \u001b[36m0.4812\u001b[0m        \u001b[32m1.0910\u001b[0m  0.0810\n",
      "    146        \u001b[36m0.4805\u001b[0m        \u001b[32m1.0904\u001b[0m  0.0793\n",
      "    147        \u001b[36m0.4798\u001b[0m        \u001b[32m1.0899\u001b[0m  0.0976\n",
      "    148        \u001b[36m0.4791\u001b[0m        \u001b[32m1.0894\u001b[0m  0.0835\n",
      "    149        \u001b[36m0.4784\u001b[0m        \u001b[32m1.0890\u001b[0m  0.0928\n",
      "    150        \u001b[36m0.4777\u001b[0m        \u001b[32m1.0887\u001b[0m  0.0843\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m4.1827\u001b[0m        \u001b[32m3.6853\u001b[0m  0.1019\n",
      "      2        4.2770        \u001b[32m2.5203\u001b[0m  0.0952\n",
      "      3        \u001b[36m3.5096\u001b[0m        2.5691  0.1250\n",
      "      4        \u001b[36m3.3319\u001b[0m        \u001b[32m2.1204\u001b[0m  0.1121\n",
      "      5        \u001b[36m3.0895\u001b[0m        2.1763  0.1204\n",
      "      6        3.1149        \u001b[32m1.9718\u001b[0m  0.1075\n",
      "      7        \u001b[36m3.0264\u001b[0m        2.1589  0.1168\n",
      "      8        3.0761        \u001b[32m1.8573\u001b[0m  0.1300\n",
      "      9        \u001b[36m2.9537\u001b[0m        2.5362  0.1172\n",
      "     10        3.0651        2.1539  0.1246\n",
      "     11        \u001b[36m2.8539\u001b[0m        3.6739  0.1210\n",
      "     12        3.3286        3.9099  0.1177\n",
      "     13        \u001b[36m2.7603\u001b[0m        4.1634  0.1081\n",
      "     14        3.5466        2.4119  0.1179\n",
      "     15        2.9445        2.0562  0.1189\n",
      "     16        2.8887        1.9524  0.1175\n",
      "     17        2.8956        2.7327  0.1079\n",
      "     18        2.8984        2.7222  0.0994\n",
      "     19        2.8735        4.4493  0.1229\n",
      "     20        3.2481        5.1099  0.1171\n",
      "     21        2.9369        5.3715  0.1173\n",
      "     22        3.8088        2.1832  0.1143\n",
      "     23        \u001b[36m2.5099\u001b[0m        \u001b[32m1.6278\u001b[0m  0.1190\n",
      "     24        2.9641        \u001b[32m1.0832\u001b[0m  0.1107\n",
      "     25        2.6743        2.1256  0.1107\n",
      "     26        2.8177        \u001b[32m1.0252\u001b[0m  0.1103\n",
      "     27        2.6603        \u001b[32m0.8066\u001b[0m  0.1108\n",
      "     28        2.6473        2.5330  0.1189\n",
      "     29        2.6909        4.5316  0.1203\n",
      "     30        2.6512        5.2100  0.1109\n",
      "     31        3.3212        2.6981  0.1091\n",
      "     32        \u001b[36m2.2142\u001b[0m        2.5410  0.0955\n",
      "     33        2.2440        4.1085  0.1165\n",
      "     34        \u001b[36m1.3749\u001b[0m        3.8395  0.1156\n",
      "     35        2.3672        2.0204  0.1042\n",
      "     36        2.5610        0.8684  0.1077\n",
      "     37        \u001b[36m0.9741\u001b[0m        1.5090  0.1328\n",
      "     38        2.1758        \u001b[32m0.6874\u001b[0m  0.1310\n",
      "     39        1.0255        2.3310  0.1217\n",
      "     40        2.4804        1.1881  0.1104\n",
      "     41        1.3598        2.6903  0.1178\n",
      "     42        1.6036        2.6064  0.1163\n",
      "     43        \u001b[36m0.6839\u001b[0m        3.2126  0.1192\n",
      "     44        1.7154        7.3268  0.1036\n",
      "     45        1.3241        4.9166  0.0829\n",
      "     46        2.5799        2.5592  0.1101\n",
      "     47        1.8804        2.6080  0.1067\n",
      "     48        3.0133        3.5172  0.1098\n",
      "     49        2.0544        1.7125  0.1140\n",
      "     50        1.7487        4.0476  0.1174\n",
      "     51        1.2320        4.0398  0.1093\n",
      "     52        2.0614        1.4698  0.1193\n",
      "     53        1.3840        0.7345  0.1050\n",
      "     54        0.7409        0.7955  0.1051\n",
      "     55        1.3585        \u001b[32m0.5493\u001b[0m  0.1102\n",
      "     56        \u001b[36m0.6504\u001b[0m        0.9171  0.1291\n",
      "     57        1.1987        \u001b[32m0.4228\u001b[0m  0.1098\n",
      "     58        \u001b[36m0.5831\u001b[0m        0.5404  0.0974\n",
      "     59        0.9367        0.4440  0.1202\n",
      "     60        \u001b[36m0.5273\u001b[0m        0.9157  0.1173\n",
      "     61        1.1199        0.5557  0.1103\n",
      "     62        0.5490        1.2584  0.1192\n",
      "     63        1.2554        1.0875  0.1131\n",
      "     64        0.5332        2.4293  0.1194\n",
      "     65        1.2663        6.1494  0.1164\n",
      "     66        0.7678        4.8322  0.1144\n",
      "     67        2.4731        2.5761  0.1103\n",
      "     68        1.6144        1.7365  0.1115\n",
      "     69        1.2329        1.7345  0.0996\n",
      "     70        0.9228        1.8943  0.1106\n",
      "     71        1.8349        1.6044  0.1099\n",
      "     72        0.8449        3.8179  0.1069\n",
      "     73        1.5678        6.6582  0.1178\n",
      "     74        1.5443        2.6865  0.1092\n",
      "     75        1.2761        2.5757  0.1289\n",
      "     76        1.1924        \u001b[32m0.3851\u001b[0m  0.1270\n",
      "     77        0.6335        \u001b[32m0.2567\u001b[0m  0.1229\n",
      "     78        1.2318        0.6033  0.1232\n",
      "     79        0.7032        0.9864  0.1181\n",
      "     80        1.0781        3.4770  0.1197\n",
      "     81        0.6184        3.4937  0.1202\n",
      "     82        1.4570        2.8547  0.1118\n",
      "     83        1.1972        0.6384  0.1164\n",
      "     84        0.6208        2.5430  0.1255\n",
      "     85        0.9909        1.1335  0.1312\n",
      "     86        1.0243        1.7035  0.1179\n",
      "     87        1.5277        0.5594  0.1236\n",
      "     88        0.9753        0.3550  0.0907\n",
      "     89        0.9323        0.8161  0.0863\n",
      "     90        0.5644        1.5879  0.0951\n",
      "     91        0.8386        6.2604  0.1194\n",
      "     92        0.6124        4.5281  0.1100\n",
      "     93        2.1650        2.0764  0.1239\n",
      "     94        0.7464        1.8929  0.1215\n",
      "     95        1.1503        7.2877  0.1219\n",
      "     96        1.0536        4.2592  0.1141\n",
      "     97        2.4017        3.7806  0.1128\n",
      "     98        2.1713        3.3839  0.1191\n",
      "     99        1.9857        3.8661  0.1016\n",
      "    100        2.1823        2.1981  0.1224\n",
      "    101        1.6941        3.3711  0.1260\n",
      "    102        2.5631        1.7031  0.1121\n",
      "    103        1.2582        0.8208  0.1298\n",
      "    104        1.1568        1.0446  0.0823\n",
      "    105        0.8457        0.3702  0.0761\n",
      "    106        0.9650        0.6722  0.0828\n",
      "    107        0.7600        2.2749  0.0866\n",
      "    108        1.1518        4.8181  0.0872\n",
      "    109        0.7133        3.9872  0.0841\n",
      "    110        1.8687        2.1923  0.0834\n",
      "    111        2.3039        1.0905  0.0782\n",
      "    112        1.3894        0.4165  0.0858\n",
      "    113        1.2127        5.9363  0.0785\n",
      "    114        1.1079        4.9675  0.0825\n",
      "    115        2.2088        1.7782  0.1035\n",
      "    116        1.6360        1.4424  0.1028\n",
      "    117        0.8113        1.8804  0.1111\n",
      "    118        1.1237        8.8880  0.1197\n",
      "    119        1.3912        4.4822  0.1250\n",
      "    120        2.7216        3.4621  0.1217\n",
      "    121        2.1422        2.9764  0.1289\n",
      "    122        1.7660        3.6988  0.1200\n",
      "    123        1.6524        4.6129  0.1114\n",
      "    124        2.3618        1.8197  0.1087\n",
      "    125        1.4144        2.8006  0.1178\n",
      "    126        1.4422        3.1649  0.1094\n",
      "    127        1.6876        2.5901  0.1109\n",
      "    128        1.9687        1.0456  0.1155\n",
      "    129        1.4024        0.3092  0.1133\n",
      "    130        1.3823        0.8460  0.1222\n",
      "    131        1.2298        0.3615  0.1209\n",
      "    132        1.2481        0.9889  0.1195\n",
      "    133        1.3086        0.4257  0.1304\n",
      "    134        1.3287        1.5639  0.0936\n",
      "    135        1.4470        0.5566  0.1207\n",
      "    136        1.4573        3.5025  0.1205\n",
      "    137        1.7388        0.8865  0.1112\n",
      "    138        1.5881        6.0263  0.1199\n",
      "    139        2.1699        2.4661  0.0926\n",
      "    140        1.8982        6.0271  0.1087\n",
      "    141        2.5880        1.5839  0.1205\n",
      "    142        1.9031       10.9525  0.1133\n",
      "    143        2.3847        4.2754  0.1297\n",
      "    144        2.3737        3.2686  0.1088\n",
      "    145        1.6283        2.2055  0.1036\n",
      "    146        1.8069        4.2276  0.1188\n",
      "    147        2.5541        2.4984  0.1196\n",
      "    148        2.0865        5.7785  0.1044\n",
      "    149        2.6217        0.9674  0.1194\n",
      "    150        1.9464       13.3844  0.1120\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m1.9783\u001b[0m        \u001b[32m2.6602\u001b[0m  0.1091\n",
      "      2        2.6375        2.6800  0.1192\n",
      "      3        2.9504        5.2635  0.1375\n",
      "      4        3.0722        3.5350  0.1179\n",
      "      5        2.1357        3.7182  0.1172\n",
      "      6        2.1676        3.9784  0.1177\n",
      "      7        2.1485        3.5528  0.1135\n",
      "      8        2.0628        3.4023  0.1111\n",
      "      9        \u001b[36m1.9067\u001b[0m        2.8778  0.0953\n",
      "     10        \u001b[36m1.7113\u001b[0m        2.7611  0.1116\n",
      "     11        \u001b[36m1.6513\u001b[0m        2.8286  0.1074\n",
      "     12        1.6571        \u001b[32m2.5575\u001b[0m  0.1184\n",
      "     13        \u001b[36m1.5123\u001b[0m        \u001b[32m2.5198\u001b[0m  0.1064\n",
      "     14        \u001b[36m1.4805\u001b[0m        3.4215  0.1071\n",
      "     15        1.6410        \u001b[32m1.9430\u001b[0m  0.1106\n",
      "     16        \u001b[36m1.0495\u001b[0m        4.4343  0.1129\n",
      "     17        2.0616        2.0192  0.0994\n",
      "     18        \u001b[36m0.9119\u001b[0m        3.4348  0.1233\n",
      "     19        1.9668        \u001b[32m1.5879\u001b[0m  0.1102\n",
      "     20        1.0733        2.0346  0.1098\n",
      "     21        1.2060        1.9703  0.1212\n",
      "     22        1.0319        \u001b[32m0.6508\u001b[0m  0.1090\n",
      "     23        \u001b[36m0.6300\u001b[0m        4.6991  0.1179\n",
      "     24        1.5659        4.3248  0.1043\n",
      "     25        0.6599        3.6870  0.1190\n",
      "     26        1.8549        3.4150  0.1157\n",
      "     27        0.9737        2.8659  0.1072\n",
      "     28        1.6035        1.6351  0.1132\n",
      "     29        1.0399        0.8075  0.1214\n",
      "     30        0.7407        1.2675  0.1141\n",
      "     31        0.7436        1.6920  0.1186\n",
      "     32        0.7934        \u001b[32m0.2663\u001b[0m  0.1260\n",
      "     33        \u001b[36m0.4082\u001b[0m        2.1298  0.1190\n",
      "     34        0.8645        1.7699  0.1497\n",
      "     35        \u001b[36m0.3569\u001b[0m        2.7284  0.0907\n",
      "     36        1.0467       13.4243  0.0917\n",
      "     37        1.1603        4.3123  0.1191\n",
      "     38        2.3041        1.7450  0.1219\n",
      "     39        1.1013        1.0603  0.1198\n",
      "     40        0.8917        0.8121  0.1224\n",
      "     41        0.7833        0.7489  0.1299\n",
      "     42        0.5943        1.4021  0.1229\n",
      "     43        0.8204        2.7269  0.1120\n",
      "     44        0.6175        4.6057  0.1017\n",
      "     45        2.2723        2.7418  0.1092\n",
      "     46        0.6909        3.2943  0.1173\n",
      "     47        1.6367        3.8756  0.0971\n",
      "     48        0.9014        3.1013  0.1212\n",
      "     49        1.5468        1.8255  0.1280\n",
      "     50        0.9633        0.6433  0.0999\n",
      "     51        0.5877        0.4006  0.1160\n",
      "     52        0.5165        0.9828  0.1056\n",
      "     53        0.3866        1.7368  0.1269\n",
      "     54        0.7591        6.1190  0.1246\n",
      "     55        0.6761        5.7338  0.1156\n",
      "     56        2.7059        2.5421  0.1194\n",
      "     57        1.1670        7.5805  0.1089\n",
      "     58        1.2373        3.5614  0.1180\n",
      "     59        1.7203        1.7807  0.1108\n",
      "     60        1.0425        1.2598  0.1200\n",
      "     61        0.8643        0.7556  0.1072\n",
      "     62        0.6782        1.6003  0.1257\n",
      "     63        0.4293        2.8265  0.1286\n",
      "     64        1.1146       11.0428  0.1144\n",
      "     65        1.1237        3.4609  0.1264\n",
      "     66        1.7776        1.9336  0.1214\n",
      "     67        1.0212        1.2689  0.1218\n",
      "     68        0.8455        0.8170  0.1191\n",
      "     69        0.7323        1.3987  0.1185\n",
      "     70        0.5640        2.0798  0.1334\n",
      "     71        0.8969        9.4368  0.1010\n",
      "     72        0.8793        4.6860  0.1231\n",
      "     73        2.3784        1.2604  0.1185\n",
      "     74        0.8798        2.5761  0.1337\n",
      "     75        0.8497        1.4998  0.1023\n",
      "     76        0.9289        3.2306  0.0858\n",
      "     77        0.7275        2.6023  0.0899\n",
      "     78        1.3098        1.8596  0.1097\n",
      "     79        0.7240        0.6315  0.1100\n",
      "     80        0.6637        1.7713  0.0937\n",
      "     81        0.5091        1.3900  0.0790\n",
      "     82        0.8428        4.6634  0.0694\n",
      "     83        0.7813        3.4684  0.0805\n",
      "     84        1.7022        1.0078  0.0789\n",
      "     85        0.6495        0.6764  0.0762\n",
      "     86        0.5252        0.2931  0.0810\n",
      "     87        0.4939        1.3559  0.1014\n",
      "     88        0.4593        1.0991  0.1210\n",
      "     89        0.7432        4.7937  0.1161\n",
      "     90        0.7373        2.9304  0.1198\n",
      "     91        1.5150        0.9185  0.1111\n",
      "     92        0.5905        0.5094  0.1019\n",
      "     93        0.5142        \u001b[32m0.2617\u001b[0m  0.0980\n",
      "     94        0.4560        0.5739  0.1099\n",
      "     95        0.4405        0.3566  0.1024\n",
      "     96        0.5130        1.7641  0.1249\n",
      "     97        0.4825        1.2557  0.0996\n",
      "     98        0.7983        4.9237  0.1026\n",
      "     99        0.7679        2.7207  0.1121\n",
      "    100        1.4843        0.6651  0.1208\n",
      "    101        0.5645        0.7935  0.1033\n",
      "    102        0.4974        0.3994  0.1119\n",
      "    103        0.5260        2.2026  0.1092\n",
      "    104        0.5193        1.3967  0.1198\n",
      "    105        0.8446        4.4700  0.1117\n",
      "    106        0.7766        2.5003  0.1295\n",
      "    107        1.3855        0.9183  0.1004\n",
      "    108        0.5680        0.4415  0.1191\n",
      "    109        0.5046        \u001b[32m0.2477\u001b[0m  0.1272\n",
      "    110        0.4397        0.4745  0.1302\n",
      "    111        0.4268        0.3171  0.1124\n",
      "    112        0.4979        1.3147  0.1178\n",
      "    113        0.4386        0.9262  0.1302\n",
      "    114        0.7100        3.8165  0.1000\n",
      "    115        0.6445        1.8854  0.1015\n",
      "    116        1.1029        2.0830  0.1138\n",
      "    117        0.6487        0.8443  0.1124\n",
      "    118        0.7403        2.0099  0.1310\n",
      "    119        0.5554        0.8024  0.1131\n",
      "    120        0.6934        2.3844  0.1110\n",
      "    121        0.5669        0.9913  0.1168\n",
      "    122        0.7464        2.6099  0.1131\n",
      "    123        0.6024        1.1421  0.1202\n",
      "    124        0.7926        2.6171  0.1337\n",
      "    125        0.6170        1.1578  0.1107\n",
      "    126        0.7930        2.5045  0.1099\n",
      "    127        0.6046        1.0020  0.1172\n",
      "    128        0.7457        2.1430  0.1584\n",
      "    129        0.5567        0.6517  0.0796\n",
      "    130        0.6462        1.4525  0.0907\n",
      "    131        0.4904        0.3470  0.1206\n",
      "    132        0.5423        0.8031  0.1115\n",
      "    133        0.4547        0.2726  0.1255\n",
      "    134        0.4947        0.6448  0.1134\n",
      "    135        0.4409        0.2892  0.1237\n",
      "    136        0.4930        0.8183  0.1159\n",
      "    137        0.4567        0.3742  0.1189\n",
      "    138        0.5465        0.9264  0.1124\n",
      "    139        0.4650        0.5150  0.1133\n",
      "    140        0.5866        1.8496  0.1137\n",
      "    141        0.4979        0.8753  0.1281\n",
      "    142        0.7133        2.2919  0.1372\n",
      "    143        0.5824        0.8617  0.1209\n",
      "    144        0.7015        2.0399  0.1127\n",
      "    145        0.4253        0.8169  0.1284\n",
      "    146        0.6652        2.2092  0.1196\n",
      "    147        0.4785        0.7081  0.0922\n",
      "    148        0.6940        1.5436  0.1106\n",
      "    149        0.4883        0.3797  0.1204\n",
      "    150        0.5628        0.7209  0.1292\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m4.0731\u001b[0m        \u001b[32m1.4684\u001b[0m  0.1140\n",
      "      2        5.3133        8.1300  0.1249\n",
      "      3        7.7844        \u001b[32m1.2572\u001b[0m  0.1023\n",
      "      4        4.8227        2.4631  0.1087\n",
      "      5        4.2289        4.5875  0.1030\n",
      "      6        \u001b[36m3.8306\u001b[0m        3.8364  0.0906\n",
      "      7        \u001b[36m3.3822\u001b[0m        2.2078  0.0888\n",
      "      8        \u001b[36m2.6675\u001b[0m        1.6786  0.1074\n",
      "      9        \u001b[36m2.2432\u001b[0m        1.6042  0.1095\n",
      "     10        \u001b[36m1.4651\u001b[0m        1.6818  0.1059\n",
      "     11        \u001b[36m1.1741\u001b[0m        1.7041  0.1095\n",
      "     12        1.4150        1.6016  0.0933\n",
      "     13        1.6745        1.4092  0.1012\n",
      "     14        1.3068        1.3850  0.0950\n",
      "     15        \u001b[36m0.9642\u001b[0m        1.4612  0.0952\n",
      "     16        \u001b[36m0.8576\u001b[0m        1.5195  0.1058\n",
      "     17        0.9557        1.5315  0.1073\n",
      "     18        1.0913        1.4900  0.1159\n",
      "     19        1.2809        1.3971  0.1182\n",
      "     20        1.3717        1.2944  0.1379\n",
      "     21        1.0875        1.3047  0.1130\n",
      "     22        \u001b[36m0.8138\u001b[0m        1.3869  0.1179\n",
      "     23        \u001b[36m0.7292\u001b[0m        1.4525  0.1612\n",
      "     24        0.7631        1.4786  0.0963\n",
      "     25        0.8315        1.4678  0.0894\n",
      "     26        0.9168        1.4325  0.1075\n",
      "     27        1.0185        1.3798  0.1073\n",
      "     28        1.0756        1.3254  0.1147\n",
      "     29        0.9912        1.3087  0.1048\n",
      "     30        0.8244        1.3402  0.0869\n",
      "     31        \u001b[36m0.7118\u001b[0m        1.3840  0.1047\n",
      "     32        \u001b[36m0.6780\u001b[0m        1.4124  0.1066\n",
      "     33        0.6916        1.4200  0.1090\n",
      "     34        0.7258        1.4113  0.1067\n",
      "     35        0.7681        1.3925  0.1078\n",
      "     36        0.8081        1.3686  0.0962\n",
      "     37        0.8276        1.3461  0.1014\n",
      "     38        0.8080        1.3334  0.1188\n",
      "     39        0.7550        1.3351  0.1098\n",
      "     40        0.6969        1.3464  0.1087\n",
      "     41        \u001b[36m0.6564\u001b[0m        1.3583  0.1149\n",
      "     42        \u001b[36m0.6379\u001b[0m        1.3651  0.1089\n",
      "     43        \u001b[36m0.6354\u001b[0m        1.3656  0.0940\n",
      "     44        0.6421        1.3612  0.0884\n",
      "     45        0.6521        1.3537  0.0961\n",
      "     46        0.6608        1.3449  0.1041\n",
      "     47        0.6642        1.3365  0.1291\n",
      "     48        0.6600        1.3299  0.0989\n",
      "     49        0.6486        1.3258  0.1320\n",
      "     50        \u001b[36m0.6331\u001b[0m        1.3239  0.1180\n",
      "     51        \u001b[36m0.6175\u001b[0m        1.3232  0.0949\n",
      "     52        \u001b[36m0.6046\u001b[0m        1.3226  0.1073\n",
      "     53        \u001b[36m0.5957\u001b[0m        1.3213  0.1200\n",
      "     54        \u001b[36m0.5905\u001b[0m        1.3189  0.1414\n",
      "     55        \u001b[36m0.5880\u001b[0m        1.3156  0.1531\n",
      "     56        \u001b[36m0.5870\u001b[0m        1.3116  0.1290\n",
      "     57        \u001b[36m0.5864\u001b[0m        1.3072  0.1286\n",
      "     58        \u001b[36m0.5853\u001b[0m        1.3029  0.1337\n",
      "     59        \u001b[36m0.5833\u001b[0m        1.2987  0.1159\n",
      "     60        \u001b[36m0.5802\u001b[0m        1.2948  0.1208\n",
      "     61        \u001b[36m0.5764\u001b[0m        1.2913  0.2901\n",
      "     62        \u001b[36m0.5722\u001b[0m        1.2880  0.1224\n",
      "     63        \u001b[36m0.5682\u001b[0m        1.2849  0.1615\n",
      "     64        \u001b[36m0.5646\u001b[0m        1.2818  0.1431\n",
      "     65        \u001b[36m0.5616\u001b[0m        1.2786  0.1052\n",
      "     66        \u001b[36m0.5592\u001b[0m        1.2753  0.1994\n",
      "     67        \u001b[36m0.5573\u001b[0m        1.2719  0.1266\n",
      "     68        \u001b[36m0.5558\u001b[0m        1.2684  0.1389\n",
      "     69        \u001b[36m0.5543\u001b[0m        1.2649  0.1077\n",
      "     70        \u001b[36m0.5529\u001b[0m        1.2614  0.1017\n",
      "     71        \u001b[36m0.5515\u001b[0m        1.2580  0.0924\n",
      "     72        \u001b[36m0.5500\u001b[0m        \u001b[32m1.2546\u001b[0m  0.1033\n",
      "     73        \u001b[36m0.5485\u001b[0m        \u001b[32m1.2513\u001b[0m  0.1077\n",
      "     74        \u001b[36m0.5470\u001b[0m        \u001b[32m1.2480\u001b[0m  0.1073\n",
      "     75        \u001b[36m0.5455\u001b[0m        \u001b[32m1.2448\u001b[0m  0.0916\n",
      "     76        \u001b[36m0.5441\u001b[0m        \u001b[32m1.2415\u001b[0m  0.1030\n",
      "     77        \u001b[36m0.5428\u001b[0m        \u001b[32m1.2383\u001b[0m  0.0925\n",
      "     78        \u001b[36m0.5416\u001b[0m        \u001b[32m1.2351\u001b[0m  0.1092\n",
      "     79        \u001b[36m0.5405\u001b[0m        \u001b[32m1.2319\u001b[0m  0.0947\n",
      "     80        \u001b[36m0.5395\u001b[0m        \u001b[32m1.2287\u001b[0m  0.1005\n",
      "     81        \u001b[36m0.5385\u001b[0m        \u001b[32m1.2255\u001b[0m  0.0984\n",
      "     82        \u001b[36m0.5375\u001b[0m        \u001b[32m1.2223\u001b[0m  0.1237\n",
      "     83        \u001b[36m0.5366\u001b[0m        \u001b[32m1.2192\u001b[0m  0.1427\n",
      "     84        \u001b[36m0.5356\u001b[0m        \u001b[32m1.2161\u001b[0m  0.1013\n",
      "     85        \u001b[36m0.5347\u001b[0m        \u001b[32m1.2130\u001b[0m  0.1181\n",
      "     86        \u001b[36m0.5338\u001b[0m        \u001b[32m1.2099\u001b[0m  0.1199\n",
      "     87        \u001b[36m0.5329\u001b[0m        \u001b[32m1.2068\u001b[0m  0.1290\n",
      "     88        \u001b[36m0.5320\u001b[0m        \u001b[32m1.2038\u001b[0m  0.1138\n",
      "     89        \u001b[36m0.5311\u001b[0m        \u001b[32m1.2008\u001b[0m  0.1083\n",
      "     90        \u001b[36m0.5303\u001b[0m        \u001b[32m1.1978\u001b[0m  0.1160\n",
      "     91        \u001b[36m0.5294\u001b[0m        \u001b[32m1.1948\u001b[0m  0.0936\n",
      "     92        \u001b[36m0.5286\u001b[0m        \u001b[32m1.1918\u001b[0m  0.0969\n",
      "     93        \u001b[36m0.5278\u001b[0m        \u001b[32m1.1889\u001b[0m  0.1048\n",
      "     94        \u001b[36m0.5269\u001b[0m        \u001b[32m1.1860\u001b[0m  0.1008\n",
      "     95        \u001b[36m0.5261\u001b[0m        \u001b[32m1.1831\u001b[0m  0.0983\n",
      "     96        \u001b[36m0.5253\u001b[0m        \u001b[32m1.1803\u001b[0m  0.1093\n",
      "     97        \u001b[36m0.5245\u001b[0m        \u001b[32m1.1774\u001b[0m  0.0911\n",
      "     98        \u001b[36m0.5236\u001b[0m        \u001b[32m1.1746\u001b[0m  0.1097\n",
      "     99        \u001b[36m0.5228\u001b[0m        \u001b[32m1.1719\u001b[0m  0.1380\n",
      "    100        \u001b[36m0.5219\u001b[0m        \u001b[32m1.1691\u001b[0m  0.1160\n",
      "    101        \u001b[36m0.5211\u001b[0m        \u001b[32m1.1664\u001b[0m  0.1408\n",
      "    102        \u001b[36m0.5202\u001b[0m        \u001b[32m1.1637\u001b[0m  0.1005\n",
      "    103        \u001b[36m0.5194\u001b[0m        \u001b[32m1.1611\u001b[0m  0.1041\n",
      "    104        \u001b[36m0.5185\u001b[0m        \u001b[32m1.1585\u001b[0m  0.1317\n",
      "    105        \u001b[36m0.5176\u001b[0m        \u001b[32m1.1559\u001b[0m  0.1009\n",
      "    106        \u001b[36m0.5167\u001b[0m        \u001b[32m1.1534\u001b[0m  0.1069\n",
      "    107        \u001b[36m0.5158\u001b[0m        \u001b[32m1.1509\u001b[0m  0.1112\n",
      "    108        \u001b[36m0.5149\u001b[0m        \u001b[32m1.1485\u001b[0m  0.1208\n",
      "    109        \u001b[36m0.5140\u001b[0m        \u001b[32m1.1460\u001b[0m  0.1063\n",
      "    110        \u001b[36m0.5131\u001b[0m        \u001b[32m1.1437\u001b[0m  0.1118\n",
      "    111        \u001b[36m0.5121\u001b[0m        \u001b[32m1.1414\u001b[0m  0.0990\n",
      "    112        \u001b[36m0.5112\u001b[0m        \u001b[32m1.1391\u001b[0m  0.1195\n",
      "    113        \u001b[36m0.5103\u001b[0m        \u001b[32m1.1368\u001b[0m  0.1108\n",
      "    114        \u001b[36m0.5093\u001b[0m        \u001b[32m1.1347\u001b[0m  0.1188\n",
      "    115        \u001b[36m0.5083\u001b[0m        \u001b[32m1.1325\u001b[0m  0.1103\n",
      "    116        \u001b[36m0.5074\u001b[0m        \u001b[32m1.1304\u001b[0m  0.1221\n",
      "    117        \u001b[36m0.5064\u001b[0m        \u001b[32m1.1284\u001b[0m  0.1044\n",
      "    118        \u001b[36m0.5054\u001b[0m        \u001b[32m1.1264\u001b[0m  0.1031\n",
      "    119        \u001b[36m0.5045\u001b[0m        \u001b[32m1.1244\u001b[0m  0.1059\n",
      "    120        \u001b[36m0.5035\u001b[0m        \u001b[32m1.1225\u001b[0m  0.0945\n",
      "    121        \u001b[36m0.5025\u001b[0m        \u001b[32m1.1206\u001b[0m  0.1090\n",
      "    122        \u001b[36m0.5015\u001b[0m        \u001b[32m1.1188\u001b[0m  0.0979\n",
      "    123        \u001b[36m0.5006\u001b[0m        \u001b[32m1.1171\u001b[0m  0.1136\n",
      "    124        \u001b[36m0.4996\u001b[0m        \u001b[32m1.1154\u001b[0m  0.1077\n",
      "    125        \u001b[36m0.4986\u001b[0m        \u001b[32m1.1137\u001b[0m  0.1071\n",
      "    126        \u001b[36m0.4977\u001b[0m        \u001b[32m1.1121\u001b[0m  0.1122\n",
      "    127        \u001b[36m0.4967\u001b[0m        \u001b[32m1.1105\u001b[0m  0.1100\n",
      "    128        \u001b[36m0.4958\u001b[0m        \u001b[32m1.1090\u001b[0m  0.0996\n",
      "    129        \u001b[36m0.4948\u001b[0m        \u001b[32m1.1076\u001b[0m  0.0829\n",
      "    130        \u001b[36m0.4939\u001b[0m        \u001b[32m1.1061\u001b[0m  0.0745\n",
      "    131        \u001b[36m0.4930\u001b[0m        \u001b[32m1.1048\u001b[0m  0.0904\n",
      "    132        \u001b[36m0.4920\u001b[0m        \u001b[32m1.1035\u001b[0m  0.0941\n",
      "    133        \u001b[36m0.4911\u001b[0m        \u001b[32m1.1022\u001b[0m  0.0975\n",
      "    134        \u001b[36m0.4902\u001b[0m        \u001b[32m1.1010\u001b[0m  0.1905\n",
      "    135        \u001b[36m0.4894\u001b[0m        \u001b[32m1.0998\u001b[0m  0.1113\n",
      "    136        \u001b[36m0.4885\u001b[0m        \u001b[32m1.0987\u001b[0m  0.0803\n",
      "    137        \u001b[36m0.4876\u001b[0m        \u001b[32m1.0976\u001b[0m  0.0858\n",
      "    138        \u001b[36m0.4868\u001b[0m        \u001b[32m1.0966\u001b[0m  0.0761\n",
      "    139        \u001b[36m0.4859\u001b[0m        \u001b[32m1.0957\u001b[0m  0.0854\n",
      "    140        \u001b[36m0.4851\u001b[0m        \u001b[32m1.0948\u001b[0m  0.0910\n",
      "    141        \u001b[36m0.4843\u001b[0m        \u001b[32m1.0939\u001b[0m  0.0992\n",
      "    142        \u001b[36m0.4835\u001b[0m        \u001b[32m1.0931\u001b[0m  0.1085\n",
      "    143        \u001b[36m0.4827\u001b[0m        \u001b[32m1.0923\u001b[0m  0.1176\n",
      "    144        \u001b[36m0.4820\u001b[0m        \u001b[32m1.0916\u001b[0m  0.1087\n",
      "    145        \u001b[36m0.4812\u001b[0m        \u001b[32m1.0910\u001b[0m  0.1197\n",
      "    146        \u001b[36m0.4805\u001b[0m        \u001b[32m1.0904\u001b[0m  0.1092\n",
      "    147        \u001b[36m0.4798\u001b[0m        \u001b[32m1.0899\u001b[0m  0.0916\n",
      "    148        \u001b[36m0.4791\u001b[0m        \u001b[32m1.0894\u001b[0m  0.1247\n",
      "    149        \u001b[36m0.4784\u001b[0m        \u001b[32m1.0890\u001b[0m  0.1172\n",
      "    150        \u001b[36m0.4777\u001b[0m        \u001b[32m1.0887\u001b[0m  0.0980\n",
      "    151        \u001b[36m0.4771\u001b[0m        \u001b[32m1.0884\u001b[0m  0.1122\n",
      "    152        \u001b[36m0.4765\u001b[0m        \u001b[32m1.0882\u001b[0m  0.1124\n",
      "    153        \u001b[36m0.4758\u001b[0m        \u001b[32m1.0880\u001b[0m  0.1138\n",
      "    154        \u001b[36m0.4752\u001b[0m        \u001b[32m1.0879\u001b[0m  0.0989\n",
      "    155        \u001b[36m0.4746\u001b[0m        \u001b[32m1.0879\u001b[0m  0.1002\n",
      "    156        \u001b[36m0.4741\u001b[0m        1.0879  0.1050\n",
      "    157        \u001b[36m0.4735\u001b[0m        1.0880  0.1152\n",
      "    158        \u001b[36m0.4730\u001b[0m        1.0882  0.0833\n",
      "    159        \u001b[36m0.4724\u001b[0m        1.0884  0.1109\n",
      "    160        \u001b[36m0.4719\u001b[0m        1.0886  0.1096\n",
      "    161        \u001b[36m0.4713\u001b[0m        1.0889  0.1158\n",
      "    162        \u001b[36m0.4708\u001b[0m        1.0893  0.1241\n",
      "    163        \u001b[36m0.4702\u001b[0m        1.0897  0.1108\n",
      "    164        \u001b[36m0.4696\u001b[0m        1.0901  0.1504\n",
      "    165        \u001b[36m0.4691\u001b[0m        1.0906  0.1019\n",
      "    166        \u001b[36m0.4685\u001b[0m        1.0911  0.1111\n",
      "    167        \u001b[36m0.4678\u001b[0m        1.0916  0.0878\n",
      "    168        \u001b[36m0.4672\u001b[0m        1.0921  0.0868\n",
      "    169        \u001b[36m0.4665\u001b[0m        1.0926  0.0831\n",
      "    170        \u001b[36m0.4658\u001b[0m        1.0932  0.0827\n",
      "    171        \u001b[36m0.4651\u001b[0m        1.0937  0.0843\n",
      "    172        \u001b[36m0.4643\u001b[0m        1.0943  0.0838\n",
      "    173        \u001b[36m0.4636\u001b[0m        1.0948  0.0819\n",
      "    174        \u001b[36m0.4627\u001b[0m        1.0954  0.0796\n",
      "    175        \u001b[36m0.4619\u001b[0m        1.0959  0.1005\n",
      "    176        \u001b[36m0.4610\u001b[0m        1.0965  0.1088\n",
      "    177        \u001b[36m0.4601\u001b[0m        1.0970  0.1083\n",
      "    178        \u001b[36m0.4591\u001b[0m        1.0975  0.1207\n",
      "    179        \u001b[36m0.4582\u001b[0m        1.0980  0.1001\n",
      "    180        \u001b[36m0.4572\u001b[0m        1.0985  0.1035\n",
      "    181        \u001b[36m0.4561\u001b[0m        1.0990  0.1186\n",
      "    182        \u001b[36m0.4551\u001b[0m        1.0995  0.1200\n",
      "    183        \u001b[36m0.4540\u001b[0m        1.1000  0.1057\n",
      "    184        \u001b[36m0.4529\u001b[0m        1.1005  0.1129\n",
      "    185        \u001b[36m0.4518\u001b[0m        1.1010  0.1148\n",
      "    186        \u001b[36m0.4507\u001b[0m        1.1016  0.1208\n",
      "    187        \u001b[36m0.4496\u001b[0m        1.1023  0.1185\n",
      "    188        \u001b[36m0.4485\u001b[0m        1.1031  0.1046\n",
      "    189        \u001b[36m0.4475\u001b[0m        1.1040  0.1000\n",
      "    190        \u001b[36m0.4466\u001b[0m        1.1051  0.0910\n",
      "    191        \u001b[36m0.4458\u001b[0m        1.1063  0.1145\n",
      "    192        \u001b[36m0.4454\u001b[0m        1.1077  0.1092\n",
      "    193        \u001b[36m0.4453\u001b[0m        1.1091  0.0981\n",
      "    194        0.4457        1.1106  0.1160\n",
      "    195        0.4467        1.1118  0.1213\n",
      "    196        0.4482        1.1126  0.1109\n",
      "    197        0.4500        1.1128  0.0990\n",
      "    198        0.4518        1.1123  0.1122\n",
      "    199        0.4532        1.1112  0.1252\n",
      "    200        0.4540        1.1095  0.0799\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m4.1827\u001b[0m        \u001b[32m3.6853\u001b[0m  0.0945\n",
      "      2        4.2770        \u001b[32m2.5203\u001b[0m  0.0953\n",
      "      3        \u001b[36m3.5096\u001b[0m        2.5691  0.1133\n",
      "      4        \u001b[36m3.3319\u001b[0m        \u001b[32m2.1204\u001b[0m  0.0904\n",
      "      5        \u001b[36m3.0895\u001b[0m        2.1763  0.1022\n",
      "      6        3.1149        \u001b[32m1.9718\u001b[0m  0.1152\n",
      "      7        \u001b[36m3.0264\u001b[0m        2.1589  0.1012\n",
      "      8        3.0761        \u001b[32m1.8573\u001b[0m  0.1008\n",
      "      9        \u001b[36m2.9537\u001b[0m        2.5362  0.1148\n",
      "     10        3.0651        2.1539  0.1214\n",
      "     11        \u001b[36m2.8539\u001b[0m        3.6739  0.0929\n",
      "     12        3.3286        3.9099  0.1184\n",
      "     13        \u001b[36m2.7603\u001b[0m        4.1634  0.1012\n",
      "     14        3.5466        2.4119  0.1249\n",
      "     15        2.9445        2.0562  0.1231\n",
      "     16        2.8887        1.9524  0.0977\n",
      "     17        2.8956        2.7327  0.1137\n",
      "     18        2.8984        2.7222  0.1133\n",
      "     19        2.8735        4.4493  0.0989\n",
      "     20        3.2481        5.1099  0.1134\n",
      "     21        2.9369        5.3715  0.1268\n",
      "     22        3.8088        2.1832  0.1135\n",
      "     23        \u001b[36m2.5099\u001b[0m        \u001b[32m1.6278\u001b[0m  0.1289\n",
      "     24        2.9641        \u001b[32m1.0832\u001b[0m  0.1056\n",
      "     25        2.6743        2.1256  0.1063\n",
      "     26        2.8177        \u001b[32m1.0252\u001b[0m  0.1163\n",
      "     27        2.6603        \u001b[32m0.8066\u001b[0m  0.1152\n",
      "     28        2.6473        2.5330  0.1002\n",
      "     29        2.6909        4.5316  0.1028\n",
      "     30        2.6512        5.2100  0.0999\n",
      "     31        3.3212        2.6981  0.1288\n",
      "     32        \u001b[36m2.2142\u001b[0m        2.5410  0.1512\n",
      "     33        2.2440        4.1085  0.0783\n",
      "     34        \u001b[36m1.3749\u001b[0m        3.8395  0.0913\n",
      "     35        2.3672        2.0204  0.0765\n",
      "     36        2.5610        0.8684  0.1055\n",
      "     37        \u001b[36m0.9741\u001b[0m        1.5090  0.1270\n",
      "     38        2.1758        \u001b[32m0.6874\u001b[0m  0.1089\n",
      "     39        1.0255        2.3310  0.1027\n",
      "     40        2.4804        1.1881  0.1181\n",
      "     41        1.3598        2.6903  0.1295\n",
      "     42        1.6036        2.6064  0.1140\n",
      "     43        \u001b[36m0.6839\u001b[0m        3.2126  0.1176\n",
      "     44        1.7154        7.3268  0.1107\n",
      "     45        1.3241        4.9166  0.0999\n",
      "     46        2.5799        2.5592  0.1014\n",
      "     47        1.8804        2.6080  0.1047\n",
      "     48        3.0133        3.5172  0.1136\n",
      "     49        2.0544        1.7125  0.1103\n",
      "     50        1.7487        4.0476  0.0997\n",
      "     51        1.2320        4.0398  0.1079\n",
      "     52        2.0614        1.4698  0.1132\n",
      "     53        1.3840        0.7345  0.1202\n",
      "     54        0.7409        0.7955  0.0926\n",
      "     55        1.3585        \u001b[32m0.5493\u001b[0m  0.1153\n",
      "     56        \u001b[36m0.6504\u001b[0m        0.9171  0.1242\n",
      "     57        1.1987        \u001b[32m0.4228\u001b[0m  0.1761\n",
      "     58        \u001b[36m0.5831\u001b[0m        0.5404  0.1260\n",
      "     59        0.9367        0.4440  0.1201\n",
      "     60        \u001b[36m0.5273\u001b[0m        0.9157  0.1179\n",
      "     61        1.1199        0.5557  0.1032\n",
      "     62        0.5490        1.2584  0.1103\n",
      "     63        1.2554        1.0875  0.0969\n",
      "     64        0.5332        2.4293  0.2119\n",
      "     65        1.2663        6.1494  0.2426\n",
      "     66        0.7678        4.8322  0.1252\n",
      "     67        2.4731        2.5761  0.1315\n",
      "     68        1.6144        1.7365  0.1350\n",
      "     69        1.2329        1.7345  0.0996\n",
      "     70        0.9228        1.8943  0.1129\n",
      "     71        1.8349        1.6044  0.0997\n",
      "     72        0.8449        3.8179  0.0956\n",
      "     73        1.5678        6.6582  0.1013\n",
      "     74        1.5443        2.6865  0.1281\n",
      "     75        1.2761        2.5757  0.1262\n",
      "     76        1.1924        \u001b[32m0.3851\u001b[0m  0.1172\n",
      "     77        0.6335        \u001b[32m0.2567\u001b[0m  0.1078\n",
      "     78        1.2318        0.6033  0.1144\n",
      "     79        0.7032        0.9864  0.1119\n",
      "     80        1.0781        3.4770  0.1117\n",
      "     81        0.6184        3.4937  0.1202\n",
      "     82        1.4570        2.8547  0.1138\n",
      "     83        1.1972        0.6384  0.1192\n",
      "     84        0.6208        2.5430  0.1192\n",
      "     85        0.9909        1.1335  0.0904\n",
      "     86        1.0243        1.7035  0.0873\n",
      "     87        1.5277        0.5594  0.1152\n",
      "     88        0.9753        0.3550  0.1081\n",
      "     89        0.9323        0.8161  0.0863\n",
      "     90        0.5644        1.5879  0.0867\n",
      "     91        0.8386        6.2604  0.0850\n",
      "     92        0.6124        4.5281  0.0945\n",
      "     93        2.1650        2.0764  0.1250\n",
      "     94        0.7464        1.8929  0.1402\n",
      "     95        1.1503        7.2877  0.1207\n",
      "     96        1.0536        4.2592  0.1050\n",
      "     97        2.4017        3.7806  0.1082\n",
      "     98        2.1713        3.3839  0.1023\n",
      "     99        1.9857        3.8661  0.1062\n",
      "    100        2.1823        2.1981  0.0848\n",
      "    101        1.6941        3.3711  0.1014\n",
      "    102        2.5631        1.7031  0.1120\n",
      "    103        1.2582        0.8208  0.0973\n",
      "    104        1.1568        1.0446  0.1067\n",
      "    105        0.8457        0.3702  0.1000\n",
      "    106        0.9650        0.6722  0.0880\n",
      "    107        0.7600        2.2749  0.1284\n",
      "    108        1.1518        4.8181  0.1098\n",
      "    109        0.7133        3.9872  0.1597\n",
      "    110        1.8687        2.1923  0.1302\n",
      "    111        2.3039        1.0905  0.1006\n",
      "    112        1.3894        0.4165  0.1028\n",
      "    113        1.2127        5.9363  0.1074\n",
      "    114        1.1079        4.9675  0.0979\n",
      "    115        2.2088        1.7782  0.1106\n",
      "    116        1.6360        1.4424  0.0999\n",
      "    117        0.8113        1.8804  0.1048\n",
      "    118        1.1237        8.8880  0.1051\n",
      "    119        1.3912        4.4822  0.1064\n",
      "    120        2.7216        3.4621  0.1246\n",
      "    121        2.1422        2.9764  0.1216\n",
      "    122        1.7660        3.6988  0.0979\n",
      "    123        1.6524        4.6129  0.1009\n",
      "    124        2.3618        1.8197  0.1025\n",
      "    125        1.4144        2.8006  0.1648\n",
      "    126        1.4422        3.1649  0.1377\n",
      "    127        1.6876        2.5901  0.1233\n",
      "    128        1.9687        1.0456  0.1335\n",
      "    129        1.4024        0.3092  0.1035\n",
      "    130        1.3823        0.8460  0.0953\n",
      "    131        1.2298        0.3615  0.1212\n",
      "    132        1.2481        0.9889  0.0864\n",
      "    133        1.3086        0.4257  0.1027\n",
      "    134        1.3287        1.5639  0.0817\n",
      "    135        1.4470        0.5566  0.1022\n",
      "    136        1.4573        3.5025  0.1257\n",
      "    137        1.7388        0.8865  0.1354\n",
      "    138        1.5881        6.0263  0.1202\n",
      "    139        2.1699        2.4661  0.1154\n",
      "    140        1.8982        6.0271  0.0970\n",
      "    141        2.5880        1.5839  0.1043\n",
      "    142        1.9031       10.9525  0.1014\n",
      "    143        2.3847        4.2754  0.1024\n",
      "    144        2.3737        3.2686  0.1009\n",
      "    145        1.6283        2.2055  0.1058\n",
      "    146        1.8069        4.2276  0.1142\n",
      "    147        2.5541        2.4984  0.0997\n",
      "    148        2.0865        5.7785  0.1153\n",
      "    149        2.6217        0.9674  0.1319\n",
      "    150        1.9464       13.3844  0.1200\n",
      "    151        3.1061        6.6763  0.1309\n",
      "    152        2.9029        4.1719  0.1041\n",
      "    153        2.3269        2.4632  0.1114\n",
      "    154        1.6804        3.8786  0.0909\n",
      "    155        2.3147        0.9838  0.1037\n",
      "    156        1.9595        7.2695  0.0880\n",
      "    157        2.0967        3.1739  0.0958\n",
      "    158        2.1226        5.2960  0.1048\n",
      "    159        1.8032        1.8615  0.1252\n",
      "    160        1.9098        7.4783  0.1086\n",
      "    161        2.8205        3.1540  0.1104\n",
      "    162        2.3601        4.3773  0.1278\n",
      "    163        1.5889        1.2137  0.1016\n",
      "    164        1.4321        8.2739  0.1212\n",
      "    165        2.9143        4.0268  0.1194\n",
      "    166        2.5676        4.4733  0.1399\n",
      "    167        1.5945        2.6099  0.1266\n",
      "    168        1.4480        4.8013  0.1156\n",
      "    169        2.5935        2.3284  0.1122\n",
      "    170        2.0306        7.3169  0.1360\n",
      "    171        2.6670        4.0973  0.1404\n",
      "    172        2.5574        4.6377  0.1181\n",
      "    173        1.5943        1.5309  0.1130\n",
      "    174        1.0039       10.5313  0.1202\n",
      "    175        2.6326        5.7127  0.0953\n",
      "    176        2.8923        3.6256  0.0891\n",
      "    177        1.3507        6.1637  0.0931\n",
      "    178        1.9345        6.4150  0.1029\n",
      "    179        3.3442        2.4139  0.1050\n",
      "    180        1.9140        5.8180  0.0891\n",
      "    181        2.5568        1.8452  0.0957\n",
      "    182        1.8648        6.7894  0.1323\n",
      "    183        2.0143        3.6182  0.1040\n",
      "    184        1.9995        5.6031  0.1314\n",
      "    185        2.2204        1.6143  0.1212\n",
      "    186        1.7279        8.5054  0.0915\n",
      "    187        2.6329        3.8434  0.1172\n",
      "    188        2.2245        4.9495  0.1169\n",
      "    189        1.6516        2.3202  0.1209\n",
      "    190        1.4304        9.7290  0.1131\n",
      "    191        2.7567        3.9822  0.1293\n",
      "    192        2.4564        3.2867  0.1189\n",
      "    193        1.4635        2.0877  0.1015\n",
      "    194        1.2971        4.9956  0.1027\n",
      "    195        2.4778        1.8335  0.0818\n",
      "    196        1.6968        4.0274  0.0943\n",
      "    197        1.6182        1.1375  0.0865\n",
      "    198        1.3806        7.5747  0.0818\n",
      "    199        1.9433        3.2847  0.0839\n",
      "    200        1.5650        8.1696  0.0862\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m1.9783\u001b[0m        \u001b[32m2.6602\u001b[0m  0.1050\n",
      "      2        2.6375        2.6800  0.1149\n",
      "      3        2.9504        5.2635  0.0987\n",
      "      4        3.0722        3.5350  0.1192\n",
      "      5        2.1357        3.7182  0.0983\n",
      "      6        2.1676        3.9784  0.1383\n",
      "      7        2.1485        3.5528  0.0986\n",
      "      8        2.0628        3.4023  0.1020\n",
      "      9        \u001b[36m1.9067\u001b[0m        2.8778  0.1081\n",
      "     10        \u001b[36m1.7113\u001b[0m        2.7611  0.1004\n",
      "     11        \u001b[36m1.6513\u001b[0m        2.8286  0.0962\n",
      "     12        1.6571        \u001b[32m2.5575\u001b[0m  0.0994\n",
      "     13        \u001b[36m1.5123\u001b[0m        \u001b[32m2.5198\u001b[0m  0.1345\n",
      "     14        \u001b[36m1.4805\u001b[0m        3.4215  0.1043\n",
      "     15        1.6410        \u001b[32m1.9430\u001b[0m  0.1301\n",
      "     16        \u001b[36m1.0495\u001b[0m        4.4343  0.0964\n",
      "     17        2.0616        2.0192  0.1057\n",
      "     18        \u001b[36m0.9119\u001b[0m        3.4348  0.1113\n",
      "     19        1.9668        \u001b[32m1.5879\u001b[0m  0.0951\n",
      "     20        1.0733        2.0346  0.1448\n",
      "     21        1.2060        1.9703  0.0920\n",
      "     22        1.0319        \u001b[32m0.6508\u001b[0m  0.1541\n",
      "     23        \u001b[36m0.6300\u001b[0m        4.6991  0.0991\n",
      "     24        1.5659        4.3248  0.1099\n",
      "     25        0.6599        3.6870  0.0947\n",
      "     26        1.8549        3.4150  0.1058\n",
      "     27        0.9737        2.8659  0.0877\n",
      "     28        1.6035        1.6351  0.0947\n",
      "     29        1.0399        0.8075  0.0852\n",
      "     30        0.7407        1.2675  0.1193\n",
      "     31        0.7436        1.6920  0.1008\n",
      "     32        0.7934        \u001b[32m0.2663\u001b[0m  0.1019\n",
      "     33        \u001b[36m0.4082\u001b[0m        2.1298  0.0895\n",
      "     34        0.8645        1.7699  0.0912\n",
      "     35        \u001b[36m0.3569\u001b[0m        2.7284  0.0943\n",
      "     36        1.0467       13.4243  0.1131\n",
      "     37        1.1603        4.3123  0.1146\n",
      "     38        2.3041        1.7450  0.0898\n",
      "     39        1.1013        1.0603  0.1260\n",
      "     40        0.8917        0.8121  0.1127\n",
      "     41        0.7833        0.7489  0.1111\n",
      "     42        0.5943        1.4021  0.1133\n",
      "     43        0.8204        2.7269  0.1126\n",
      "     44        0.6175        4.6057  0.1087\n",
      "     45        2.2723        2.7418  0.0942\n",
      "     46        0.6909        3.2943  0.1119\n",
      "     47        1.6367        3.8756  0.1051\n",
      "     48        0.9014        3.1013  0.0942\n",
      "     49        1.5468        1.8255  0.1032\n",
      "     50        0.9633        0.6433  0.1397\n",
      "     51        0.5877        0.4006  0.1023\n",
      "     52        0.5165        0.9828  0.0965\n",
      "     53        0.3866        1.7368  0.1042\n",
      "     54        0.7591        6.1190  0.1139\n",
      "     55        0.6761        5.7338  0.1274\n",
      "     56        2.7059        2.5421  0.1027\n",
      "     57        1.1670        7.5805  0.1194\n",
      "     58        1.2373        3.5614  0.1155\n",
      "     59        1.7203        1.7807  0.1045\n",
      "     60        1.0425        1.2598  0.0964\n",
      "     61        0.8643        0.7556  0.1166\n",
      "     62        0.6782        1.6003  0.0899\n",
      "     63        0.4293        2.8265  0.0915\n",
      "     64        1.1146       11.0428  0.1203\n",
      "     65        1.1237        3.4609  0.0858\n",
      "     66        1.7776        1.9336  0.0991\n",
      "     67        1.0212        1.2689  0.0817\n",
      "     68        0.8455        0.8170  0.1102\n",
      "     69        0.7323        1.3987  0.0977\n",
      "     70        0.5640        2.0798  0.0999\n",
      "     71        0.8969        9.4368  0.1064\n",
      "     72        0.8793        4.6860  0.0958\n",
      "     73        2.3784        1.2604  0.0978\n",
      "     74        0.8798        2.5761  0.0999\n",
      "     75        0.8497        1.4998  0.1088\n",
      "     76        0.9289        3.2306  0.1132\n",
      "     77        0.7275        2.6023  0.1058\n",
      "     78        1.3098        1.8596  0.0905\n",
      "     79        0.7240        0.6315  0.1600\n",
      "     80        0.6637        1.7713  0.0912\n",
      "     81        0.5091        1.3900  0.0740\n",
      "     82        0.8428        4.6634  0.1028\n",
      "     83        0.7813        3.4684  0.1076\n",
      "     84        1.7022        1.0078  0.1149\n",
      "     85        0.6495        0.6764  0.1055\n",
      "     86        0.5252        0.2931  0.1137\n",
      "     87        0.4939        1.3559  0.0951\n",
      "     88        0.4593        1.0991  0.1021\n",
      "     89        0.7432        4.7937  0.1057\n",
      "     90        0.7373        2.9304  0.0865\n",
      "     91        1.5150        0.9185  0.0902\n",
      "     92        0.5905        0.5094  0.0888\n",
      "     93        0.5142        \u001b[32m0.2617\u001b[0m  0.1016\n",
      "     94        0.4560        0.5739  0.1267\n",
      "     95        0.4405        0.3566  0.0987\n",
      "     96        0.5130        1.7641  0.1089\n",
      "     97        0.4825        1.2557  0.1013\n",
      "     98        0.7983        4.9237  0.1188\n",
      "     99        0.7679        2.7207  0.1080\n",
      "    100        1.4843        0.6651  0.1006\n",
      "    101        0.5645        0.7935  0.1200\n",
      "    102        0.4974        0.3994  0.1167\n",
      "    103        0.5260        2.2026  0.1155\n",
      "    104        0.5193        1.3967  0.1049\n",
      "    105        0.8446        4.4700  0.0929\n",
      "    106        0.7766        2.5003  0.0859\n",
      "    107        1.3855        0.9183  0.1234\n",
      "    108        0.5680        0.4415  0.0919\n",
      "    109        0.5046        \u001b[32m0.2477\u001b[0m  0.1202\n",
      "    110        0.4397        0.4745  0.1021\n",
      "    111        0.4268        0.3171  0.1009\n",
      "    112        0.4979        1.3147  0.0947\n",
      "    113        0.4386        0.9262  0.1053\n",
      "    114        0.7100        3.8165  0.0975\n",
      "    115        0.6445        1.8854  0.1229\n",
      "    116        1.1029        2.0830  0.1051\n",
      "    117        0.6487        0.8443  0.1192\n",
      "    118        0.7403        2.0099  0.1093\n",
      "    119        0.5554        0.8024  0.1034\n",
      "    120        0.6934        2.3844  0.0966\n",
      "    121        0.5669        0.9913  0.0870\n",
      "    122        0.7464        2.6099  0.0982\n",
      "    123        0.6024        1.1421  0.0900\n",
      "    124        0.7926        2.6171  0.1301\n",
      "    125        0.6170        1.1578  0.0907\n",
      "    126        0.7930        2.5045  0.0840\n",
      "    127        0.6046        1.0020  0.0847\n",
      "    128        0.7457        2.1430  0.0928\n",
      "    129        0.5567        0.6517  0.1343\n",
      "    130        0.6462        1.4525  0.0900\n",
      "    131        0.4904        0.3470  0.1118\n",
      "    132        0.5423        0.8031  0.0839\n",
      "    133        0.4547        0.2726  0.0894\n",
      "    134        0.4947        0.6448  0.1197\n",
      "    135        0.4409        0.2892  0.1516\n",
      "    136        0.4930        0.8183  0.1128\n",
      "    137        0.4567        0.3742  0.1219\n",
      "    138        0.5465        0.9264  0.1047\n",
      "    139        0.4650        0.5150  0.0826\n",
      "    140        0.5866        1.8496  0.1224\n",
      "    141        0.4979        0.8753  0.1288\n",
      "    142        0.7133        2.2919  0.0819\n",
      "    143        0.5824        0.8617  0.0942\n",
      "    144        0.7015        2.0399  0.1157\n",
      "    145        0.4253        0.8169  0.1127\n",
      "    146        0.6652        2.2092  0.1299\n",
      "    147        0.4785        0.7081  0.1065\n",
      "    148        0.6940        1.5436  0.1083\n",
      "    149        0.4883        0.3797  0.0965\n",
      "    150        0.5628        0.7209  0.0792\n",
      "    151        0.3779        \u001b[32m0.2305\u001b[0m  0.1158\n",
      "    152        0.4224        0.6408  0.0991\n",
      "    153        \u001b[36m0.3371\u001b[0m        \u001b[32m0.2260\u001b[0m  0.1148\n",
      "    154        0.4370        0.8744  0.0935\n",
      "    155        \u001b[36m0.3302\u001b[0m        0.3352  0.0944\n",
      "    156        0.5024        1.2160  0.1125\n",
      "    157        0.3357        0.4667  0.1267\n",
      "    158        0.5574        1.7877  0.1089\n",
      "    159        0.4167        0.7048  0.1172\n",
      "    160        0.6322        2.0919  0.0932\n",
      "    161        0.4466        0.7963  0.0903\n",
      "    162        0.6659        2.1331  0.1263\n",
      "    163        0.4363        0.7599  0.1046\n",
      "    164        0.6402        1.9628  0.1141\n",
      "    165        0.4576        0.5389  0.1102\n",
      "    166        0.5682        1.3311  0.1103\n",
      "    167        0.3638        0.3041  0.1064\n",
      "    168        0.4688        0.9712  0.1088\n",
      "    169        0.3496        0.2640  0.1129\n",
      "    170        0.4276        0.8168  0.0998\n",
      "    171        0.3381        0.2586  0.0960\n",
      "    172        0.4036        0.9394  0.1098\n",
      "    173        \u001b[36m0.3291\u001b[0m        0.3293  0.1230\n",
      "    174        0.4296        1.3128  0.1130\n",
      "    175        0.3427        0.4378  0.0895\n",
      "    176        0.4771        1.6068  0.0976\n",
      "    177        0.3607        0.5102  0.1181\n",
      "    178        0.5071        1.8068  0.1448\n",
      "    179        0.3760        0.5341  0.0918\n",
      "    180        0.5173        1.7966  0.1576\n",
      "    181        0.3825        0.5021  0.1282\n",
      "    182        0.5037        1.7287  0.1201\n",
      "    183        0.3748        0.4629  0.0959\n",
      "    184        0.4877        1.5489  0.1333\n",
      "    185        0.3689        0.4056  0.1073\n",
      "    186        0.4626        1.4289  0.0930\n",
      "    187        0.3580        0.3909  0.1021\n",
      "    188        0.4552        1.3558  0.1204\n",
      "    189        0.3590        0.3743  0.1092\n",
      "    190        0.4456        1.3698  0.1358\n",
      "    191        0.3530        0.4012  0.0989\n",
      "    192        0.4534        1.4425  0.1123\n",
      "    193        0.3612        0.4174  0.1162\n",
      "    194        0.4572        1.5621  0.1275\n",
      "    195        0.3588        0.4592  0.1277\n",
      "    196        0.4700        1.6512  0.1075\n",
      "    197        0.3720        0.4730  0.1214\n",
      "    198        0.4726        1.7718  0.1234\n",
      "    199        0.3660        0.5085  0.1223\n",
      "    200        0.4847        1.7872  0.1322\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m4.0731\u001b[0m        \u001b[32m1.4684\u001b[0m  0.0936\n",
      "      2        5.3133        8.1300  0.1021\n",
      "      3        7.7844        \u001b[32m1.2572\u001b[0m  0.1001\n",
      "      4        4.8227        2.4631  0.1201\n",
      "      5        4.2289        4.5875  0.1187\n",
      "      6        \u001b[36m3.8306\u001b[0m        3.8364  0.1094\n",
      "      7        \u001b[36m3.3822\u001b[0m        2.2078  0.1117\n",
      "      8        \u001b[36m2.6675\u001b[0m        1.6786  0.1036\n",
      "      9        \u001b[36m2.2432\u001b[0m        1.6042  0.1607\n",
      "     10        \u001b[36m1.4651\u001b[0m        1.6818  0.0840\n",
      "     11        \u001b[36m1.1741\u001b[0m        1.7041  0.0826\n",
      "     12        1.4150        1.6016  0.1004\n",
      "     13        1.6745        1.4092  0.1167\n",
      "     14        1.3068        1.3850  0.0996\n",
      "     15        \u001b[36m0.9642\u001b[0m        1.4612  0.1192\n",
      "     16        \u001b[36m0.8576\u001b[0m        1.5195  0.0959\n",
      "     17        0.9557        1.5315  0.1213\n",
      "     18        1.0913        1.4900  0.1261\n",
      "     19        1.2809        1.3971  0.0918\n",
      "     20        1.3717        1.2944  0.1076\n",
      "     21        1.0875        1.3047  0.1146\n",
      "     22        \u001b[36m0.8138\u001b[0m        1.3869  0.1068\n",
      "     23        \u001b[36m0.7292\u001b[0m        1.4525  0.1120\n",
      "     24        0.7631        1.4786  0.1159\n",
      "     25        0.8315        1.4678  0.1024\n",
      "     26        0.9168        1.4325  0.0968\n",
      "     27        1.0185        1.3798  0.1084\n",
      "     28        1.0756        1.3254  0.1121\n",
      "     29        0.9912        1.3087  0.1158\n",
      "     30        0.8244        1.3402  0.0984\n",
      "     31        \u001b[36m0.7118\u001b[0m        1.3840  0.0939\n",
      "     32        \u001b[36m0.6780\u001b[0m        1.4124  0.1026\n",
      "     33        0.6916        1.4200  0.0986\n",
      "     34        0.7258        1.4113  0.1107\n",
      "     35        0.7681        1.3925  0.1003\n",
      "     36        0.8081        1.3686  0.0997\n",
      "     37        0.8276        1.3461  0.0826\n",
      "     38        0.8080        1.3334  0.1021\n",
      "     39        0.7550        1.3351  0.0982\n",
      "     40        0.6969        1.3464  0.1030\n",
      "     41        \u001b[36m0.6564\u001b[0m        1.3583  0.0929\n",
      "     42        \u001b[36m0.6379\u001b[0m        1.3651  0.1132\n",
      "     43        \u001b[36m0.6354\u001b[0m        1.3656  0.0981\n",
      "     44        0.6421        1.3612  0.0908\n",
      "     45        0.6521        1.3537  0.0760\n",
      "     46        0.6608        1.3449  0.0783\n",
      "     47        0.6642        1.3365  0.0810\n",
      "     48        0.6600        1.3299  0.0840\n",
      "     49        0.6486        1.3258  0.0798\n",
      "     50        \u001b[36m0.6331\u001b[0m        1.3239  0.0838\n",
      "     51        \u001b[36m0.6175\u001b[0m        1.3232  0.0796\n",
      "     52        \u001b[36m0.6046\u001b[0m        1.3226  0.0825\n",
      "     53        \u001b[36m0.5957\u001b[0m        1.3213  0.0824\n",
      "     54        \u001b[36m0.5905\u001b[0m        1.3189  0.0898\n",
      "     55        \u001b[36m0.5880\u001b[0m        1.3156  0.0988\n",
      "     56        \u001b[36m0.5870\u001b[0m        1.3116  0.1136\n",
      "     57        \u001b[36m0.5864\u001b[0m        1.3072  0.1192\n",
      "     58        \u001b[36m0.5853\u001b[0m        1.3029  0.0842\n",
      "     59        \u001b[36m0.5833\u001b[0m        1.2987  0.0810\n",
      "     60        \u001b[36m0.5802\u001b[0m        1.2948  0.0827\n",
      "     61        \u001b[36m0.5764\u001b[0m        1.2913  0.0693\n",
      "     62        \u001b[36m0.5722\u001b[0m        1.2880  0.0878\n",
      "     63        \u001b[36m0.5682\u001b[0m        1.2849  0.1061\n",
      "     64        \u001b[36m0.5646\u001b[0m        1.2818  0.1216\n",
      "     65        \u001b[36m0.5616\u001b[0m        1.2786  0.1222\n",
      "     66        \u001b[36m0.5592\u001b[0m        1.2753  0.1210\n",
      "     67        \u001b[36m0.5573\u001b[0m        1.2719  0.1342\n",
      "     68        \u001b[36m0.5558\u001b[0m        1.2684  0.1182\n",
      "     69        \u001b[36m0.5543\u001b[0m        1.2649  0.1458\n",
      "     70        \u001b[36m0.5529\u001b[0m        1.2614  0.1223\n",
      "     71        \u001b[36m0.5515\u001b[0m        1.2580  0.1050\n",
      "     72        \u001b[36m0.5500\u001b[0m        \u001b[32m1.2546\u001b[0m  0.1227\n",
      "     73        \u001b[36m0.5485\u001b[0m        \u001b[32m1.2513\u001b[0m  0.0986\n",
      "     74        \u001b[36m0.5470\u001b[0m        \u001b[32m1.2480\u001b[0m  0.0918\n",
      "     75        \u001b[36m0.5455\u001b[0m        \u001b[32m1.2448\u001b[0m  0.1026\n",
      "     76        \u001b[36m0.5441\u001b[0m        \u001b[32m1.2415\u001b[0m  0.0925\n",
      "     77        \u001b[36m0.5428\u001b[0m        \u001b[32m1.2383\u001b[0m  0.1090\n",
      "     78        \u001b[36m0.5416\u001b[0m        \u001b[32m1.2351\u001b[0m  0.1066\n",
      "     79        \u001b[36m0.5405\u001b[0m        \u001b[32m1.2319\u001b[0m  0.1050\n",
      "     80        \u001b[36m0.5395\u001b[0m        \u001b[32m1.2287\u001b[0m  0.1143\n",
      "     81        \u001b[36m0.5385\u001b[0m        \u001b[32m1.2255\u001b[0m  0.1001\n",
      "     82        \u001b[36m0.5375\u001b[0m        \u001b[32m1.2223\u001b[0m  0.1111\n",
      "     83        \u001b[36m0.5366\u001b[0m        \u001b[32m1.2192\u001b[0m  0.1020\n",
      "     84        \u001b[36m0.5356\u001b[0m        \u001b[32m1.2161\u001b[0m  0.0923\n",
      "     85        \u001b[36m0.5347\u001b[0m        \u001b[32m1.2130\u001b[0m  0.1114\n",
      "     86        \u001b[36m0.5338\u001b[0m        \u001b[32m1.2099\u001b[0m  0.1159\n",
      "     87        \u001b[36m0.5329\u001b[0m        \u001b[32m1.2068\u001b[0m  0.1162\n",
      "     88        \u001b[36m0.5320\u001b[0m        \u001b[32m1.2038\u001b[0m  0.1224\n",
      "     89        \u001b[36m0.5311\u001b[0m        \u001b[32m1.2008\u001b[0m  0.1071\n",
      "     90        \u001b[36m0.5303\u001b[0m        \u001b[32m1.1978\u001b[0m  0.1108\n",
      "     91        \u001b[36m0.5294\u001b[0m        \u001b[32m1.1948\u001b[0m  0.0964\n",
      "     92        \u001b[36m0.5286\u001b[0m        \u001b[32m1.1918\u001b[0m  0.1000\n",
      "     93        \u001b[36m0.5278\u001b[0m        \u001b[32m1.1889\u001b[0m  0.1096\n",
      "     94        \u001b[36m0.5269\u001b[0m        \u001b[32m1.1860\u001b[0m  0.1096\n",
      "     95        \u001b[36m0.5261\u001b[0m        \u001b[32m1.1831\u001b[0m  0.1142\n",
      "     96        \u001b[36m0.5253\u001b[0m        \u001b[32m1.1803\u001b[0m  0.1208\n",
      "     97        \u001b[36m0.5245\u001b[0m        \u001b[32m1.1774\u001b[0m  0.1272\n",
      "     98        \u001b[36m0.5236\u001b[0m        \u001b[32m1.1746\u001b[0m  0.0800\n",
      "     99        \u001b[36m0.5228\u001b[0m        \u001b[32m1.1719\u001b[0m  0.0777\n",
      "    100        \u001b[36m0.5219\u001b[0m        \u001b[32m1.1691\u001b[0m  0.0970\n",
      "    101        \u001b[36m0.5211\u001b[0m        \u001b[32m1.1664\u001b[0m  0.1108\n",
      "    102        \u001b[36m0.5202\u001b[0m        \u001b[32m1.1637\u001b[0m  0.1156\n",
      "    103        \u001b[36m0.5194\u001b[0m        \u001b[32m1.1611\u001b[0m  0.1003\n",
      "    104        \u001b[36m0.5185\u001b[0m        \u001b[32m1.1585\u001b[0m  0.0967\n",
      "    105        \u001b[36m0.5176\u001b[0m        \u001b[32m1.1559\u001b[0m  0.1116\n",
      "    106        \u001b[36m0.5167\u001b[0m        \u001b[32m1.1534\u001b[0m  0.0999\n",
      "    107        \u001b[36m0.5158\u001b[0m        \u001b[32m1.1509\u001b[0m  0.1134\n",
      "    108        \u001b[36m0.5149\u001b[0m        \u001b[32m1.1485\u001b[0m  0.1089\n",
      "    109        \u001b[36m0.5140\u001b[0m        \u001b[32m1.1460\u001b[0m  0.1044\n",
      "    110        \u001b[36m0.5131\u001b[0m        \u001b[32m1.1437\u001b[0m  0.1175\n",
      "    111        \u001b[36m0.5121\u001b[0m        \u001b[32m1.1414\u001b[0m  0.0975\n",
      "    112        \u001b[36m0.5112\u001b[0m        \u001b[32m1.1391\u001b[0m  0.1012\n",
      "    113        \u001b[36m0.5103\u001b[0m        \u001b[32m1.1368\u001b[0m  0.0911\n",
      "    114        \u001b[36m0.5093\u001b[0m        \u001b[32m1.1347\u001b[0m  0.0996\n",
      "    115        \u001b[36m0.5083\u001b[0m        \u001b[32m1.1325\u001b[0m  0.1281\n",
      "    116        \u001b[36m0.5074\u001b[0m        \u001b[32m1.1304\u001b[0m  0.0981\n",
      "    117        \u001b[36m0.5064\u001b[0m        \u001b[32m1.1284\u001b[0m  0.0997\n",
      "    118        \u001b[36m0.5054\u001b[0m        \u001b[32m1.1264\u001b[0m  0.0992\n",
      "    119        \u001b[36m0.5045\u001b[0m        \u001b[32m1.1244\u001b[0m  0.1079\n",
      "    120        \u001b[36m0.5035\u001b[0m        \u001b[32m1.1225\u001b[0m  0.1107\n",
      "    121        \u001b[36m0.5025\u001b[0m        \u001b[32m1.1206\u001b[0m  0.1158\n",
      "    122        \u001b[36m0.5015\u001b[0m        \u001b[32m1.1188\u001b[0m  0.1026\n",
      "    123        \u001b[36m0.5006\u001b[0m        \u001b[32m1.1171\u001b[0m  0.1127\n",
      "    124        \u001b[36m0.4996\u001b[0m        \u001b[32m1.1154\u001b[0m  0.1582\n",
      "    125        \u001b[36m0.4986\u001b[0m        \u001b[32m1.1137\u001b[0m  0.1017\n",
      "    126        \u001b[36m0.4977\u001b[0m        \u001b[32m1.1121\u001b[0m  0.1178\n",
      "    127        \u001b[36m0.4967\u001b[0m        \u001b[32m1.1105\u001b[0m  0.0980\n",
      "    128        \u001b[36m0.4958\u001b[0m        \u001b[32m1.1090\u001b[0m  0.1063\n",
      "    129        \u001b[36m0.4948\u001b[0m        \u001b[32m1.1076\u001b[0m  0.0977\n",
      "    130        \u001b[36m0.4939\u001b[0m        \u001b[32m1.1061\u001b[0m  0.1032\n",
      "    131        \u001b[36m0.4930\u001b[0m        \u001b[32m1.1048\u001b[0m  0.1136\n",
      "    132        \u001b[36m0.4920\u001b[0m        \u001b[32m1.1035\u001b[0m  0.1023\n",
      "    133        \u001b[36m0.4911\u001b[0m        \u001b[32m1.1022\u001b[0m  0.1067\n",
      "    134        \u001b[36m0.4902\u001b[0m        \u001b[32m1.1010\u001b[0m  0.1080\n",
      "    135        \u001b[36m0.4894\u001b[0m        \u001b[32m1.0998\u001b[0m  0.1026\n",
      "    136        \u001b[36m0.4885\u001b[0m        \u001b[32m1.0987\u001b[0m  0.1127\n",
      "    137        \u001b[36m0.4876\u001b[0m        \u001b[32m1.0976\u001b[0m  0.1072\n",
      "    138        \u001b[36m0.4868\u001b[0m        \u001b[32m1.0966\u001b[0m  0.1169\n",
      "    139        \u001b[36m0.4859\u001b[0m        \u001b[32m1.0957\u001b[0m  0.1032\n",
      "    140        \u001b[36m0.4851\u001b[0m        \u001b[32m1.0948\u001b[0m  0.0899\n",
      "    141        \u001b[36m0.4843\u001b[0m        \u001b[32m1.0939\u001b[0m  0.0949\n",
      "    142        \u001b[36m0.4835\u001b[0m        \u001b[32m1.0931\u001b[0m  0.0990\n",
      "    143        \u001b[36m0.4827\u001b[0m        \u001b[32m1.0923\u001b[0m  0.0967\n",
      "    144        \u001b[36m0.4820\u001b[0m        \u001b[32m1.0916\u001b[0m  0.0943\n",
      "    145        \u001b[36m0.4812\u001b[0m        \u001b[32m1.0910\u001b[0m  0.1213\n",
      "    146        \u001b[36m0.4805\u001b[0m        \u001b[32m1.0904\u001b[0m  0.0962\n",
      "    147        \u001b[36m0.4798\u001b[0m        \u001b[32m1.0899\u001b[0m  0.1011\n",
      "    148        \u001b[36m0.4791\u001b[0m        \u001b[32m1.0894\u001b[0m  0.0890\n",
      "    149        \u001b[36m0.4784\u001b[0m        \u001b[32m1.0890\u001b[0m  0.0914\n",
      "    150        \u001b[36m0.4777\u001b[0m        \u001b[32m1.0887\u001b[0m  0.0929\n",
      "    151        \u001b[36m0.4771\u001b[0m        \u001b[32m1.0884\u001b[0m  0.0891\n",
      "    152        \u001b[36m0.4765\u001b[0m        \u001b[32m1.0882\u001b[0m  0.1154\n",
      "    153        \u001b[36m0.4758\u001b[0m        \u001b[32m1.0880\u001b[0m  0.1086\n",
      "    154        \u001b[36m0.4752\u001b[0m        \u001b[32m1.0879\u001b[0m  0.1110\n",
      "    155        \u001b[36m0.4746\u001b[0m        \u001b[32m1.0879\u001b[0m  0.0997\n",
      "    156        \u001b[36m0.4741\u001b[0m        1.0879  0.1230\n",
      "    157        \u001b[36m0.4735\u001b[0m        1.0880  0.1101\n",
      "    158        \u001b[36m0.4730\u001b[0m        1.0882  0.1005\n",
      "    159        \u001b[36m0.4724\u001b[0m        1.0884  0.1016\n",
      "    160        \u001b[36m0.4719\u001b[0m        1.0886  0.1199\n",
      "    161        \u001b[36m0.4713\u001b[0m        1.0889  0.1169\n",
      "    162        \u001b[36m0.4708\u001b[0m        1.0893  0.1032\n",
      "    163        \u001b[36m0.4702\u001b[0m        1.0897  0.0797\n",
      "    164        \u001b[36m0.4696\u001b[0m        1.0901  0.1112\n",
      "    165        \u001b[36m0.4691\u001b[0m        1.0906  0.1235\n",
      "    166        \u001b[36m0.4685\u001b[0m        1.0911  0.0871\n",
      "    167        \u001b[36m0.4678\u001b[0m        1.0916  0.1035\n",
      "    168        \u001b[36m0.4672\u001b[0m        1.0921  0.0729\n",
      "    169        \u001b[36m0.4665\u001b[0m        1.0926  0.0778\n",
      "    170        \u001b[36m0.4658\u001b[0m        1.0932  0.0794\n",
      "    171        \u001b[36m0.4651\u001b[0m        1.0937  0.0770\n",
      "    172        \u001b[36m0.4643\u001b[0m        1.0943  0.0778\n",
      "    173        \u001b[36m0.4636\u001b[0m        1.0948  0.0874\n",
      "    174        \u001b[36m0.4627\u001b[0m        1.0954  0.0831\n",
      "    175        \u001b[36m0.4619\u001b[0m        1.0959  0.0834\n",
      "    176        \u001b[36m0.4610\u001b[0m        1.0965  0.0797\n",
      "    177        \u001b[36m0.4601\u001b[0m        1.0970  0.0935\n",
      "    178        \u001b[36m0.4591\u001b[0m        1.0975  0.1020\n",
      "    179        \u001b[36m0.4582\u001b[0m        1.0980  0.1201\n",
      "    180        \u001b[36m0.4572\u001b[0m        1.0985  0.1221\n",
      "    181        \u001b[36m0.4561\u001b[0m        1.0990  0.1203\n",
      "    182        \u001b[36m0.4551\u001b[0m        1.0995  0.1096\n",
      "    183        \u001b[36m0.4540\u001b[0m        1.1000  0.0997\n",
      "    184        \u001b[36m0.4529\u001b[0m        1.1005  0.1048\n",
      "    185        \u001b[36m0.4518\u001b[0m        1.1010  0.1187\n",
      "    186        \u001b[36m0.4507\u001b[0m        1.1016  0.1132\n",
      "    187        \u001b[36m0.4496\u001b[0m        1.1023  0.1099\n",
      "    188        \u001b[36m0.4485\u001b[0m        1.1031  0.1040\n",
      "    189        \u001b[36m0.4475\u001b[0m        1.1040  0.1155\n",
      "    190        \u001b[36m0.4466\u001b[0m        1.1051  0.0908\n",
      "    191        \u001b[36m0.4458\u001b[0m        1.1063  0.0973\n",
      "    192        \u001b[36m0.4454\u001b[0m        1.1077  0.1011\n",
      "    193        \u001b[36m0.4453\u001b[0m        1.1091  0.0990\n",
      "    194        0.4457        1.1106  0.1270\n",
      "    195        0.4467        1.1118  0.1109\n",
      "    196        0.4482        1.1126  0.1109\n",
      "    197        0.4500        1.1128  0.1115\n",
      "    198        0.4518        1.1123  0.1100\n",
      "    199        0.4532        1.1112  0.1055\n",
      "    200        0.4540        1.1095  0.1194\n",
      "    201        0.4539        1.1075  0.0996\n",
      "    202        0.4530        1.1051  0.1114\n",
      "    203        0.4516        1.1027  0.0901\n",
      "    204        0.4497        1.1001  0.0907\n",
      "    205        0.4478        1.0975  0.0811\n",
      "    206        0.4459        1.0950  0.0888\n",
      "    207        \u001b[36m0.4441\u001b[0m        1.0925  0.0946\n",
      "    208        \u001b[36m0.4424\u001b[0m        1.0901  0.1157\n",
      "    209        \u001b[36m0.4409\u001b[0m        \u001b[32m1.0878\u001b[0m  0.1142\n",
      "    210        \u001b[36m0.4395\u001b[0m        \u001b[32m1.0856\u001b[0m  0.1100\n",
      "    211        \u001b[36m0.4382\u001b[0m        \u001b[32m1.0834\u001b[0m  0.0976\n",
      "    212        \u001b[36m0.4369\u001b[0m        \u001b[32m1.0813\u001b[0m  0.0982\n",
      "    213        \u001b[36m0.4356\u001b[0m        \u001b[32m1.0792\u001b[0m  0.1033\n",
      "    214        \u001b[36m0.4343\u001b[0m        \u001b[32m1.0771\u001b[0m  0.0858\n",
      "    215        \u001b[36m0.4331\u001b[0m        \u001b[32m1.0751\u001b[0m  0.1182\n",
      "    216        \u001b[36m0.4318\u001b[0m        \u001b[32m1.0731\u001b[0m  0.1130\n",
      "    217        \u001b[36m0.4306\u001b[0m        \u001b[32m1.0711\u001b[0m  0.1017\n",
      "    218        \u001b[36m0.4294\u001b[0m        \u001b[32m1.0692\u001b[0m  0.1185\n",
      "    219        \u001b[36m0.4283\u001b[0m        \u001b[32m1.0674\u001b[0m  0.0917\n",
      "    220        \u001b[36m0.4271\u001b[0m        \u001b[32m1.0656\u001b[0m  0.0972\n",
      "    221        \u001b[36m0.4260\u001b[0m        \u001b[32m1.0638\u001b[0m  0.1017\n",
      "    222        \u001b[36m0.4249\u001b[0m        \u001b[32m1.0620\u001b[0m  0.1040\n",
      "    223        \u001b[36m0.4238\u001b[0m        \u001b[32m1.0603\u001b[0m  0.0979\n",
      "    224        \u001b[36m0.4227\u001b[0m        \u001b[32m1.0587\u001b[0m  0.1129\n",
      "    225        \u001b[36m0.4217\u001b[0m        \u001b[32m1.0571\u001b[0m  0.1007\n",
      "    226        \u001b[36m0.4206\u001b[0m        \u001b[32m1.0555\u001b[0m  0.1190\n",
      "    227        \u001b[36m0.4196\u001b[0m        \u001b[32m1.0540\u001b[0m  0.0991\n",
      "    228        \u001b[36m0.4186\u001b[0m        \u001b[32m1.0525\u001b[0m  0.1067\n",
      "    229        \u001b[36m0.4176\u001b[0m        \u001b[32m1.0511\u001b[0m  0.1068\n",
      "    230        \u001b[36m0.4166\u001b[0m        \u001b[32m1.0497\u001b[0m  0.0904\n",
      "    231        \u001b[36m0.4156\u001b[0m        \u001b[32m1.0484\u001b[0m  0.1108\n",
      "    232        \u001b[36m0.4147\u001b[0m        \u001b[32m1.0471\u001b[0m  0.1129\n",
      "    233        \u001b[36m0.4137\u001b[0m        \u001b[32m1.0458\u001b[0m  0.0953\n",
      "    234        \u001b[36m0.4128\u001b[0m        \u001b[32m1.0446\u001b[0m  0.1183\n",
      "    235        \u001b[36m0.4119\u001b[0m        \u001b[32m1.0434\u001b[0m  0.0981\n",
      "    236        \u001b[36m0.4110\u001b[0m        \u001b[32m1.0423\u001b[0m  0.0861\n",
      "    237        \u001b[36m0.4101\u001b[0m        \u001b[32m1.0412\u001b[0m  0.0992\n",
      "    238        \u001b[36m0.4092\u001b[0m        \u001b[32m1.0402\u001b[0m  0.1092\n",
      "    239        \u001b[36m0.4083\u001b[0m        \u001b[32m1.0392\u001b[0m  0.1115\n",
      "    240        \u001b[36m0.4075\u001b[0m        \u001b[32m1.0382\u001b[0m  0.1192\n",
      "    241        \u001b[36m0.4066\u001b[0m        \u001b[32m1.0373\u001b[0m  0.0974\n",
      "    242        \u001b[36m0.4058\u001b[0m        \u001b[32m1.0364\u001b[0m  0.1135\n",
      "    243        \u001b[36m0.4050\u001b[0m        \u001b[32m1.0355\u001b[0m  0.1059\n",
      "    244        \u001b[36m0.4042\u001b[0m        \u001b[32m1.0347\u001b[0m  0.1009\n",
      "    245        \u001b[36m0.4034\u001b[0m        \u001b[32m1.0339\u001b[0m  0.1157\n",
      "    246        \u001b[36m0.4026\u001b[0m        \u001b[32m1.0332\u001b[0m  0.1160\n",
      "    247        \u001b[36m0.4018\u001b[0m        \u001b[32m1.0325\u001b[0m  0.1042\n",
      "    248        \u001b[36m0.4010\u001b[0m        \u001b[32m1.0318\u001b[0m  0.1195\n",
      "    249        \u001b[36m0.4003\u001b[0m        \u001b[32m1.0311\u001b[0m  0.1178\n",
      "    250        \u001b[36m0.3996\u001b[0m        \u001b[32m1.0305\u001b[0m  0.1209\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m4.1827\u001b[0m        \u001b[32m3.6853\u001b[0m  0.1359\n",
      "      2        4.2770        \u001b[32m2.5203\u001b[0m  0.0937\n",
      "      3        \u001b[36m3.5096\u001b[0m        2.5691  0.1091\n",
      "      4        \u001b[36m3.3319\u001b[0m        \u001b[32m2.1204\u001b[0m  0.0854\n",
      "      5        \u001b[36m3.0895\u001b[0m        2.1763  0.0680\n",
      "      6        3.1149        \u001b[32m1.9718\u001b[0m  0.1106\n",
      "      7        \u001b[36m3.0264\u001b[0m        2.1589  0.1088\n",
      "      8        3.0761        \u001b[32m1.8573\u001b[0m  0.1120\n",
      "      9        \u001b[36m2.9537\u001b[0m        2.5362  0.1054\n",
      "     10        3.0651        2.1539  0.1714\n",
      "     11        \u001b[36m2.8539\u001b[0m        3.6739  0.1263\n",
      "     12        3.3286        3.9099  0.1039\n",
      "     13        \u001b[36m2.7603\u001b[0m        4.1634  0.1057\n",
      "     14        3.5466        2.4119  0.1066\n",
      "     15        2.9445        2.0562  0.1037\n",
      "     16        2.8887        1.9524  0.0915\n",
      "     17        2.8956        2.7327  0.0965\n",
      "     18        2.8984        2.7222  0.1275\n",
      "     19        2.8735        4.4493  0.1091\n",
      "     20        3.2481        5.1099  0.0946\n",
      "     21        2.9369        5.3715  0.1188\n",
      "     22        3.8088        2.1832  0.1258\n",
      "     23        \u001b[36m2.5099\u001b[0m        \u001b[32m1.6278\u001b[0m  0.1126\n",
      "     24        2.9641        \u001b[32m1.0832\u001b[0m  0.1157\n",
      "     25        2.6743        2.1256  0.1159\n",
      "     26        2.8177        \u001b[32m1.0252\u001b[0m  0.1020\n",
      "     27        2.6603        \u001b[32m0.8066\u001b[0m  0.0935\n",
      "     28        2.6473        2.5330  0.1165\n",
      "     29        2.6909        4.5316  0.0962\n",
      "     30        2.6512        5.2100  0.0987\n",
      "     31        3.3212        2.6981  0.1212\n",
      "     32        \u001b[36m2.2142\u001b[0m        2.5410  0.0939\n",
      "     33        2.2440        4.1085  0.1047\n",
      "     34        \u001b[36m1.3749\u001b[0m        3.8395  0.1268\n",
      "     35        2.3672        2.0204  0.1014\n",
      "     36        2.5610        0.8684  0.0944\n",
      "     37        \u001b[36m0.9741\u001b[0m        1.5090  0.1106\n",
      "     38        2.1758        \u001b[32m0.6874\u001b[0m  0.0829\n",
      "     39        1.0255        2.3310  0.0876\n",
      "     40        2.4804        1.1881  0.1009\n",
      "     41        1.3598        2.6903  0.1038\n",
      "     42        1.6036        2.6064  0.1004\n",
      "     43        \u001b[36m0.6839\u001b[0m        3.2126  0.1097\n",
      "     44        1.7154        7.3268  0.0956\n",
      "     45        1.3241        4.9166  0.1216\n",
      "     46        2.5799        2.5592  0.1144\n",
      "     47        1.8804        2.6080  0.0956\n",
      "     48        3.0133        3.5172  0.1432\n",
      "     49        2.0544        1.7125  0.1048\n",
      "     50        1.7487        4.0476  0.1089\n",
      "     51        1.2320        4.0398  0.1007\n",
      "     52        2.0614        1.4698  0.1201\n",
      "     53        1.3840        0.7345  0.1137\n",
      "     54        0.7409        0.7955  0.0938\n",
      "     55        1.3585        \u001b[32m0.5493\u001b[0m  0.1095\n",
      "     56        \u001b[36m0.6504\u001b[0m        0.9171  0.1065\n",
      "     57        1.1987        \u001b[32m0.4228\u001b[0m  0.1136\n",
      "     58        \u001b[36m0.5831\u001b[0m        0.5404  0.0935\n",
      "     59        0.9367        0.4440  0.0925\n",
      "     60        \u001b[36m0.5273\u001b[0m        0.9157  0.0936\n",
      "     61        1.1199        0.5557  0.0879\n",
      "     62        0.5490        1.2584  0.1343\n",
      "     63        1.2554        1.0875  0.0969\n",
      "     64        0.5332        2.4293  0.1016\n",
      "     65        1.2663        6.1494  0.1192\n",
      "     66        0.7678        4.8322  0.1144\n",
      "     67        2.4731        2.5761  0.1150\n",
      "     68        1.6144        1.7365  0.1258\n",
      "     69        1.2329        1.7345  0.1219\n",
      "     70        0.9228        1.8943  0.1131\n",
      "     71        1.8349        1.6044  0.1298\n",
      "     72        0.8449        3.8179  0.1012\n",
      "     73        1.5678        6.6582  0.1038\n",
      "     74        1.5443        2.6865  0.1163\n",
      "     75        1.2761        2.5757  0.0971\n",
      "     76        1.1924        \u001b[32m0.3851\u001b[0m  0.1080\n",
      "     77        0.6335        \u001b[32m0.2567\u001b[0m  0.0914\n",
      "     78        1.2318        0.6033  0.0822\n",
      "     79        0.7032        0.9864  0.0857\n",
      "     80        1.0781        3.4770  0.1112\n",
      "     81        0.6184        3.4937  0.1212\n",
      "     82        1.4570        2.8547  0.0924\n",
      "     83        1.1972        0.6384  0.1084\n",
      "     84        0.6208        2.5430  0.1163\n",
      "     85        0.9909        1.1335  0.1188\n",
      "     86        1.0243        1.7035  0.0987\n",
      "     87        1.5277        0.5594  0.0992\n",
      "     88        0.9753        0.3550  0.1139\n",
      "     89        0.9323        0.8161  0.1015\n",
      "     90        0.5644        1.5879  0.1035\n",
      "     91        0.8386        6.2604  0.1155\n",
      "     92        0.6124        4.5281  0.1065\n",
      "     93        2.1650        2.0764  0.1353\n",
      "     94        0.7464        1.8929  0.1069\n",
      "     95        1.1503        7.2877  0.0993\n",
      "     96        1.0536        4.2592  0.1011\n",
      "     97        2.4017        3.7806  0.0959\n",
      "     98        2.1713        3.3839  0.1124\n",
      "     99        1.9857        3.8661  0.0993\n",
      "    100        2.1823        2.1981  0.1030\n",
      "    101        1.6941        3.3711  0.0990\n",
      "    102        2.5631        1.7031  0.1019\n",
      "    103        1.2582        0.8208  0.1140\n",
      "    104        1.1568        1.0446  0.1125\n",
      "    105        0.8457        0.3702  0.1193\n",
      "    106        0.9650        0.6722  0.1035\n",
      "    107        0.7600        2.2749  0.1241\n",
      "    108        1.1518        4.8181  0.0969\n",
      "    109        0.7133        3.9872  0.1089\n",
      "    110        1.8687        2.1923  0.1228\n",
      "    111        2.3039        1.0905  0.0819\n",
      "    112        1.3894        0.4165  0.1005\n",
      "    113        1.2127        5.9363  0.1132\n",
      "    114        1.1079        4.9675  0.1196\n",
      "    115        2.2088        1.7782  0.1125\n",
      "    116        1.6360        1.4424  0.1055\n",
      "    117        0.8113        1.8804  0.0898\n",
      "    118        1.1237        8.8880  0.1020\n",
      "    119        1.3912        4.4822  0.1167\n",
      "    120        2.7216        3.4621  0.1202\n",
      "    121        2.1422        2.9764  0.1292\n",
      "    122        1.7660        3.6988  0.1101\n",
      "    123        1.6524        4.6129  0.1284\n",
      "    124        2.3618        1.8197  0.1003\n",
      "    125        1.4144        2.8006  0.1116\n",
      "    126        1.4422        3.1649  0.1090\n",
      "    127        1.6876        2.5901  0.1075\n",
      "    128        1.9687        1.0456  0.1133\n",
      "    129        1.4024        0.3092  0.1183\n",
      "    130        1.3823        0.8460  0.0878\n",
      "    131        1.2298        0.3615  0.1120\n",
      "    132        1.2481        0.9889  0.1269\n",
      "    133        1.3086        0.4257  0.1028\n",
      "    134        1.3287        1.5639  0.1204\n",
      "    135        1.4470        0.5566  0.1688\n",
      "    136        1.4573        3.5025  0.0986\n",
      "    137        1.7388        0.8865  0.0891\n",
      "    138        1.5881        6.0263  0.0881\n",
      "    139        2.1699        2.4661  0.1276\n",
      "    140        1.8982        6.0271  0.1184\n",
      "    141        2.5880        1.5839  0.0999\n",
      "    142        1.9031       10.9525  0.1226\n",
      "    143        2.3847        4.2754  0.1193\n",
      "    144        2.3737        3.2686  0.1191\n",
      "    145        1.6283        2.2055  0.1068\n",
      "    146        1.8069        4.2276  0.1168\n",
      "    147        2.5541        2.4984  0.1302\n",
      "    148        2.0865        5.7785  0.1122\n",
      "    149        2.6217        0.9674  0.1438\n",
      "    150        1.9464       13.3844  0.0807\n",
      "    151        3.1061        6.6763  0.0968\n",
      "    152        2.9029        4.1719  0.0873\n",
      "    153        2.3269        2.4632  0.0829\n",
      "    154        1.6804        3.8786  0.0833\n",
      "    155        2.3147        0.9838  0.0878\n",
      "    156        1.9595        7.2695  0.0837\n",
      "    157        2.0967        3.1739  0.0804\n",
      "    158        2.1226        5.2960  0.0949\n",
      "    159        1.8032        1.8615  0.0986\n",
      "    160        1.9098        7.4783  0.1000\n",
      "    161        2.8205        3.1540  0.0963\n",
      "    162        2.3601        4.3773  0.1115\n",
      "    163        1.5889        1.2137  0.1087\n",
      "    164        1.4321        8.2739  0.1282\n",
      "    165        2.9143        4.0268  0.1121\n",
      "    166        2.5676        4.4733  0.0980\n",
      "    167        1.5945        2.6099  0.1109\n",
      "    168        1.4480        4.8013  0.1197\n",
      "    169        2.5935        2.3284  0.1198\n",
      "    170        2.0306        7.3169  0.1282\n",
      "    171        2.6670        4.0973  0.0801\n",
      "    172        2.5574        4.6377  0.0817\n",
      "    173        1.5943        1.5309  0.1095\n",
      "    174        1.0039       10.5313  0.1016\n",
      "    175        2.6326        5.7127  0.1206\n",
      "    176        2.8923        3.6256  0.1119\n",
      "    177        1.3507        6.1637  0.1115\n",
      "    178        1.9345        6.4150  0.1177\n",
      "    179        3.3442        2.4139  0.1224\n",
      "    180        1.9140        5.8180  0.1075\n",
      "    181        2.5568        1.8452  0.0996\n",
      "    182        1.8648        6.7894  0.1188\n",
      "    183        2.0143        3.6182  0.1238\n",
      "    184        1.9995        5.6031  0.1210\n",
      "    185        2.2204        1.6143  0.1409\n",
      "    186        1.7279        8.5054  0.1178\n",
      "    187        2.6329        3.8434  0.1178\n",
      "    188        2.2245        4.9495  0.1113\n",
      "    189        1.6516        2.3202  0.1019\n",
      "    190        1.4304        9.7290  0.1200\n",
      "    191        2.7567        3.9822  0.1022\n",
      "    192        2.4564        3.2867  0.0836\n",
      "    193        1.4635        2.0877  0.0923\n",
      "    194        1.2971        4.9956  0.1004\n",
      "    195        2.4778        1.8335  0.1108\n",
      "    196        1.6968        4.0274  0.1273\n",
      "    197        1.6182        1.1375  0.1214\n",
      "    198        1.3806        7.5747  0.1299\n",
      "    199        1.9433        3.2847  0.1169\n",
      "    200        1.5650        8.1696  0.1225\n",
      "    201        1.9436        6.3243  0.1028\n",
      "    202        2.2819        5.4026  0.1160\n",
      "    203        2.2393        2.0341  0.1184\n",
      "    204        1.5243        8.4815  0.0990\n",
      "    205        2.7184        3.5687  0.1297\n",
      "    206        2.0536        5.4928  0.1287\n",
      "    207        1.5552        4.1307  0.1279\n",
      "    208        1.7419       10.1431  0.1785\n",
      "    209        2.9044        3.9486  0.0848\n",
      "    210        2.2166        4.0214  0.0918\n",
      "    211        1.5429        0.6436  0.1186\n",
      "    212        1.2286        6.1426  0.1071\n",
      "    213        2.2794        1.6753  0.1122\n",
      "    214        1.4820        6.0099  0.1389\n",
      "    215        1.3935        3.2136  0.1181\n",
      "    216        1.4231        8.9965  0.1190\n",
      "    217        2.3466        5.4384  0.1214\n",
      "    218        2.5547        4.1862  0.1083\n",
      "    219        1.6982        2.1802  0.1122\n",
      "    220        1.3272        7.4389  0.1364\n",
      "    221        2.8481        3.1920  0.1191\n",
      "    222        1.9942        4.9412  0.1183\n",
      "    223        1.3515        2.2776  0.1273\n",
      "    224        1.2723        9.8825  0.1150\n",
      "    225        2.6022        3.7644  0.1000\n",
      "    226        1.8542        7.5260  0.1073\n",
      "    227        1.6112        7.0556  0.1126\n",
      "    228        2.2995        6.8938  0.1193\n",
      "    229        2.3330        3.6876  0.1212\n",
      "    230        1.8144        6.4971  0.1370\n",
      "    231        2.3537        2.0564  0.1027\n",
      "    232        1.6074        4.8736  0.1170\n",
      "    233        1.4323        0.9131  0.1089\n",
      "    234        1.1173        5.2070  0.1089\n",
      "    235        1.7702        1.1848  0.1312\n",
      "    236        1.2746        3.9587  0.0928\n",
      "    237        1.1408        0.8619  0.1102\n",
      "    238        1.1914        4.3177  0.1188\n",
      "    239        1.3606        1.0759  0.1288\n",
      "    240        1.1719        5.5279  0.1019\n",
      "    241        1.3757        1.8490  0.1215\n",
      "    242        1.3688        8.0382  0.1090\n",
      "    243        1.7984        3.8597  0.0888\n",
      "    244        1.6807        8.8406  0.1047\n",
      "    245        2.2697        6.0638  0.1018\n",
      "    246        2.1305        5.3767  0.1160\n",
      "    247        2.3317        2.3020  0.1212\n",
      "    248        1.7495        3.8897  0.0924\n",
      "    249        1.8974        0.5590  0.0916\n",
      "    250        1.3069        6.5402  0.1193\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m1.9783\u001b[0m        \u001b[32m2.6602\u001b[0m  0.0886\n",
      "      2        2.6375        2.6800  0.0814\n",
      "      3        2.9504        5.2635  0.0877\n",
      "      4        3.0722        3.5350  0.0891\n",
      "      5        2.1357        3.7182  0.1008\n",
      "      6        2.1676        3.9784  0.0836\n",
      "      7        2.1485        3.5528  0.0903\n",
      "      8        2.0628        3.4023  0.0988\n",
      "      9        \u001b[36m1.9067\u001b[0m        2.8778  0.1243\n",
      "     10        \u001b[36m1.7113\u001b[0m        2.7611  0.1121\n",
      "     11        \u001b[36m1.6513\u001b[0m        2.8286  0.1052\n",
      "     12        1.6571        \u001b[32m2.5575\u001b[0m  0.0764\n",
      "     13        \u001b[36m1.5123\u001b[0m        \u001b[32m2.5198\u001b[0m  0.0988\n",
      "     14        \u001b[36m1.4805\u001b[0m        3.4215  0.0968\n",
      "     15        1.6410        \u001b[32m1.9430\u001b[0m  0.1092\n",
      "     16        \u001b[36m1.0495\u001b[0m        4.4343  0.1027\n",
      "     17        2.0616        2.0192  0.0942\n",
      "     18        \u001b[36m0.9119\u001b[0m        3.4348  0.1206\n",
      "     19        1.9668        \u001b[32m1.5879\u001b[0m  0.1104\n",
      "     20        1.0733        2.0346  0.1187\n",
      "     21        1.2060        1.9703  0.0990\n",
      "     22        1.0319        \u001b[32m0.6508\u001b[0m  0.0977\n",
      "     23        \u001b[36m0.6300\u001b[0m        4.6991  0.0944\n",
      "     24        1.5659        4.3248  0.1050\n",
      "     25        0.6599        3.6870  0.0911\n",
      "     26        1.8549        3.4150  0.1050\n",
      "     27        0.9737        2.8659  0.0972\n",
      "     28        1.6035        1.6351  0.0955\n",
      "     29        1.0399        0.8075  0.0979\n",
      "     30        0.7407        1.2675  0.1006\n",
      "     31        0.7436        1.6920  0.0965\n",
      "     32        0.7934        \u001b[32m0.2663\u001b[0m  0.0988\n",
      "     33        \u001b[36m0.4082\u001b[0m        2.1298  0.1013\n",
      "     34        0.8645        1.7699  0.1008\n",
      "     35        \u001b[36m0.3569\u001b[0m        2.7284  0.1193\n",
      "     36        1.0467       13.4243  0.1601\n",
      "     37        1.1603        4.3123  0.1032\n",
      "     38        2.3041        1.7450  0.1272\n",
      "     39        1.1013        1.0603  0.1141\n",
      "     40        0.8917        0.8121  0.0858\n",
      "     41        0.7833        0.7489  0.0913\n",
      "     42        0.5943        1.4021  0.0963\n",
      "     43        0.8204        2.7269  0.1057\n",
      "     44        0.6175        4.6057  0.1115\n",
      "     45        2.2723        2.7418  0.0983\n",
      "     46        0.6909        3.2943  0.0969\n",
      "     47        1.6367        3.8756  0.1108\n",
      "     48        0.9014        3.1013  0.1314\n",
      "     49        1.5468        1.8255  0.1205\n",
      "     50        0.9633        0.6433  0.0913\n",
      "     51        0.5877        0.4006  0.0828\n",
      "     52        0.5165        0.9828  0.0848\n",
      "     53        0.3866        1.7368  0.1257\n",
      "     54        0.7591        6.1190  0.1254\n",
      "     55        0.6761        5.7338  0.0985\n",
      "     56        2.7059        2.5421  0.1202\n",
      "     57        1.1670        7.5805  0.1198\n",
      "     58        1.2373        3.5614  0.1090\n",
      "     59        1.7203        1.7807  0.1074\n",
      "     60        1.0425        1.2598  0.0997\n",
      "     61        0.8643        0.7556  0.1127\n",
      "     62        0.6782        1.6003  0.1146\n",
      "     63        0.4293        2.8265  0.0957\n",
      "     64        1.1146       11.0428  0.1320\n",
      "     65        1.1237        3.4609  0.0899\n",
      "     66        1.7776        1.9336  0.1005\n",
      "     67        1.0212        1.2689  0.1012\n",
      "     68        0.8455        0.8170  0.1054\n",
      "     69        0.7323        1.3987  0.1168\n",
      "     70        0.5640        2.0798  0.0995\n",
      "     71        0.8969        9.4368  0.1019\n",
      "     72        0.8793        4.6860  0.1089\n",
      "     73        2.3784        1.2604  0.1136\n",
      "     74        0.8798        2.5761  0.0980\n",
      "     75        0.8497        1.4998  0.1133\n",
      "     76        0.9289        3.2306  0.0952\n",
      "     77        0.7275        2.6023  0.1009\n",
      "     78        1.3098        1.8596  0.1280\n",
      "     79        0.7240        0.6315  0.0979\n",
      "     80        0.6637        1.7713  0.1134\n",
      "     81        0.5091        1.3900  0.1056\n",
      "     82        0.8428        4.6634  0.1338\n",
      "     83        0.7813        3.4684  0.0974\n",
      "     84        1.7022        1.0078  0.1491\n",
      "     85        0.6495        0.6764  0.1031\n",
      "     86        0.5252        0.2931  0.1046\n",
      "     87        0.4939        1.3559  0.0861\n",
      "     88        0.4593        1.0991  0.1006\n",
      "     89        0.7432        4.7937  0.1211\n",
      "     90        0.7373        2.9304  0.1046\n",
      "     91        1.5150        0.9185  0.1109\n",
      "     92        0.5905        0.5094  0.1081\n",
      "     93        0.5142        \u001b[32m0.2617\u001b[0m  0.0817\n",
      "     94        0.4560        0.5739  0.1160\n",
      "     95        0.4405        0.3566  0.1195\n",
      "     96        0.5130        1.7641  0.0958\n",
      "     97        0.4825        1.2557  0.1202\n",
      "     98        0.7983        4.9237  0.1142\n",
      "     99        0.7679        2.7207  0.1103\n",
      "    100        1.4843        0.6651  0.1077\n",
      "    101        0.5645        0.7935  0.1127\n",
      "    102        0.4974        0.3994  0.1018\n",
      "    103        0.5260        2.2026  0.1088\n",
      "    104        0.5193        1.3967  0.1206\n",
      "    105        0.8446        4.4700  0.1121\n",
      "    106        0.7766        2.5003  0.0939\n",
      "    107        1.3855        0.9183  0.1046\n",
      "    108        0.5680        0.4415  0.1011\n",
      "    109        0.5046        \u001b[32m0.2477\u001b[0m  0.1791\n",
      "    110        0.4397        0.4745  0.0967\n",
      "    111        0.4268        0.3171  0.1069\n",
      "    112        0.4979        1.3147  0.0941\n",
      "    113        0.4386        0.9262  0.1111\n",
      "    114        0.7100        3.8165  0.1056\n",
      "    115        0.6445        1.8854  0.1236\n",
      "    116        1.1029        2.0830  0.1149\n",
      "    117        0.6487        0.8443  0.0938\n",
      "    118        0.7403        2.0099  0.1131\n",
      "    119        0.5554        0.8024  0.0871\n",
      "    120        0.6934        2.3844  0.1043\n",
      "    121        0.5669        0.9913  0.0917\n",
      "    122        0.7464        2.6099  0.0811\n",
      "    123        0.6024        1.1421  0.0779\n",
      "    124        0.7926        2.6171  0.1152\n",
      "    125        0.6170        1.1578  0.0867\n",
      "    126        0.7930        2.5045  0.0832\n",
      "    127        0.6046        1.0020  0.0704\n",
      "    128        0.7457        2.1430  0.0920\n",
      "    129        0.5567        0.6517  0.0909\n",
      "    130        0.6462        1.4525  0.0877\n",
      "    131        0.4904        0.3470  0.0895\n",
      "    132        0.5423        0.8031  0.0875\n",
      "    133        0.4547        0.2726  0.1119\n",
      "    134        0.4947        0.6448  0.1138\n",
      "    135        0.4409        0.2892  0.1207\n",
      "    136        0.4930        0.8183  0.1289\n",
      "    137        0.4567        0.3742  0.0940\n",
      "    138        0.5465        0.9264  0.1152\n",
      "    139        0.4650        0.5150  0.1166\n",
      "    140        0.5866        1.8496  0.0815\n",
      "    141        0.4979        0.8753  0.0823\n",
      "    142        0.7133        2.2919  0.0853\n",
      "    143        0.5824        0.8617  0.0929\n",
      "    144        0.7015        2.0399  0.0879\n",
      "    145        0.4253        0.8169  0.0833\n",
      "    146        0.6652        2.2092  0.0801\n",
      "    147        0.4785        0.7081  0.0926\n",
      "    148        0.6940        1.5436  0.0883\n",
      "    149        0.4883        0.3797  0.0869\n",
      "    150        0.5628        0.7209  0.0810\n",
      "    151        0.3779        \u001b[32m0.2305\u001b[0m  0.0897\n",
      "    152        0.4224        0.6408  0.0857\n",
      "    153        \u001b[36m0.3371\u001b[0m        \u001b[32m0.2260\u001b[0m  0.0791\n",
      "    154        0.4370        0.8744  0.0857\n",
      "    155        \u001b[36m0.3302\u001b[0m        0.3352  0.0861\n",
      "    156        0.5024        1.2160  0.0844\n",
      "    157        0.3357        0.4667  0.0906\n",
      "    158        0.5574        1.7877  0.0825\n",
      "    159        0.4167        0.7048  0.0880\n",
      "    160        0.6322        2.0919  0.0864\n",
      "    161        0.4466        0.7963  0.0805\n",
      "    162        0.6659        2.1331  0.0775\n",
      "    163        0.4363        0.7599  0.0827\n",
      "    164        0.6402        1.9628  0.0850\n",
      "    165        0.4576        0.5389  0.0717\n",
      "    166        0.5682        1.3311  0.0819\n",
      "    167        0.3638        0.3041  0.0892\n",
      "    168        0.4688        0.9712  0.0865\n",
      "    169        0.3496        0.2640  0.1596\n",
      "    170        0.4276        0.8168  0.0828\n",
      "    171        0.3381        0.2586  0.1125\n",
      "    172        0.4036        0.9394  0.0879\n",
      "    173        \u001b[36m0.3291\u001b[0m        0.3293  0.1051\n",
      "    174        0.4296        1.3128  0.0991\n",
      "    175        0.3427        0.4378  0.0817\n",
      "    176        0.4771        1.6068  0.0766\n",
      "    177        0.3607        0.5102  0.0869\n",
      "    178        0.5071        1.8068  0.0872\n",
      "    179        0.3760        0.5341  0.0791\n",
      "    180        0.5173        1.7966  0.0936\n",
      "    181        0.3825        0.5021  0.0776\n",
      "    182        0.5037        1.7287  0.0808\n",
      "    183        0.3748        0.4629  0.0709\n",
      "    184        0.4877        1.5489  0.0854\n",
      "    185        0.3689        0.4056  0.0903\n",
      "    186        0.4626        1.4289  0.0851\n",
      "    187        0.3580        0.3909  0.0862\n",
      "    188        0.4552        1.3558  0.0850\n",
      "    189        0.3590        0.3743  0.0841\n",
      "    190        0.4456        1.3698  0.0871\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'lr': [0.01, 0.001, 0.0001],\n",
    "    'max_epochs': list(range(50,300,50)),\n",
    "    'batch_size' : list(range(2,10,2))\n",
    "}\n",
    "gs = GridSearchCV(net_skorch, params, refit=False, cv=3, scoring='neg_root_mean_squared_error')\n",
    "# cv specifies the number of folds in a (Stratified)KFold\n",
    "\n",
    "gs.fit(X.cpu(), y.cpu())\n",
    "print(gs.best_score_, gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb01088-f13c-469c-bf2d-bd53453cac09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
